{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#1. Preparation\n",
        "##1.1 Download Stable-Diffusion Checkpoint"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Yt7ej3c5E9qC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-31 13:14:59--  https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4-full-ema.ckpt\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.5, 13.35.7.81, 13.35.7.38, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/4c/37/4c372b4ebb57bbd02e68413d4951aa326d4b3cfb6e62db989e529c6d4b26fb21/14749efc0ae8ef0329391ad4436feb781b402f4fece4883c7ad8d10556d8a36a?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd-v1-4-full-ema.ckpt%3B+filename%3D%22sd-v1-4-full-ema.ckpt%22%3B&Expires=1691068499&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MTA2ODQ5OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy80Yy8zNy80YzM3MmI0ZWJiNTdiYmQwMmU2ODQxM2Q0OTUxYWEzMjZkNGIzY2ZiNmU2MmRiOTg5ZTUyOWM2ZDRiMjZmYjIxLzE0NzQ5ZWZjMGFlOGVmMDMyOTM5MWFkNDQzNmZlYjc4MWI0MDJmNGZlY2U0ODgzYzdhZDhkMTA1NTZkOGEzNmE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=mi37clcbVySUNkaW0dxjt%7Eij3cE7Mxa5ShBp22EtFivWiKXSzxONlLBRnHwJOWNUsaG4Te84H56-W8TIxgPLceyw5eTuSOL3MXkH4jSxtoY9KSR3CCQmxZJON2doAi8j7uIuEBqTLPvfSjQ14%7EpUeKEUzjPaO3RfMTAkPy3kZ7bYu1NYaYB4DXqLnbIj66PIgqHfAqo1Y3IWZBiRWfOhRtNaEbS-yc-0B7YHjRlrFWbfNyjhNBS2dizAB97mf105WAT%7EyUq44Hgv7JB0E5qf1KoQrohKNEGQkZM2z1JG9mt2WvUqx3cx5XK2UwM-Wyigdv2VWbQ6169LV2-PgA99pA__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-07-31 13:14:59--  https://cdn-lfs.huggingface.co/repos/4c/37/4c372b4ebb57bbd02e68413d4951aa326d4b3cfb6e62db989e529c6d4b26fb21/14749efc0ae8ef0329391ad4436feb781b402f4fece4883c7ad8d10556d8a36a?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd-v1-4-full-ema.ckpt%3B+filename%3D%22sd-v1-4-full-ema.ckpt%22%3B&Expires=1691068499&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MTA2ODQ5OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy80Yy8zNy80YzM3MmI0ZWJiNTdiYmQwMmU2ODQxM2Q0OTUxYWEzMjZkNGIzY2ZiNmU2MmRiOTg5ZTUyOWM2ZDRiMjZmYjIxLzE0NzQ5ZWZjMGFlOGVmMDMyOTM5MWFkNDQzNmZlYjc4MWI0MDJmNGZlY2U0ODgzYzdhZDhkMTA1NTZkOGEzNmE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=mi37clcbVySUNkaW0dxjt%7Eij3cE7Mxa5ShBp22EtFivWiKXSzxONlLBRnHwJOWNUsaG4Te84H56-W8TIxgPLceyw5eTuSOL3MXkH4jSxtoY9KSR3CCQmxZJON2doAi8j7uIuEBqTLPvfSjQ14%7EpUeKEUzjPaO3RfMTAkPy3kZ7bYu1NYaYB4DXqLnbIj66PIgqHfAqo1Y3IWZBiRWfOhRtNaEbS-yc-0B7YHjRlrFWbfNyjhNBS2dizAB97mf105WAT%7EyUq44Hgv7JB0E5qf1KoQrohKNEGQkZM2z1JG9mt2WvUqx3cx5XK2UwM-Wyigdv2VWbQ6169LV2-PgA99pA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.35.7.99, 13.35.7.93, 13.35.7.113, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.35.7.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7703807346 (7.2G) [binary/octet-stream]\n",
            "Saving to: ‘sd-v1-4-full-ema.ckpt’\n",
            "\n",
            "sd-v1-4-full-ema.ck 100%[===================>]   7.17G  21.3MB/s    in 5m 47s  \n",
            "\n",
            "2023-07-31 13:20:47 (21.2 MB/s) - ‘sd-v1-4-full-ema.ckpt’ saved [7703807346/7703807346]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "mkdir -p pretrained/\n",
        "cd pretrained/\n",
        "wget https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4-full-ema.ckpt\n",
        "cd .."
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "t6B-ni4sE9qE",
        "outputId": "c902a215-d902-48a9-af78-fbfb29171996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2 Clone CelebBasis Code from [GitHub](https://github.com/ygtxr1997/CelebBasis/tree/main)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "dcnCuRJ_E9qF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CelebBasis'...\n",
            "remote: Enumerating objects: 788, done.\u001b[K\n",
            "remote: Counting objects: 100% (788/788), done.\u001b[K\n",
            "remote: Compressing objects: 100% (635/635), done.\u001b[K\n",
            "remote: Total 788 (delta 127), reused 739 (delta 97), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (788/788), 16.82 MiB | 9.15 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ygtxr1997/CelebBasis.git"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "24iZTCA2E9qF",
        "outputId": "1010712e-e1c8-4b8b-827a-6a6b618e22c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Download the StyleGAN Datasets and Third-Party Pretrained Weights from HuggingFace"
      ],
      "metadata": {
        "collapsed": false,
        "id": "_7qk1G31E9qG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "# dataset\n",
        "!mkdir -p ./datasets/ && cd ./datasets/ && wget -q https://huggingface.co/datasets/ygtxr1997/CelebBasis/resolve/main/stylegan.tar\n",
        "!cd ./datasets/ && tar -xf stylegan.tar && rm stylegan.tar\n",
        "# face alignment model\n",
        "!mkdir -p ./pretrained/PIPNet/ && mkdir -p ./pretrained/glint360k_cosface_r100_fp16_0.1/\n",
        "!cd ./pretrained/PIPNet/ && wget -q https://huggingface.co/datasets/ygtxr1997/CelebBasis/resolve/main/PIPNet/FaceBoxesV2.pth && wget -q https://huggingface.co/datasets/ygtxr1997/CelebBasis/resolve/main/PIPNet/epoch59.pth\n",
        "!cp ./pretrained/PIPNet/* ./CelebBasis/evaluation/face_align/PIPNet/weights\n",
        "# face recognition model\n",
        "!cd ./pretrained/glint360k_cosface_r100_fp16_0.1/ && wget -q https://huggingface.co/datasets/ygtxr1997/CelebBasis/resolve/main/glint360k_cosface_r100_fp16_0.1/backbone.pth\n",
        "!mkdir -p ./CelebBasis/weights/\n",
        "!cp -r ./pretrained/glint360k_cosface_r100_fp16_0.1/ ./CelebBasis/weights/"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WUco6eArE9qG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.4 *(Optional) Copy StyleGAN Datasets and Third-Party Pretrained Weights from Your Own Google Drive*\n",
        "*If you have any downloading problem in (Step 1.3), you can copy the datasets and pretrained models to your own Google Drive as follows.*\n",
        "\n",
        "You should first copy [CelebBasis Google Drive](https://drive.google.com/drive/folders/181pJ3Y2Ffk0R8jVcErPT611aWQLCz7D9?usp=sharing) to your own [Google Drive](https://drive.google.com/drive/my-drive).\n",
        "The Google Drive directory tree will be like:\n",
        "```shell\n",
        "My Drive/\n",
        " |--CelebBasis/\n",
        "  |--datasets/\n",
        "  |--pretrained/\n",
        "```\n",
        "Then, the following cell mounts your own Google Drive to this Colab Notebook and copies the datasets and weights files from the mounted folder."
      ],
      "metadata": {
        "collapsed": false,
        "id": "6zpPH-ZIE9qG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use Google Drive: False\n"
          ]
        }
      ],
      "source": [
        "# @title Use Googgle Drive? { display-mode: \"form\" }\n",
        "\n",
        "use_google_drive = False # @param [\"False\", \"True\"]\n",
        "print('Use Google Drive:', use_google_drive)\n",
        "if use_google_drive:\n",
        "  import os\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  os.system('cp -r /content/drive/MyDrive/CelebBasis/datasets/ ./')\n",
        "  os.system('cp -r /content/drive/MyDrive/CelebBasis/pretrained/* ./pretrained/')\n",
        "  drive.flush_and_unmount()\n",
        "  os.system('cd ./datasets && tar -xf stylegan.tar && rm stylegan.tar')\n",
        "  os.system('cp ./pretrained/PIPNet/* ./CelebBasis/evaluation/face_align/PIPNet/weights')\n",
        "  os.system('mkdir -p ./CelebBasis/weights/')\n",
        "  os.system('cp -r ./pretrained/glint360k_cosface_r100_fp16_0.1/ ./CelebBasis/weights/')\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PS4sau7TE9qG",
        "outputId": "8df3c57a-fb38-4755-a6b5-d3d1b74d091d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Use PIP to Install the Python Dependencies and Uninstall the Needless Modules (which are preinstalled by Google Colab but not used)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "GFbAJ13UE9qH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting blinker==1.6.2\n",
            "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: blinker\n",
            "Successfully installed blinker-1.6.2\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchdata as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mObtaining clip from git+https://github.com/openai/CLIP.git@a1d071733d7111c9c014f024669f959182114e33#egg=clip (from -r ../CelebBasis/requirements.txt (line 18))\n",
            "  Skipping because already up-to-date.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Obtaining taming_transformers from git+https://github.com/CompVis/taming-transformers.git@3ba01b241669f5ade541ce990f7650a3b8f65318#egg=taming_transformers (from -r ../CelebBasis/requirements.txt (line 141))\n",
            "  Skipping because already up-to-date.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting absl-py==1.3.0 (from -r ../CelebBasis/requirements.txt (line 1))\n",
            "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "Collecting aiohttp==3.8.3 (from -r ../CelebBasis/requirements.txt (line 2))\n",
            "  Using cached aiohttp-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 3)) (1.3.1)\n",
            "Collecting albumentations==1.1.0 (from -r ../CelebBasis/requirements.txt (line 4))\n",
            "  Using cached albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
            "Collecting altair==4.2.0 (from -r ../CelebBasis/requirements.txt (line 5))\n",
            "  Using cached altair-4.2.0-py3-none-any.whl (812 kB)\n",
            "Requirement already satisfied: aniso8601==9.0.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 6)) (9.0.1)\n",
            "Collecting asttokens (from -r ../CelebBasis/requirements.txt (line 7))\n",
            "  Using cached asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: async-timeout==4.0.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 8)) (4.0.2)\n",
            "Collecting attrs==22.1.0 (from -r ../CelebBasis/requirements.txt (line 9))\n",
            "  Using cached attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
            "Collecting autofaiss==2.15.6 (from -r ../CelebBasis/requirements.txt (line 10))\n",
            "  Using cached autofaiss-2.15.6-py3-none-any.whl (70 kB)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 12)) (1.6.2)\n",
            "Requirement already satisfied: braceexpand==0.1.7 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 13)) (0.1.7)\n",
            "Requirement already satisfied: cachetools==5.2.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 14)) (5.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 15)) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer==2.0.12 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 16)) (2.0.12)\n",
            "Requirement already satisfied: click==8.1.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 17)) (8.1.3)\n",
            "Collecting clip-anytorch==2.5.2 (from -r ../CelebBasis/requirements.txt (line 19))\n",
            "  Using cached clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n",
            "Collecting clip-retrieval==2.36.1 (from -r ../CelebBasis/requirements.txt (line 20))\n",
            "  Using cached clip_retrieval-2.36.1-py3-none-any.whl (353 kB)\n",
            "Requirement already satisfied: comm in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 21)) (0.1.3)\n",
            "Requirement already satisfied: commonmark==0.9.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 22)) (0.9.1)\n",
            "Requirement already satisfied: contourpy==1.0.6 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 23)) (1.0.6)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 24)) (0.11.0)\n",
            "Requirement already satisfied: Cython==0.29.35 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 25)) (0.29.35)\n",
            "Requirement already satisfied: dataclasses==0.6 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 26)) (0.6)\n",
            "Requirement already satisfied: debugpy in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 27)) (1.6.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 28)) (4.4.2)\n",
            "Requirement already satisfied: docker-pycreds==0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 29)) (0.4.0)\n",
            "Requirement already satisfied: einops==0.4.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 30)) (0.4.1)\n",
            "Collecting embedding-reader==1.5.0 (from -r ../CelebBasis/requirements.txt (line 31))\n",
            "  Using cached embedding_reader-1.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: entrypoints==0.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 32)) (0.4)\n",
            "Requirement already satisfied: executing in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 33)) (1.2.0)\n",
            "Requirement already satisfied: ExifRead-nocycle==3.0.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 34)) (3.0.1)\n",
            "Collecting facexlib==0.2.5 (from -r ../CelebBasis/requirements.txt (line 35))\n",
            "  Using cached facexlib-0.2.5-py3-none-any.whl (59 kB)\n",
            "Requirement already satisfied: faiss-cpu==1.7.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 36)) (1.7.4)\n",
            "Requirement already satisfied: filelock==3.8.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 37)) (3.8.0)\n",
            "Collecting filterpy==1.4.5 (from -r ../CelebBasis/requirements.txt (line 38))\n",
            "  Using cached filterpy-1.4.5-py3-none-any.whl\n",
            "Requirement already satisfied: fire==0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 39)) (0.4.0)\n",
            "Collecting Flask==2.3.2 (from -r ../CelebBasis/requirements.txt (line 40))\n",
            "  Using cached Flask-2.3.2-py3-none-any.whl (96 kB)\n",
            "Collecting Flask-Cors==3.0.10 (from -r ../CelebBasis/requirements.txt (line 41))\n",
            "  Using cached Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting Flask-RESTful==0.3.9 (from -r ../CelebBasis/requirements.txt (line 42))\n",
            "  Using cached Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fonttools==4.38.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 43)) (4.38.0)\n",
            "Requirement already satisfied: frozenlist==1.3.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 44)) (1.3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 45)) (2022.11.0)\n",
            "Requirement already satisfied: ftfy==6.1.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 46)) (6.1.1)\n",
            "Requirement already satisfied: future==0.18.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 47)) (0.18.2)\n",
            "Requirement already satisfied: gitdb==4.0.10 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 48)) (4.0.10)\n",
            "Collecting GitPython==3.1.29 (from -r ../CelebBasis/requirements.txt (line 49))\n",
            "  Using cached GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "Requirement already satisfied: grpcio==1.50.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 50)) (1.50.0)\n",
            "Requirement already satisfied: h5py==3.8.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 51)) (3.8.0)\n",
            "Collecting huggingface-hub==0.11.0 (from -r ../CelebBasis/requirements.txt (line 52))\n",
            "  Using cached huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "Requirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 53)) (3.4)\n",
            "Requirement already satisfied: imageio==2.14.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 54)) (2.14.1)\n",
            "Requirement already satisfied: imageio-ffmpeg==0.4.7 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 55)) (0.4.7)\n",
            "Collecting img2dataset==1.41.0 (from -r ../CelebBasis/requirements.txt (line 56))\n",
            "  Using cached img2dataset-1.41.0-py3-none-any.whl (40 kB)\n",
            "Requirement already satisfied: importlib-metadata==5.0.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 57)) (5.0.0)\n",
            "Requirement already satisfied: importlib-resources==5.10.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 58)) (5.10.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 59)) (5.5.6)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 60)) (7.34.0)\n",
            "Requirement already satisfied: itsdangerous==2.1.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 61)) (2.1.2)\n",
            "Requirement already satisfied: jedi in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 62)) (0.19.0)\n",
            "Requirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 63)) (3.1.2)\n",
            "Requirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 64)) (1.2.0)\n",
            "Collecting jsonschema==4.17.1 (from -r ../CelebBasis/requirements.txt (line 65))\n",
            "  Using cached jsonschema-4.17.1-py3-none-any.whl (90 kB)\n",
            "Requirement already satisfied: jupyter_client in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 66)) (6.1.12)\n",
            "Requirement already satisfied: jupyter_core in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 67)) (5.3.1)\n",
            "Requirement already satisfied: kiwisolver==1.4.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 68)) (1.4.4)\n",
            "Collecting kornia==0.6.0 (from -r ../CelebBasis/requirements.txt (line 69))\n",
            "  Using cached kornia-0.6.0-py2.py3-none-any.whl (367 kB)\n",
            "Requirement already satisfied: llvmlite==0.39.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 70)) (0.39.1)\n",
            "Requirement already satisfied: Markdown==3.4.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 71)) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe==2.1.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 72)) (2.1.1)\n",
            "Collecting matplotlib==3.6.2 (from -r ../CelebBasis/requirements.txt (line 73))\n",
            "  Using cached matplotlib-3.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 74)) (0.1.6)\n",
            "Requirement already satisfied: multidict==6.0.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 75)) (6.0.2)\n",
            "Collecting multilingual-clip==1.0.10 (from -r ../CelebBasis/requirements.txt (line 76))\n",
            "  Using cached multilingual_clip-1.0.10-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 77)) (1.5.6)\n",
            "Requirement already satisfied: networkx==2.8.8 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 78)) (2.8.8)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 79)) (3.8.1)\n",
            "Requirement already satisfied: numba==0.56.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 80)) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 81)) (1.22.4)\n",
            "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 82)) (3.2.2)\n",
            "Requirement already satisfied: omegaconf==2.1.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 83)) (2.1.1)\n",
            "Collecting open-clip-torch==2.19.0 (from -r ../CelebBasis/requirements.txt (line 84))\n",
            "  Using cached open_clip_torch-2.19.0-py3-none-any.whl (1.5 MB)\n",
            "Requirement already satisfied: opencv-python==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 85)) (4.8.0.74)\n",
            "Requirement already satisfied: opencv-python-headless==4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 86)) (4.6.0.66)\n",
            "Requirement already satisfied: packaging==21.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 87)) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 88)) (1.5.3)\n",
            "Requirement already satisfied: parso in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 89)) (0.8.3)\n",
            "Requirement already satisfied: pathtools==0.1.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 90)) (0.1.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 91)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 92)) (0.7.5)\n",
            "Requirement already satisfied: Pillow==9.0.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 93)) (9.0.1)\n",
            "Requirement already satisfied: pkgutil_resolve_name==1.3.10 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 94)) (1.3.10)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 95)) (3.9.1)\n",
            "Requirement already satisfied: prometheus-client==0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 96)) (0.16.0)\n",
            "Requirement already satisfied: promise==2.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 97)) (2.3)\n",
            "Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 98)) (3.0.39)\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 99)) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 100)) (5.9.5)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 101)) (0.7.0)\n",
            "Requirement already satisfied: pudb==2019.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 102)) (2019.2)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 103)) (0.2.2)\n",
            "Requirement already satisfied: pyarrow==7.0.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 104)) (7.0.0)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 105)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 106)) (0.2.8)\n",
            "Collecting pydeck==0.8.0 (from -r ../CelebBasis/requirements.txt (line 107))\n",
            "  Using cached pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 108)) (0.3.1)\n",
            "Requirement already satisfied: Pygments==2.13.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 109)) (2.13.0)\n",
            "Requirement already satisfied: Pympler==1.0.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 110)) (1.0.1)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 111)) (3.0.9)\n",
            "Requirement already satisfied: pyrsistent==0.19.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 112)) (0.19.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 113)) (2.8.2)\n",
            "Collecting pytorch-lightning==1.5.9 (from -r ../CelebBasis/requirements.txt (line 114))\n",
            "  Using cached pytorch_lightning-1.5.9-py3-none-any.whl (527 kB)\n",
            "Requirement already satisfied: pytz==2022.6 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 115)) (2022.6)\n",
            "Requirement already satisfied: pytz-deprecation-shim==0.1.0.post0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 116)) (0.1.0.post0)\n",
            "Requirement already satisfied: PyWavelets==1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 117)) (1.4.1)\n",
            "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 118)) (6.0)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 119)) (23.2.1)\n",
            "Requirement already satisfied: qudida==0.0.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 120)) (0.0.4)\n",
            "Requirement already satisfied: regex==2022.10.31 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 121)) (2022.10.31)\n",
            "Requirement already satisfied: requests==2.27.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 122)) (2.27.1)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 123)) (1.3.1)\n",
            "Requirement already satisfied: rich==12.6.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 124)) (12.6.0)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 125)) (4.9)\n",
            "Requirement already satisfied: sacremoses==0.0.53 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 126)) (0.0.53)\n",
            "Requirement already satisfied: safetensors==0.3.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 127)) (0.3.1)\n",
            "Requirement already satisfied: scikit-image==0.19.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 128)) (0.19.3)\n",
            "Collecting scikit-learn==1.1.3 (from -r ../CelebBasis/requirements.txt (line 129))\n",
            "  Using cached scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "Requirement already satisfied: scipy==1.9.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 130)) (1.9.3)\n",
            "Requirement already satisfied: semver==2.13.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 131)) (2.13.0)\n",
            "Collecting sentence-transformers==2.2.2 (from -r ../CelebBasis/requirements.txt (line 132))\n",
            "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
            "Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 133)) (0.1.99)\n",
            "Requirement already satisfied: sentry-sdk==1.21.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 134)) (1.21.1)\n",
            "Requirement already satisfied: setproctitle==1.3.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 135)) (1.3.2)\n",
            "Requirement already satisfied: shortuuid==1.0.11 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 136)) (1.0.11)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 137)) (1.16.0)\n",
            "Requirement already satisfied: smmap==5.0.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 138)) (5.0.0)\n",
            "Collecting stack-data (from -r ../CelebBasis/requirements.txt (line 139))\n",
            "  Using cached stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting streamlit==1.15.1 (from -r ../CelebBasis/requirements.txt (line 140))\n",
            "  Using cached streamlit-1.15.1-py2.py3-none-any.whl (10.3 MB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 142)) (2.12.3)\n",
            "Requirement already satisfied: tensorboard-data-server in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 143)) (0.7.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 144)) (1.8.1)\n",
            "Requirement already satisfied: termcolor==2.3.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 145)) (2.3.0)\n",
            "Collecting test-tube==0.7.5 (from -r ../CelebBasis/requirements.txt (line 146))\n",
            "  Using cached test_tube-0.7.5-py3-none-any.whl\n",
            "Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 147)) (3.1.0)\n",
            "Requirement already satisfied: tifffile==2022.10.10 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 148)) (2022.10.10)\n",
            "Collecting timm==0.6.13 (from -r ../CelebBasis/requirements.txt (line 149))\n",
            "  Using cached timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "Requirement already satisfied: tokenizers==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 150)) (0.12.1)\n",
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 151)) (0.10.2)\n",
            "Requirement already satisfied: toolz==0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 152)) (0.12.0)\n",
            "Requirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 153)) (1.12.0)\n",
            "Collecting torch-fidelity==0.3.0 (from -r ../CelebBasis/requirements.txt (line 154))\n",
            "  Using cached torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Collecting torchmetrics==0.6.0 (from -r ../CelebBasis/requirements.txt (line 155))\n",
            "  Using cached torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 156)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 157)) (6.3.1)\n",
            "Requirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 158)) (4.64.1)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 159)) (5.7.1)\n",
            "Collecting transformers==4.18.0 (from -r ../CelebBasis/requirements.txt (line 160))\n",
            "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 161)) (4.7.1)\n",
            "Requirement already satisfied: tzdata==2022.6 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 162)) (2022.6)\n",
            "Collecting tzlocal==4.2 (from -r ../CelebBasis/requirements.txt (line 163))\n",
            "  Using cached tzlocal-4.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: urllib3==1.26.13 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 164)) (1.26.13)\n",
            "Requirement already satisfied: urwid==2.1.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 165)) (2.1.2)\n",
            "Requirement already satisfied: validators==0.20.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 166)) (0.20.0)\n",
            "Collecting wandb==0.12.21 (from -r ../CelebBasis/requirements.txt (line 167))\n",
            "  Using cached wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "Requirement already satisfied: watchdog==2.1.9 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 168)) (2.1.9)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 169)) (0.2.6)\n",
            "Requirement already satisfied: webdataset==0.2.48 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 170)) (0.2.48)\n",
            "Requirement already satisfied: Werkzeug==2.3.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 171)) (2.3.3)\n",
            "Requirement already satisfied: yarl==1.8.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 172)) (1.8.1)\n",
            "Requirement already satisfied: zipp==3.10.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 173)) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba==0.56.4->-r ../CelebBasis/requirements.txt (line 80)) (59.5.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.1.1->-r ../CelebBasis/requirements.txt (line 83)) (4.8)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r ../CelebBasis/requirements.txt (line 59)) (0.2.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r ../CelebBasis/requirements.txt (line 142)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r ../CelebBasis/requirements.txt (line 142)) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r ../CelebBasis/requirements.txt (line 142)) (0.41.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from -r ../CelebBasis/requirements.txt (line 156))\n",
            "  Using cached torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "  Using cached torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "  Using cached torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "  Using cached torchvision-0.14.0-cp310-cp310-manylinux1_x86_64.whl (24.3 MB)\n",
            "  Using cached torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
            "  Using cached torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
            "Installing collected packages: attrs, asttokens, absl-py, tzlocal, torchvision, torchmetrics, taming_transformers, stack-data, scikit-learn, pydeck, matplotlib, kornia, jsonschema, huggingface-hub, GitPython, Flask, aiohttp, wandb, transformers, torch-fidelity, timm, Flask-RESTful, Flask-Cors, filterpy, embedding-reader, clip-anytorch, clip, altair, streamlit, sentence-transformers, open-clip-torch, multilingual-clip, facexlib, autofaiss, albumentations, test-tube, pytorch-lightning, img2dataset, clip-retrieval\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.1.0\n",
            "    Uninstalling attrs-23.1.0:\n",
            "      Successfully uninstalled attrs-23.1.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 5.0.1\n",
            "    Uninstalling tzlocal-5.0.1:\n",
            "      Successfully uninstalled tzlocal-5.0.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "  Running setup.py develop for taming_transformers\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 2.2.5\n",
            "    Uninstalling Flask-2.2.5:\n",
            "      Successfully uninstalled Flask-2.2.5\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.8.5\n",
            "    Uninstalling aiohttp-3.8.5:\n",
            "      Successfully uninstalled aiohttp-3.8.5\n",
            "  Running setup.py develop for clip\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 4.2.2\n",
            "    Uninstalling altair-4.2.2:\n",
            "      Successfully uninstalled altair-4.2.2\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.2.1\n",
            "    Uninstalling albumentations-1.2.1:\n",
            "      Successfully uninstalled albumentations-1.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2022.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Flask-2.3.2 Flask-Cors-3.0.10 Flask-RESTful-0.3.9 GitPython-3.1.29 absl-py-1.3.0 aiohttp-3.8.3 albumentations-1.1.0 altair-4.2.0 asttokens-2.2.1 attrs-22.1.0 autofaiss-2.15.6 clip-1.0 clip-anytorch-2.5.2 clip-retrieval-2.36.1 embedding-reader-1.5.0 facexlib-0.2.5 filterpy-1.4.5 huggingface-hub-0.11.0 img2dataset-1.41.0 jsonschema-4.17.1 kornia-0.6.0 matplotlib-3.6.2 multilingual-clip-1.0.10 open-clip-torch-2.19.0 pydeck-0.8.0 pytorch-lightning-1.5.9 scikit-learn-1.1.3 sentence-transformers-2.2.2 stack-data-0.6.2 streamlit-1.15.1 taming_transformers-0.0.1 test-tube-0.7.5 timm-0.6.13 torch-fidelity-0.3.0 torchmetrics-0.6.0 torchvision-0.13.0 transformers-4.18.0 tzlocal-4.2 wandb-0.12.21\n",
            "clip-anytorch                    2.5.2\n",
            "open-clip-torch                  2.19.0\n",
            "pytorch-lightning                1.5.9\n",
            "torch                            1.12.0\n",
            "torch-fidelity                   0.3.0\n",
            "torchmetrics                     0.6.0\n",
            "torchsummary                     1.5.1\n",
            "torchvision                      0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install blinker==1.6.2 --ignore-installed\n",
        "!pip uninstall -r ./CelebBasis/requirements_uninstall.txt -y\n",
        "!mkdir -p pip_installed/ && cd pip_installed/ && pip install -r ../CelebBasis/requirements.txt\n",
        "!pip list |grep torch"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "h35uGw4EE9qH",
        "outputId": "07eb4ae8-2ffb-4953-98b6-b3985957d4b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#2. Crop and Align Faces"
      ],
      "metadata": {
        "collapsed": false,
        "id": "GGuX_09qE9qI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CelebBasis/evaluation/face_align/PIPNet/FaceBoxesV2/utils/build.py:13: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
            "  from distutils.core import setup\n",
            "running build_ext\n",
            "skipping 'nms/cpu_nms.c' Cython extension (up-to-date)\n",
            "/content/CelebBasis\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "alignment model loaded\n",
            "Detect and Align: 100% 224/224 [00:46<00:00,  4.78it/s]\n",
            "Generating pickle list...(saved to ../datasets/stylegan/ffhq.pickle)\n",
            "100% 224/224 [00:00<00:00, 680321.58it/s]\n",
            "Checking pickle list...\n",
            "pickle type: <class 'list'> , total len: 224\n",
            "pickle[0]: ../datasets/stylegan/ffhq/0002.png\n",
            "pickle[1]: ../datasets/stylegan/ffhq/0011.png\n",
            "pickle[-2]: ../datasets/stylegan/ffhq/1996.png\n",
            "pickle[-1]: ../datasets/stylegan/ffhq/1997.png\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!cd CelebBasis && chmod +x *.sh && bash ./00_align_face.sh ../datasets/stylegan/stylegan3-r-ffhq-1024x1024 ../datasets/stylegan/ffhq"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qqI_LbxzE9qI",
        "outputId": "7d3d6385-1431-4965-9e33-8f649ce1253c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train\n",
        "* Limited by Google Colab V100 GPU Memory ($<$16GB), we have to modify the `configs/stable-diffusion/aigc_id_colab.yaml` as follows:\n",
        "```yaml\n",
        "model:\n",
        "  params:\n",
        "    personalization_config:\n",
        "      params:\n",
        "        momentum: 0.9  # default: 0.99\n",
        "data:\n",
        "  params:\n",
        "    batch_size: 1  # default: 2\n",
        "    num_workers: 2  # default: 8\n",
        "lightning:\n",
        "  modelcheckpoint:\n",
        "    params:\n",
        "      every_n_train_steps: 400  # default: 200\n",
        "  callbacks:\n",
        "    image_logger:\n",
        "      params:\n",
        "        batch_frequency: 1200  # default: 600\n",
        "  trainer:\n",
        "    max_steps: 800  # default: 1600\n",
        "```\n",
        "* These modifications may increase the training time and downgrade the performance slightly."
      ],
      "metadata": {
        "collapsed": false,
        "id": "guux5FSnE9qI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 23\n",
            "Running on GPUs 0,\n",
            "Loading model from ../pretrained/sd-v1-4-full-ema.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Downloading: \"https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth\" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth\n",
            "100% 5.10M/5.10M [00:00<00:00, 63.0MB/s]\n",
            "Downloading: 100% 939k/939k [00:00<00:00, 5.43MB/s]\n",
            "Downloading: 100% 512k/512k [00:00<00:00, 1.02MB/s]\n",
            "Downloading: 100% 389/389 [00:00<00:00, 293kB/s]\n",
            "Downloading: 100% 905/905 [00:00<00:00, 660kB/s]\n",
            "Downloading: 100% 4.41k/4.41k [00:00<00:00, 3.47MB/s]\n",
            "Downloading: 100% 1.59G/1.59G [00:23<00:00, 71.4MB/s]\n",
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'text_projection.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'visual_projection.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'logit_scale', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[celebs cols_embeddings len]: [646, 638, 311, 118, 25, 2]\n",
            "[(col_0) celebs ori]: torch.Size([646, 768]) tensor(5.3118e-05) tensor(-0.0405) tensor(0.0509)\n",
            "[(col_0) celebs c_mean]: tensor(-1.2509e-05) tensor(-0.0091) tensor(0.0112)\n",
            "[(col_0) celebs pca_base]: torch.Size([512, 768]) tensor(-0.0003) tensor(-0.1054) tensor(0.0999) tensor(1.0000)\n",
            "[(col_0) celebs embeddings loaded]: torch.Size([513, 768]) (device:cuda)\n",
            "[(col_1) celebs ori]: torch.Size([638, 768]) tensor(-9.8908e-06) tensor(-0.0414) tensor(0.0464)\n",
            "[(col_1) celebs c_mean]: tensor(-3.7355e-06) tensor(-0.0087) tensor(0.0065)\n",
            "[(col_1) celebs pca_base]: torch.Size([512, 768]) tensor(1.3023e-05) tensor(-0.1589) tensor(0.2419) tensor(1.)\n",
            "[(col_1) celebs embeddings loaded]: torch.Size([513, 768]) (device:cuda)\n",
            "[all celebs embeddings loaded] shape = torch.Size([2, 513, 768]) (device:cuda) flatten=False\n",
            "Restored from ../pretrained/sd-v1-4-full-ema.ckpt with 0 missing and 688 unexpected keys\n",
            "Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'model_ema.diffusion_modeltime_embed0weight', 'model_ema.diffusion_modeltime_embed0bias', 'model_ema.diffusion_modeltime_embed2weight', 'model_ema.diffusion_modeltime_embed2bias', 'model_ema.diffusion_modelinput_blocks00weight', 'model_ema.diffusion_modelinput_blocks00bias', 'model_ema.diffusion_modelinput_blocks10in_layers0weight', 'model_ema.diffusion_modelinput_blocks10in_layers0bias', 'model_ema.diffusion_modelinput_blocks10in_layers2weight', 'model_ema.diffusion_modelinput_blocks10in_layers2bias', 'model_ema.diffusion_modelinput_blocks10emb_layers1weight', 'model_ema.diffusion_modelinput_blocks10emb_layers1bias', 'model_ema.diffusion_modelinput_blocks10out_layers0weight', 'model_ema.diffusion_modelinput_blocks10out_layers0bias', 'model_ema.diffusion_modelinput_blocks10out_layers3weight', 'model_ema.diffusion_modelinput_blocks10out_layers3bias', 'model_ema.diffusion_modelinput_blocks11normweight', 'model_ema.diffusion_modelinput_blocks11normbias', 'model_ema.diffusion_modelinput_blocks11proj_inweight', 'model_ema.diffusion_modelinput_blocks11proj_inbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks11proj_outweight', 'model_ema.diffusion_modelinput_blocks11proj_outbias', 'model_ema.diffusion_modelinput_blocks20in_layers0weight', 'model_ema.diffusion_modelinput_blocks20in_layers0bias', 'model_ema.diffusion_modelinput_blocks20in_layers2weight', 'model_ema.diffusion_modelinput_blocks20in_layers2bias', 'model_ema.diffusion_modelinput_blocks20emb_layers1weight', 'model_ema.diffusion_modelinput_blocks20emb_layers1bias', 'model_ema.diffusion_modelinput_blocks20out_layers0weight', 'model_ema.diffusion_modelinput_blocks20out_layers0bias', 'model_ema.diffusion_modelinput_blocks20out_layers3weight', 'model_ema.diffusion_modelinput_blocks20out_layers3bias', 'model_ema.diffusion_modelinput_blocks21normweight', 'model_ema.diffusion_modelinput_blocks21normbias', 'model_ema.diffusion_modelinput_blocks21proj_inweight', 'model_ema.diffusion_modelinput_blocks21proj_inbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks21proj_outweight', 'model_ema.diffusion_modelinput_blocks21proj_outbias', 'model_ema.diffusion_modelinput_blocks30opweight', 'model_ema.diffusion_modelinput_blocks30opbias', 'model_ema.diffusion_modelinput_blocks40in_layers0weight', 'model_ema.diffusion_modelinput_blocks40in_layers0bias', 'model_ema.diffusion_modelinput_blocks40in_layers2weight', 'model_ema.diffusion_modelinput_blocks40in_layers2bias', 'model_ema.diffusion_modelinput_blocks40emb_layers1weight', 'model_ema.diffusion_modelinput_blocks40emb_layers1bias', 'model_ema.diffusion_modelinput_blocks40out_layers0weight', 'model_ema.diffusion_modelinput_blocks40out_layers0bias', 'model_ema.diffusion_modelinput_blocks40out_layers3weight', 'model_ema.diffusion_modelinput_blocks40out_layers3bias', 'model_ema.diffusion_modelinput_blocks40skip_connectionweight', 'model_ema.diffusion_modelinput_blocks40skip_connectionbias', 'model_ema.diffusion_modelinput_blocks41normweight', 'model_ema.diffusion_modelinput_blocks41normbias', 'model_ema.diffusion_modelinput_blocks41proj_inweight', 'model_ema.diffusion_modelinput_blocks41proj_inbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks41proj_outweight', 'model_ema.diffusion_modelinput_blocks41proj_outbias', 'model_ema.diffusion_modelinput_blocks50in_layers0weight', 'model_ema.diffusion_modelinput_blocks50in_layers0bias', 'model_ema.diffusion_modelinput_blocks50in_layers2weight', 'model_ema.diffusion_modelinput_blocks50in_layers2bias', 'model_ema.diffusion_modelinput_blocks50emb_layers1weight', 'model_ema.diffusion_modelinput_blocks50emb_layers1bias', 'model_ema.diffusion_modelinput_blocks50out_layers0weight', 'model_ema.diffusion_modelinput_blocks50out_layers0bias', 'model_ema.diffusion_modelinput_blocks50out_layers3weight', 'model_ema.diffusion_modelinput_blocks50out_layers3bias', 'model_ema.diffusion_modelinput_blocks51normweight', 'model_ema.diffusion_modelinput_blocks51normbias', 'model_ema.diffusion_modelinput_blocks51proj_inweight', 'model_ema.diffusion_modelinput_blocks51proj_inbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks51proj_outweight', 'model_ema.diffusion_modelinput_blocks51proj_outbias', 'model_ema.diffusion_modelinput_blocks60opweight', 'model_ema.diffusion_modelinput_blocks60opbias', 'model_ema.diffusion_modelinput_blocks70in_layers0weight', 'model_ema.diffusion_modelinput_blocks70in_layers0bias', 'model_ema.diffusion_modelinput_blocks70in_layers2weight', 'model_ema.diffusion_modelinput_blocks70in_layers2bias', 'model_ema.diffusion_modelinput_blocks70emb_layers1weight', 'model_ema.diffusion_modelinput_blocks70emb_layers1bias', 'model_ema.diffusion_modelinput_blocks70out_layers0weight', 'model_ema.diffusion_modelinput_blocks70out_layers0bias', 'model_ema.diffusion_modelinput_blocks70out_layers3weight', 'model_ema.diffusion_modelinput_blocks70out_layers3bias', 'model_ema.diffusion_modelinput_blocks70skip_connectionweight', 'model_ema.diffusion_modelinput_blocks70skip_connectionbias', 'model_ema.diffusion_modelinput_blocks71normweight', 'model_ema.diffusion_modelinput_blocks71normbias', 'model_ema.diffusion_modelinput_blocks71proj_inweight', 'model_ema.diffusion_modelinput_blocks71proj_inbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks71proj_outweight', 'model_ema.diffusion_modelinput_blocks71proj_outbias', 'model_ema.diffusion_modelinput_blocks80in_layers0weight', 'model_ema.diffusion_modelinput_blocks80in_layers0bias', 'model_ema.diffusion_modelinput_blocks80in_layers2weight', 'model_ema.diffusion_modelinput_blocks80in_layers2bias', 'model_ema.diffusion_modelinput_blocks80emb_layers1weight', 'model_ema.diffusion_modelinput_blocks80emb_layers1bias', 'model_ema.diffusion_modelinput_blocks80out_layers0weight', 'model_ema.diffusion_modelinput_blocks80out_layers0bias', 'model_ema.diffusion_modelinput_blocks80out_layers3weight', 'model_ema.diffusion_modelinput_blocks80out_layers3bias', 'model_ema.diffusion_modelinput_blocks81normweight', 'model_ema.diffusion_modelinput_blocks81normbias', 'model_ema.diffusion_modelinput_blocks81proj_inweight', 'model_ema.diffusion_modelinput_blocks81proj_inbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks81proj_outweight', 'model_ema.diffusion_modelinput_blocks81proj_outbias', 'model_ema.diffusion_modelinput_blocks90opweight', 'model_ema.diffusion_modelinput_blocks90opbias', 'model_ema.diffusion_modelinput_blocks100in_layers0weight', 'model_ema.diffusion_modelinput_blocks100in_layers0bias', 'model_ema.diffusion_modelinput_blocks100in_layers2weight', 'model_ema.diffusion_modelinput_blocks100in_layers2bias', 'model_ema.diffusion_modelinput_blocks100emb_layers1weight', 'model_ema.diffusion_modelinput_blocks100emb_layers1bias', 'model_ema.diffusion_modelinput_blocks100out_layers0weight', 'model_ema.diffusion_modelinput_blocks100out_layers0bias', 'model_ema.diffusion_modelinput_blocks100out_layers3weight', 'model_ema.diffusion_modelinput_blocks100out_layers3bias', 'model_ema.diffusion_modelinput_blocks110in_layers0weight', 'model_ema.diffusion_modelinput_blocks110in_layers0bias', 'model_ema.diffusion_modelinput_blocks110in_layers2weight', 'model_ema.diffusion_modelinput_blocks110in_layers2bias', 'model_ema.diffusion_modelinput_blocks110emb_layers1weight', 'model_ema.diffusion_modelinput_blocks110emb_layers1bias', 'model_ema.diffusion_modelinput_blocks110out_layers0weight', 'model_ema.diffusion_modelinput_blocks110out_layers0bias', 'model_ema.diffusion_modelinput_blocks110out_layers3weight', 'model_ema.diffusion_modelinput_blocks110out_layers3bias', 'model_ema.diffusion_modelmiddle_block0in_layers0weight', 'model_ema.diffusion_modelmiddle_block0in_layers0bias', 'model_ema.diffusion_modelmiddle_block0in_layers2weight', 'model_ema.diffusion_modelmiddle_block0in_layers2bias', 'model_ema.diffusion_modelmiddle_block0emb_layers1weight', 'model_ema.diffusion_modelmiddle_block0emb_layers1bias', 'model_ema.diffusion_modelmiddle_block0out_layers0weight', 'model_ema.diffusion_modelmiddle_block0out_layers0bias', 'model_ema.diffusion_modelmiddle_block0out_layers3weight', 'model_ema.diffusion_modelmiddle_block0out_layers3bias', 'model_ema.diffusion_modelmiddle_block1normweight', 'model_ema.diffusion_modelmiddle_block1normbias', 'model_ema.diffusion_modelmiddle_block1proj_inweight', 'model_ema.diffusion_modelmiddle_block1proj_inbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3bias', 'model_ema.diffusion_modelmiddle_block1proj_outweight', 'model_ema.diffusion_modelmiddle_block1proj_outbias', 'model_ema.diffusion_modelmiddle_block2in_layers0weight', 'model_ema.diffusion_modelmiddle_block2in_layers0bias', 'model_ema.diffusion_modelmiddle_block2in_layers2weight', 'model_ema.diffusion_modelmiddle_block2in_layers2bias', 'model_ema.diffusion_modelmiddle_block2emb_layers1weight', 'model_ema.diffusion_modelmiddle_block2emb_layers1bias', 'model_ema.diffusion_modelmiddle_block2out_layers0weight', 'model_ema.diffusion_modelmiddle_block2out_layers0bias', 'model_ema.diffusion_modelmiddle_block2out_layers3weight', 'model_ema.diffusion_modelmiddle_block2out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00in_layers0weight', 'model_ema.diffusion_modeloutput_blocks00in_layers0bias', 'model_ema.diffusion_modeloutput_blocks00in_layers2weight', 'model_ema.diffusion_modeloutput_blocks00in_layers2bias', 'model_ema.diffusion_modeloutput_blocks00emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks00emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks00out_layers0weight', 'model_ema.diffusion_modeloutput_blocks00out_layers0bias', 'model_ema.diffusion_modeloutput_blocks00out_layers3weight', 'model_ema.diffusion_modeloutput_blocks00out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks00skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks10in_layers0weight', 'model_ema.diffusion_modeloutput_blocks10in_layers0bias', 'model_ema.diffusion_modeloutput_blocks10in_layers2weight', 'model_ema.diffusion_modeloutput_blocks10in_layers2bias', 'model_ema.diffusion_modeloutput_blocks10emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks10emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks10out_layers0weight', 'model_ema.diffusion_modeloutput_blocks10out_layers0bias', 'model_ema.diffusion_modeloutput_blocks10out_layers3weight', 'model_ema.diffusion_modeloutput_blocks10out_layers3bias', 'model_ema.diffusion_modeloutput_blocks10skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks10skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks20in_layers0weight', 'model_ema.diffusion_modeloutput_blocks20in_layers0bias', 'model_ema.diffusion_modeloutput_blocks20in_layers2weight', 'model_ema.diffusion_modeloutput_blocks20in_layers2bias', 'model_ema.diffusion_modeloutput_blocks20emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks20emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks20out_layers0weight', 'model_ema.diffusion_modeloutput_blocks20out_layers0bias', 'model_ema.diffusion_modeloutput_blocks20out_layers3weight', 'model_ema.diffusion_modeloutput_blocks20out_layers3bias', 'model_ema.diffusion_modeloutput_blocks20skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks20skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks21convweight', 'model_ema.diffusion_modeloutput_blocks21convbias', 'model_ema.diffusion_modeloutput_blocks30in_layers0weight', 'model_ema.diffusion_modeloutput_blocks30in_layers0bias', 'model_ema.diffusion_modeloutput_blocks30in_layers2weight', 'model_ema.diffusion_modeloutput_blocks30in_layers2bias', 'model_ema.diffusion_modeloutput_blocks30emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks30emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks30out_layers0weight', 'model_ema.diffusion_modeloutput_blocks30out_layers0bias', 'model_ema.diffusion_modeloutput_blocks30out_layers3weight', 'model_ema.diffusion_modeloutput_blocks30out_layers3bias', 'model_ema.diffusion_modeloutput_blocks30skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks30skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks31normweight', 'model_ema.diffusion_modeloutput_blocks31normbias', 'model_ema.diffusion_modeloutput_blocks31proj_inweight', 'model_ema.diffusion_modeloutput_blocks31proj_inbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks31proj_outweight', 'model_ema.diffusion_modeloutput_blocks31proj_outbias', 'model_ema.diffusion_modeloutput_blocks40in_layers0weight', 'model_ema.diffusion_modeloutput_blocks40in_layers0bias', 'model_ema.diffusion_modeloutput_blocks40in_layers2weight', 'model_ema.diffusion_modeloutput_blocks40in_layers2bias', 'model_ema.diffusion_modeloutput_blocks40emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks40emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks40out_layers0weight', 'model_ema.diffusion_modeloutput_blocks40out_layers0bias', 'model_ema.diffusion_modeloutput_blocks40out_layers3weight', 'model_ema.diffusion_modeloutput_blocks40out_layers3bias', 'model_ema.diffusion_modeloutput_blocks40skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks40skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks41normweight', 'model_ema.diffusion_modeloutput_blocks41normbias', 'model_ema.diffusion_modeloutput_blocks41proj_inweight', 'model_ema.diffusion_modeloutput_blocks41proj_inbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks41proj_outweight', 'model_ema.diffusion_modeloutput_blocks41proj_outbias', 'model_ema.diffusion_modeloutput_blocks50in_layers0weight', 'model_ema.diffusion_modeloutput_blocks50in_layers0bias', 'model_ema.diffusion_modeloutput_blocks50in_layers2weight', 'model_ema.diffusion_modeloutput_blocks50in_layers2bias', 'model_ema.diffusion_modeloutput_blocks50emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks50emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks50out_layers0weight', 'model_ema.diffusion_modeloutput_blocks50out_layers0bias', 'model_ema.diffusion_modeloutput_blocks50out_layers3weight', 'model_ema.diffusion_modeloutput_blocks50out_layers3bias', 'model_ema.diffusion_modeloutput_blocks50skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks50skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks51normweight', 'model_ema.diffusion_modeloutput_blocks51normbias', 'model_ema.diffusion_modeloutput_blocks51proj_inweight', 'model_ema.diffusion_modeloutput_blocks51proj_inbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks51proj_outweight', 'model_ema.diffusion_modeloutput_blocks51proj_outbias', 'model_ema.diffusion_modeloutput_blocks52convweight', 'model_ema.diffusion_modeloutput_blocks52convbias', 'model_ema.diffusion_modeloutput_blocks60in_layers0weight', 'model_ema.diffusion_modeloutput_blocks60in_layers0bias', 'model_ema.diffusion_modeloutput_blocks60in_layers2weight', 'model_ema.diffusion_modeloutput_blocks60in_layers2bias', 'model_ema.diffusion_modeloutput_blocks60emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks60emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks60out_layers0weight', 'model_ema.diffusion_modeloutput_blocks60out_layers0bias', 'model_ema.diffusion_modeloutput_blocks60out_layers3weight', 'model_ema.diffusion_modeloutput_blocks60out_layers3bias', 'model_ema.diffusion_modeloutput_blocks60skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks60skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks61normweight', 'model_ema.diffusion_modeloutput_blocks61normbias', 'model_ema.diffusion_modeloutput_blocks61proj_inweight', 'model_ema.diffusion_modeloutput_blocks61proj_inbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks61proj_outweight', 'model_ema.diffusion_modeloutput_blocks61proj_outbias', 'model_ema.diffusion_modeloutput_blocks70in_layers0weight', 'model_ema.diffusion_modeloutput_blocks70in_layers0bias', 'model_ema.diffusion_modeloutput_blocks70in_layers2weight', 'model_ema.diffusion_modeloutput_blocks70in_layers2bias', 'model_ema.diffusion_modeloutput_blocks70emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks70emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks70out_layers0weight', 'model_ema.diffusion_modeloutput_blocks70out_layers0bias', 'model_ema.diffusion_modeloutput_blocks70out_layers3weight', 'model_ema.diffusion_modeloutput_blocks70out_layers3bias', 'model_ema.diffusion_modeloutput_blocks70skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks70skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks71normweight', 'model_ema.diffusion_modeloutput_blocks71normbias', 'model_ema.diffusion_modeloutput_blocks71proj_inweight', 'model_ema.diffusion_modeloutput_blocks71proj_inbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks71proj_outweight', 'model_ema.diffusion_modeloutput_blocks71proj_outbias', 'model_ema.diffusion_modeloutput_blocks80in_layers0weight', 'model_ema.diffusion_modeloutput_blocks80in_layers0bias', 'model_ema.diffusion_modeloutput_blocks80in_layers2weight', 'model_ema.diffusion_modeloutput_blocks80in_layers2bias', 'model_ema.diffusion_modeloutput_blocks80emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks80emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks80out_layers0weight', 'model_ema.diffusion_modeloutput_blocks80out_layers0bias', 'model_ema.diffusion_modeloutput_blocks80out_layers3weight', 'model_ema.diffusion_modeloutput_blocks80out_layers3bias', 'model_ema.diffusion_modeloutput_blocks80skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks80skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks81normweight', 'model_ema.diffusion_modeloutput_blocks81normbias', 'model_ema.diffusion_modeloutput_blocks81proj_inweight', 'model_ema.diffusion_modeloutput_blocks81proj_inbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks81proj_outweight', 'model_ema.diffusion_modeloutput_blocks81proj_outbias', 'model_ema.diffusion_modeloutput_blocks82convweight', 'model_ema.diffusion_modeloutput_blocks82convbias', 'model_ema.diffusion_modeloutput_blocks90in_layers0weight', 'model_ema.diffusion_modeloutput_blocks90in_layers0bias', 'model_ema.diffusion_modeloutput_blocks90in_layers2weight', 'model_ema.diffusion_modeloutput_blocks90in_layers2bias', 'model_ema.diffusion_modeloutput_blocks90emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks90emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks90out_layers0weight', 'model_ema.diffusion_modeloutput_blocks90out_layers0bias', 'model_ema.diffusion_modeloutput_blocks90out_layers3weight', 'model_ema.diffusion_modeloutput_blocks90out_layers3bias', 'model_ema.diffusion_modeloutput_blocks90skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks90skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks91normweight', 'model_ema.diffusion_modeloutput_blocks91normbias', 'model_ema.diffusion_modeloutput_blocks91proj_inweight', 'model_ema.diffusion_modeloutput_blocks91proj_inbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks91proj_outweight', 'model_ema.diffusion_modeloutput_blocks91proj_outbias', 'model_ema.diffusion_modeloutput_blocks100in_layers0weight', 'model_ema.diffusion_modeloutput_blocks100in_layers0bias', 'model_ema.diffusion_modeloutput_blocks100in_layers2weight', 'model_ema.diffusion_modeloutput_blocks100in_layers2bias', 'model_ema.diffusion_modeloutput_blocks100emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks100emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks100out_layers0weight', 'model_ema.diffusion_modeloutput_blocks100out_layers0bias', 'model_ema.diffusion_modeloutput_blocks100out_layers3weight', 'model_ema.diffusion_modeloutput_blocks100out_layers3bias', 'model_ema.diffusion_modeloutput_blocks100skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks100skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks101normweight', 'model_ema.diffusion_modeloutput_blocks101normbias', 'model_ema.diffusion_modeloutput_blocks101proj_inweight', 'model_ema.diffusion_modeloutput_blocks101proj_inbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks101proj_outweight', 'model_ema.diffusion_modeloutput_blocks101proj_outbias', 'model_ema.diffusion_modeloutput_blocks110in_layers0weight', 'model_ema.diffusion_modeloutput_blocks110in_layers0bias', 'model_ema.diffusion_modeloutput_blocks110in_layers2weight', 'model_ema.diffusion_modeloutput_blocks110in_layers2bias', 'model_ema.diffusion_modeloutput_blocks110emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks110emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks110out_layers0weight', 'model_ema.diffusion_modeloutput_blocks110out_layers0bias', 'model_ema.diffusion_modeloutput_blocks110out_layers3weight', 'model_ema.diffusion_modeloutput_blocks110out_layers3bias', 'model_ema.diffusion_modeloutput_blocks110skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks110skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks111normweight', 'model_ema.diffusion_modeloutput_blocks111normbias', 'model_ema.diffusion_modeloutput_blocks111proj_inweight', 'model_ema.diffusion_modeloutput_blocks111proj_inbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks111proj_outweight', 'model_ema.diffusion_modeloutput_blocks111proj_outbias', 'model_ema.diffusion_modelout0weight', 'model_ema.diffusion_modelout0bias', 'model_ema.diffusion_modelout2weight', 'model_ema.diffusion_modelout2bias']\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/test_tube.py:104: LightningDeprecationWarning: The TestTubeLogger is deprecated since v1.5 and will be removed in v1.7. We recommend switching to the `pytorch_lightning.loggers.TensorBoardLogger` as an alternative.\n",
            "  rank_zero_deprecation(\n",
            "Monitoring val/loss_simple_ema as checkpoint metric.\n",
            "Merged modelckpt-cfg: \n",
            "{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/training2023-07-31T13-40-17_celebbasis/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/loss_simple_ema', 'save_top_k': 1, 'every_n_train_steps': 400}}\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='ddp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='ddp')` instead.\n",
            "  rank_zero_deprecation(\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "[FaceIdDataset] loaded from /content/datasets/stylegan/ffhq.pickle. (id*max_img=2*1, train2000+reg0=total2000)\n",
            "[FaceIdDataset] loaded from /content/datasets/stylegan/ffhq.pickle. (id*max_img=1*1, train1+reg0=total1)\n",
            "[FaceIdDataset] loaded from /content/datasets/stylegan/ffhq.pickle. (id*max_img=2*1, train2000+reg0=total2000)\n",
            "[FaceIdDataset] loaded from /content/datasets/stylegan/ffhq.pickle. (id*max_img=1*1, train1+reg0=total1)\n",
            "#### Data #####\n",
            "train, FaceIdDatasetOneShot, 2000\n",
            "validation, FaceIdDatasetOneShot, 1\n",
            "accumulate_grad_batches = 1\n",
            "Setting learning rate to 5.00e-03 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 1 (batchsize) * 5.00e-03 (base_lr)\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:275: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "  rank_zero_deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:284: LightningDeprecationWarning: Base `LightningModule.on_train_batch_start` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
            "  rank_zero_deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:291: LightningDeprecationWarning: Base `Callback.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
            "  rank_zero_deprecation(\n",
            "Global seed set to 23\n",
            "initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2023-07-31 13:42:43.703785: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 13:42:46.033566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Project config\n",
            "model:\n",
            "  base_learning_rate: 0.005\n",
            "  target: ldm.models.diffusion.ddpm.LatentDiffusion\n",
            "  params:\n",
            "    linear_start: 0.00085\n",
            "    linear_end: 0.012\n",
            "    num_timesteps_cond: 1\n",
            "    log_every_t: 200\n",
            "    timesteps: 1000\n",
            "    first_stage_key: image\n",
            "    cond_stage_key: caption\n",
            "    image_size: 64\n",
            "    channels: 4\n",
            "    cond_stage_trainable: true\n",
            "    conditioning_key: crossattn\n",
            "    monitor: val/loss_simple_ema\n",
            "    scale_factor: 0.18215\n",
            "    use_ema: false\n",
            "    embedding_reg_weight: 0.0\n",
            "    unfreeze_model: false\n",
            "    model_lr: 0.0\n",
            "    personalization_config:\n",
            "      target: ldm.modules.embedding_manager.EmbeddingManagerId\n",
            "      params:\n",
            "        placeholder_strings:\n",
            "        - sks\n",
            "        - ks\n",
            "        - ata\n",
            "        - tre\n",
            "        - ry\n",
            "        - bop\n",
            "        - rn\n",
            "        - '&'\n",
            "        - '*'\n",
            "        - '`'\n",
            "        initializer_words:\n",
            "        - face\n",
            "        - face\n",
            "        - face\n",
            "        - face\n",
            "        - face\n",
            "        - face\n",
            "        - face\n",
            "        - face\n",
            "        - face\n",
            "        - face\n",
            "        max_ids: 10\n",
            "        num_embeds_per_token: 2\n",
            "        meta_mlp_depth: 1\n",
            "        loss_type: none\n",
            "        meta_inner_dim: 512\n",
            "        meta_heads: 1\n",
            "        use_rm_mlp: false\n",
            "        test_mode: coefficient\n",
            "        momentum: 0.9\n",
            "        save_fp16: false\n",
            "        embedding_manager_ckpt: ''\n",
            "    unet_config:\n",
            "      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n",
            "      params:\n",
            "        image_size: 32\n",
            "        in_channels: 4\n",
            "        out_channels: 4\n",
            "        model_channels: 320\n",
            "        attention_resolutions:\n",
            "        - 4\n",
            "        - 2\n",
            "        - 1\n",
            "        num_res_blocks: 2\n",
            "        channel_mult:\n",
            "        - 1\n",
            "        - 2\n",
            "        - 4\n",
            "        - 4\n",
            "        num_heads: 8\n",
            "        use_spatial_transformer: true\n",
            "        transformer_depth: 1\n",
            "        context_dim: 768\n",
            "        use_checkpoint: true\n",
            "        legacy: false\n",
            "    first_stage_config:\n",
            "      target: ldm.models.autoencoder.AutoencoderKL\n",
            "      params:\n",
            "        embed_dim: 4\n",
            "        monitor: val/rec_loss\n",
            "        ddconfig:\n",
            "          double_z: true\n",
            "          z_channels: 4\n",
            "          resolution: 512\n",
            "          in_channels: 3\n",
            "          out_ch: 3\n",
            "          ch: 128\n",
            "          ch_mult:\n",
            "          - 1\n",
            "          - 2\n",
            "          - 4\n",
            "          - 4\n",
            "          num_res_blocks: 2\n",
            "          attn_resolutions: []\n",
            "          dropout: 0.0\n",
            "        lossconfig:\n",
            "          target: torch.nn.Identity\n",
            "    cond_stage_config:\n",
            "      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder\n",
            "      params:\n",
            "        use_celeb: true\n",
            "        use_svd: true\n",
            "        rm_repeats: true\n",
            "        celeb_txt: ./infer_images/wiki_names_v2.txt\n",
            "        n_components: 512\n",
            "        use_sample_reduce: false\n",
            "        n_samples: 513\n",
            "        use_flatten: false\n",
            "        num_embeds_per_token: 2\n",
            "    ckpt_path: ../pretrained/sd-v1-4-full-ema.ckpt\n",
            "data:\n",
            "  target: main.DataModuleFromConfig\n",
            "  params:\n",
            "    batch_size: 1\n",
            "    num_workers: 4\n",
            "    wrap: false\n",
            "    train:\n",
            "      target: ldm.data.face_id.FaceIdDatasetOneShot\n",
            "      params:\n",
            "        pickle_path: /content/datasets/stylegan/ffhq.pickle\n",
            "        split: train\n",
            "        num_ids: 2\n",
            "        specific_ids:\n",
            "        - 1\n",
            "        - 2\n",
            "        images_per_id: 1\n",
            "        repeats: 1000\n",
            "        reg_ids: 1000\n",
            "        reg_repeats: 0\n",
            "        diff_cnt: 0\n",
            "    validation:\n",
            "      target: ldm.data.face_id.FaceIdDatasetOneShot\n",
            "      params:\n",
            "        pickle_path: /content/datasets/stylegan/ffhq.pickle\n",
            "        split: val\n",
            "        num_ids: 1\n",
            "        images_per_id: 1\n",
            "        repeats: 1\n",
            "        reg_repeats: 0\n",
            "        diff_cnt: 0\n",
            "\n",
            "Lightning config\n",
            "modelcheckpoint:\n",
            "  params:\n",
            "    every_n_train_steps: 400\n",
            "callbacks:\n",
            "  image_logger:\n",
            "    target: main.ImageLogger\n",
            "    params:\n",
            "      batch_frequency: 1200\n",
            "      max_images: 8\n",
            "      increase_log_steps: false\n",
            "trainer:\n",
            "  benchmark: true\n",
            "  max_steps: 1600\n",
            "  accelerator: ddp\n",
            "  gpus: 0,\n",
            "\n",
            "\n",
            "  | Name              | Type               | Params\n",
            "---------------------------------------------------------\n",
            "0 | model             | DiffusionWrapper   | 859 M \n",
            "1 | first_stage_model | AutoencoderKL      | 83.7 M\n",
            "2 | cond_stage_model  | FrozenCLIPEmbedder | 123 M \n",
            "3 | embedding_manager | EmbeddingManagerId | 65.7 M\n",
            "---------------------------------------------------------\n",
            "65.7 M    Trainable params\n",
            "1.1 B     Non-trainable params\n",
            "1.1 B     Total params\n",
            "4,527.667 Total estimated model params size (MB)\n",
            "Validation sanity check:   0% 0/1 [00:00<?, ?it/s][Embedding Manager] test_mode: coefficient\n",
            "[Embedding Manager] test_mode: coefficient\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "Global seed set to 23\n",
            "Epoch 0:   0% 0/2001 [00:00<?, ?it/s] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:227: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
            "  warning_cache.warn(\n",
            "Epoch 0:  20% 400/2001 [02:22<09:30,  2.81it/s, loss=0.0589, v_num=0, train/loss_simple_step=0.189, train/loss_vlb_step=0.00209, train/loss_step=0.189, train/loss_emb_reg_step=0.000, global_step=399.0]    /usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:644: UserWarning: ModelCheckpoint(monitor='val/loss_simple_ema') not found in the returned metrics: ['train/loss_simple', 'train/loss_simple_step', 'train/loss_vlb', 'train/loss_vlb_step', 'train/loss', 'train/loss_step', 'train/loss_emb_reg', 'train/loss_emb_reg_step', 'global_step']. HINT: Did you call self.log('val/loss_simple_ema', value) in the LightningModule?\n",
            "  warning_cache.warn(m)\n",
            "Epoch 0, global step 399: val/loss_simple_ema was not in top 1\n",
            "Epoch 0:  40% 800/2001 [04:43<07:06,  2.82it/s, loss=0.0502, v_num=0, train/loss_simple_step=0.0133, train/loss_vlb_step=5.25e-5, train/loss_step=0.0133, train/loss_emb_reg_step=0.000, global_step=799.0] Epoch 0, global step 799: val/loss_simple_ema was not in top 1\n",
            "Epoch 0:  60% 1200/2001 [07:04<04:43,  2.82it/s, loss=0.0281, v_num=0, train/loss_simple_step=0.0963, train/loss_vlb_step=0.000835, train/loss_step=0.0963, train/loss_emb_reg_step=0.000, global_step=1199.0]Epoch 0, global step 1199: val/loss_simple_ema was not in top 1\n",
            "[Embedding Manager] test_mode: coefficient\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:04<00:00, 10.31it/s]\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:10<00:00,  4.62it/s]\n",
            "Epoch 0:  80% 1600/2001 [09:44<02:26,  2.74it/s, loss=0.0386, v_num=0, train/loss_simple_step=0.00254, train/loss_vlb_step=8.98e-6, train/loss_step=0.00254, train/loss_emb_reg_step=0.000, global_step=1599.0]Epoch 0, global step 1599: val/loss_simple_ema was not in top 1\n",
            "Average Epoch time: 584.47 seconds\n",
            "Average Peak memory 14144.27MiB\n",
            "Epoch 0:  81% 1620/2001 [09:44<02:17,  2.77it/s, loss=0.0386, v_num=0, train/loss_simple_step=0.00254, train/loss_vlb_step=8.98e-6, train/loss_step=0.00254, train/loss_emb_reg_step=0.000, global_step=1599.0, train/loss_simple_epoch=0.0443, train/loss_vlb_epoch=0.000883, train/loss_epoch=0.0443, train/loss_emb_reg_epoch=0.000]\n",
            "Saving latest checkpoint...\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CelebBasis/main_id_embed.py\", line 817, in <module>\n",
            "    trainer.test(model, data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 911, in test\n",
            "    return self._call_and_handle_interrupt(self._test_impl, model, dataloaders, ckpt_path, verbose, datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 954, in _test_impl\n",
            "    results = self._run(model, ckpt_path=self.tested_ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1128, in _run\n",
            "    verify_loop_configurations(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py\", line 42, in verify_loop_configurations\n",
            "    __verify_eval_loop_configuration(trainer, model, \"test\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py\", line 186, in __verify_eval_loop_configuration\n",
            "    raise MisconfigurationException(f\"No `{loader_name}()` method defined to run `Trainer.{trainer_method}`.\")\n",
            "pytorch_lightning.utilities.exceptions.MisconfigurationException: No `test_dataloader()` method defined to run `Trainer.test`.\n"
          ]
        }
      ],
      "source": [
        "!cd CelebBasis && bash ./01_start_train.sh ../pretrained/sd-v1-4-full-ema.ckpt ./configs/stable-diffusion/aigc_id_colab.yaml"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kujKlKN0E9qI",
        "outputId": "c62a0a7b-b0bc-473e-fd6a-23b12ce1acb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Test\n",
        "Modify the following `\"trainingYYYY-MM-DDTHH-MM-SS_celebbasis/\"` to the project folder under `./CelebBasis/logs/` and run the test."
      ],
      "metadata": {
        "collapsed": false,
        "id": "IICWVjl4E9qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Choose a project folder from the following list:  { display-mode: \"form\" }\n",
        "\n",
        "print('=' * 10, ' Choose a project folder from the following list ', '=' * 10)\n",
        "!ls -hlrt ./CelebBasis/logs/"
      ],
      "metadata": {
        "id": "eaNDaKm6SuMM",
        "outputId": "976e4c6c-b568-4681-b887-78dd95f3818a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========  Choose a project folder from the following list  ==========\n",
            "total 4.0K\n",
            "drwxr-xr-x 6 root root 4.0K Jul 31 13:50 training2023-07-31T13-40-17_celebbasis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========  testing  ==========\n",
            "logs/training2023-07-31T13-40-17_celebbasis/configs/training2023-07-31T13-40-17-project.yaml\n",
            "embeddings_gs-799.pt\n",
            "Global seed set to 42\n",
            "Loading model from ../pretrained/sd-v1-4-full-ema.ckpt\n",
            "Global Step: 470000\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'logit_scale', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'text_projection.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'visual_projection.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[celebs cols_embeddings len]: [646, 638, 311, 118, 25, 2]\n",
            "[(col_0) celebs ori]: torch.Size([646, 768]) tensor(5.3118e-05) tensor(-0.0405) tensor(0.0509)\n",
            "[(col_0) celebs c_mean]: tensor(-1.2509e-05) tensor(-0.0091) tensor(0.0112)\n",
            "[(col_0) celebs pca_base]: torch.Size([512, 768]) tensor(-0.0003) tensor(-0.1054) tensor(0.0999) tensor(1.0000)\n",
            "[(col_0) celebs embeddings loaded]: torch.Size([513, 768]) (device:cuda)\n",
            "[(col_1) celebs ori]: torch.Size([638, 768]) tensor(-9.8908e-06) tensor(-0.0414) tensor(0.0464)\n",
            "[(col_1) celebs c_mean]: tensor(-3.7355e-06) tensor(-0.0087) tensor(0.0065)\n",
            "[(col_1) celebs pca_base]: torch.Size([512, 768]) tensor(1.3023e-05) tensor(-0.1589) tensor(0.2419) tensor(1.)\n",
            "[(col_1) celebs embeddings loaded]: torch.Size([513, 768]) (device:cuda)\n",
            "[all celebs embeddings loaded] shape = torch.Size([2, 513, 768]) (device:cuda) flatten=False\n",
            "Restored from ../pretrained/sd-v1-4-full-ema.ckpt with 0 missing and 688 unexpected keys\n",
            "Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'model_ema.diffusion_modeltime_embed0weight', 'model_ema.diffusion_modeltime_embed0bias', 'model_ema.diffusion_modeltime_embed2weight', 'model_ema.diffusion_modeltime_embed2bias', 'model_ema.diffusion_modelinput_blocks00weight', 'model_ema.diffusion_modelinput_blocks00bias', 'model_ema.diffusion_modelinput_blocks10in_layers0weight', 'model_ema.diffusion_modelinput_blocks10in_layers0bias', 'model_ema.diffusion_modelinput_blocks10in_layers2weight', 'model_ema.diffusion_modelinput_blocks10in_layers2bias', 'model_ema.diffusion_modelinput_blocks10emb_layers1weight', 'model_ema.diffusion_modelinput_blocks10emb_layers1bias', 'model_ema.diffusion_modelinput_blocks10out_layers0weight', 'model_ema.diffusion_modelinput_blocks10out_layers0bias', 'model_ema.diffusion_modelinput_blocks10out_layers3weight', 'model_ema.diffusion_modelinput_blocks10out_layers3bias', 'model_ema.diffusion_modelinput_blocks11normweight', 'model_ema.diffusion_modelinput_blocks11normbias', 'model_ema.diffusion_modelinput_blocks11proj_inweight', 'model_ema.diffusion_modelinput_blocks11proj_inbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks11proj_outweight', 'model_ema.diffusion_modelinput_blocks11proj_outbias', 'model_ema.diffusion_modelinput_blocks20in_layers0weight', 'model_ema.diffusion_modelinput_blocks20in_layers0bias', 'model_ema.diffusion_modelinput_blocks20in_layers2weight', 'model_ema.diffusion_modelinput_blocks20in_layers2bias', 'model_ema.diffusion_modelinput_blocks20emb_layers1weight', 'model_ema.diffusion_modelinput_blocks20emb_layers1bias', 'model_ema.diffusion_modelinput_blocks20out_layers0weight', 'model_ema.diffusion_modelinput_blocks20out_layers0bias', 'model_ema.diffusion_modelinput_blocks20out_layers3weight', 'model_ema.diffusion_modelinput_blocks20out_layers3bias', 'model_ema.diffusion_modelinput_blocks21normweight', 'model_ema.diffusion_modelinput_blocks21normbias', 'model_ema.diffusion_modelinput_blocks21proj_inweight', 'model_ema.diffusion_modelinput_blocks21proj_inbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks21proj_outweight', 'model_ema.diffusion_modelinput_blocks21proj_outbias', 'model_ema.diffusion_modelinput_blocks30opweight', 'model_ema.diffusion_modelinput_blocks30opbias', 'model_ema.diffusion_modelinput_blocks40in_layers0weight', 'model_ema.diffusion_modelinput_blocks40in_layers0bias', 'model_ema.diffusion_modelinput_blocks40in_layers2weight', 'model_ema.diffusion_modelinput_blocks40in_layers2bias', 'model_ema.diffusion_modelinput_blocks40emb_layers1weight', 'model_ema.diffusion_modelinput_blocks40emb_layers1bias', 'model_ema.diffusion_modelinput_blocks40out_layers0weight', 'model_ema.diffusion_modelinput_blocks40out_layers0bias', 'model_ema.diffusion_modelinput_blocks40out_layers3weight', 'model_ema.diffusion_modelinput_blocks40out_layers3bias', 'model_ema.diffusion_modelinput_blocks40skip_connectionweight', 'model_ema.diffusion_modelinput_blocks40skip_connectionbias', 'model_ema.diffusion_modelinput_blocks41normweight', 'model_ema.diffusion_modelinput_blocks41normbias', 'model_ema.diffusion_modelinput_blocks41proj_inweight', 'model_ema.diffusion_modelinput_blocks41proj_inbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks41proj_outweight', 'model_ema.diffusion_modelinput_blocks41proj_outbias', 'model_ema.diffusion_modelinput_blocks50in_layers0weight', 'model_ema.diffusion_modelinput_blocks50in_layers0bias', 'model_ema.diffusion_modelinput_blocks50in_layers2weight', 'model_ema.diffusion_modelinput_blocks50in_layers2bias', 'model_ema.diffusion_modelinput_blocks50emb_layers1weight', 'model_ema.diffusion_modelinput_blocks50emb_layers1bias', 'model_ema.diffusion_modelinput_blocks50out_layers0weight', 'model_ema.diffusion_modelinput_blocks50out_layers0bias', 'model_ema.diffusion_modelinput_blocks50out_layers3weight', 'model_ema.diffusion_modelinput_blocks50out_layers3bias', 'model_ema.diffusion_modelinput_blocks51normweight', 'model_ema.diffusion_modelinput_blocks51normbias', 'model_ema.diffusion_modelinput_blocks51proj_inweight', 'model_ema.diffusion_modelinput_blocks51proj_inbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks51proj_outweight', 'model_ema.diffusion_modelinput_blocks51proj_outbias', 'model_ema.diffusion_modelinput_blocks60opweight', 'model_ema.diffusion_modelinput_blocks60opbias', 'model_ema.diffusion_modelinput_blocks70in_layers0weight', 'model_ema.diffusion_modelinput_blocks70in_layers0bias', 'model_ema.diffusion_modelinput_blocks70in_layers2weight', 'model_ema.diffusion_modelinput_blocks70in_layers2bias', 'model_ema.diffusion_modelinput_blocks70emb_layers1weight', 'model_ema.diffusion_modelinput_blocks70emb_layers1bias', 'model_ema.diffusion_modelinput_blocks70out_layers0weight', 'model_ema.diffusion_modelinput_blocks70out_layers0bias', 'model_ema.diffusion_modelinput_blocks70out_layers3weight', 'model_ema.diffusion_modelinput_blocks70out_layers3bias', 'model_ema.diffusion_modelinput_blocks70skip_connectionweight', 'model_ema.diffusion_modelinput_blocks70skip_connectionbias', 'model_ema.diffusion_modelinput_blocks71normweight', 'model_ema.diffusion_modelinput_blocks71normbias', 'model_ema.diffusion_modelinput_blocks71proj_inweight', 'model_ema.diffusion_modelinput_blocks71proj_inbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks71proj_outweight', 'model_ema.diffusion_modelinput_blocks71proj_outbias', 'model_ema.diffusion_modelinput_blocks80in_layers0weight', 'model_ema.diffusion_modelinput_blocks80in_layers0bias', 'model_ema.diffusion_modelinput_blocks80in_layers2weight', 'model_ema.diffusion_modelinput_blocks80in_layers2bias', 'model_ema.diffusion_modelinput_blocks80emb_layers1weight', 'model_ema.diffusion_modelinput_blocks80emb_layers1bias', 'model_ema.diffusion_modelinput_blocks80out_layers0weight', 'model_ema.diffusion_modelinput_blocks80out_layers0bias', 'model_ema.diffusion_modelinput_blocks80out_layers3weight', 'model_ema.diffusion_modelinput_blocks80out_layers3bias', 'model_ema.diffusion_modelinput_blocks81normweight', 'model_ema.diffusion_modelinput_blocks81normbias', 'model_ema.diffusion_modelinput_blocks81proj_inweight', 'model_ema.diffusion_modelinput_blocks81proj_inbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks81proj_outweight', 'model_ema.diffusion_modelinput_blocks81proj_outbias', 'model_ema.diffusion_modelinput_blocks90opweight', 'model_ema.diffusion_modelinput_blocks90opbias', 'model_ema.diffusion_modelinput_blocks100in_layers0weight', 'model_ema.diffusion_modelinput_blocks100in_layers0bias', 'model_ema.diffusion_modelinput_blocks100in_layers2weight', 'model_ema.diffusion_modelinput_blocks100in_layers2bias', 'model_ema.diffusion_modelinput_blocks100emb_layers1weight', 'model_ema.diffusion_modelinput_blocks100emb_layers1bias', 'model_ema.diffusion_modelinput_blocks100out_layers0weight', 'model_ema.diffusion_modelinput_blocks100out_layers0bias', 'model_ema.diffusion_modelinput_blocks100out_layers3weight', 'model_ema.diffusion_modelinput_blocks100out_layers3bias', 'model_ema.diffusion_modelinput_blocks110in_layers0weight', 'model_ema.diffusion_modelinput_blocks110in_layers0bias', 'model_ema.diffusion_modelinput_blocks110in_layers2weight', 'model_ema.diffusion_modelinput_blocks110in_layers2bias', 'model_ema.diffusion_modelinput_blocks110emb_layers1weight', 'model_ema.diffusion_modelinput_blocks110emb_layers1bias', 'model_ema.diffusion_modelinput_blocks110out_layers0weight', 'model_ema.diffusion_modelinput_blocks110out_layers0bias', 'model_ema.diffusion_modelinput_blocks110out_layers3weight', 'model_ema.diffusion_modelinput_blocks110out_layers3bias', 'model_ema.diffusion_modelmiddle_block0in_layers0weight', 'model_ema.diffusion_modelmiddle_block0in_layers0bias', 'model_ema.diffusion_modelmiddle_block0in_layers2weight', 'model_ema.diffusion_modelmiddle_block0in_layers2bias', 'model_ema.diffusion_modelmiddle_block0emb_layers1weight', 'model_ema.diffusion_modelmiddle_block0emb_layers1bias', 'model_ema.diffusion_modelmiddle_block0out_layers0weight', 'model_ema.diffusion_modelmiddle_block0out_layers0bias', 'model_ema.diffusion_modelmiddle_block0out_layers3weight', 'model_ema.diffusion_modelmiddle_block0out_layers3bias', 'model_ema.diffusion_modelmiddle_block1normweight', 'model_ema.diffusion_modelmiddle_block1normbias', 'model_ema.diffusion_modelmiddle_block1proj_inweight', 'model_ema.diffusion_modelmiddle_block1proj_inbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3bias', 'model_ema.diffusion_modelmiddle_block1proj_outweight', 'model_ema.diffusion_modelmiddle_block1proj_outbias', 'model_ema.diffusion_modelmiddle_block2in_layers0weight', 'model_ema.diffusion_modelmiddle_block2in_layers0bias', 'model_ema.diffusion_modelmiddle_block2in_layers2weight', 'model_ema.diffusion_modelmiddle_block2in_layers2bias', 'model_ema.diffusion_modelmiddle_block2emb_layers1weight', 'model_ema.diffusion_modelmiddle_block2emb_layers1bias', 'model_ema.diffusion_modelmiddle_block2out_layers0weight', 'model_ema.diffusion_modelmiddle_block2out_layers0bias', 'model_ema.diffusion_modelmiddle_block2out_layers3weight', 'model_ema.diffusion_modelmiddle_block2out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00in_layers0weight', 'model_ema.diffusion_modeloutput_blocks00in_layers0bias', 'model_ema.diffusion_modeloutput_blocks00in_layers2weight', 'model_ema.diffusion_modeloutput_blocks00in_layers2bias', 'model_ema.diffusion_modeloutput_blocks00emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks00emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks00out_layers0weight', 'model_ema.diffusion_modeloutput_blocks00out_layers0bias', 'model_ema.diffusion_modeloutput_blocks00out_layers3weight', 'model_ema.diffusion_modeloutput_blocks00out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks00skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks10in_layers0weight', 'model_ema.diffusion_modeloutput_blocks10in_layers0bias', 'model_ema.diffusion_modeloutput_blocks10in_layers2weight', 'model_ema.diffusion_modeloutput_blocks10in_layers2bias', 'model_ema.diffusion_modeloutput_blocks10emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks10emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks10out_layers0weight', 'model_ema.diffusion_modeloutput_blocks10out_layers0bias', 'model_ema.diffusion_modeloutput_blocks10out_layers3weight', 'model_ema.diffusion_modeloutput_blocks10out_layers3bias', 'model_ema.diffusion_modeloutput_blocks10skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks10skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks20in_layers0weight', 'model_ema.diffusion_modeloutput_blocks20in_layers0bias', 'model_ema.diffusion_modeloutput_blocks20in_layers2weight', 'model_ema.diffusion_modeloutput_blocks20in_layers2bias', 'model_ema.diffusion_modeloutput_blocks20emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks20emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks20out_layers0weight', 'model_ema.diffusion_modeloutput_blocks20out_layers0bias', 'model_ema.diffusion_modeloutput_blocks20out_layers3weight', 'model_ema.diffusion_modeloutput_blocks20out_layers3bias', 'model_ema.diffusion_modeloutput_blocks20skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks20skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks21convweight', 'model_ema.diffusion_modeloutput_blocks21convbias', 'model_ema.diffusion_modeloutput_blocks30in_layers0weight', 'model_ema.diffusion_modeloutput_blocks30in_layers0bias', 'model_ema.diffusion_modeloutput_blocks30in_layers2weight', 'model_ema.diffusion_modeloutput_blocks30in_layers2bias', 'model_ema.diffusion_modeloutput_blocks30emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks30emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks30out_layers0weight', 'model_ema.diffusion_modeloutput_blocks30out_layers0bias', 'model_ema.diffusion_modeloutput_blocks30out_layers3weight', 'model_ema.diffusion_modeloutput_blocks30out_layers3bias', 'model_ema.diffusion_modeloutput_blocks30skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks30skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks31normweight', 'model_ema.diffusion_modeloutput_blocks31normbias', 'model_ema.diffusion_modeloutput_blocks31proj_inweight', 'model_ema.diffusion_modeloutput_blocks31proj_inbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks31proj_outweight', 'model_ema.diffusion_modeloutput_blocks31proj_outbias', 'model_ema.diffusion_modeloutput_blocks40in_layers0weight', 'model_ema.diffusion_modeloutput_blocks40in_layers0bias', 'model_ema.diffusion_modeloutput_blocks40in_layers2weight', 'model_ema.diffusion_modeloutput_blocks40in_layers2bias', 'model_ema.diffusion_modeloutput_blocks40emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks40emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks40out_layers0weight', 'model_ema.diffusion_modeloutput_blocks40out_layers0bias', 'model_ema.diffusion_modeloutput_blocks40out_layers3weight', 'model_ema.diffusion_modeloutput_blocks40out_layers3bias', 'model_ema.diffusion_modeloutput_blocks40skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks40skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks41normweight', 'model_ema.diffusion_modeloutput_blocks41normbias', 'model_ema.diffusion_modeloutput_blocks41proj_inweight', 'model_ema.diffusion_modeloutput_blocks41proj_inbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks41proj_outweight', 'model_ema.diffusion_modeloutput_blocks41proj_outbias', 'model_ema.diffusion_modeloutput_blocks50in_layers0weight', 'model_ema.diffusion_modeloutput_blocks50in_layers0bias', 'model_ema.diffusion_modeloutput_blocks50in_layers2weight', 'model_ema.diffusion_modeloutput_blocks50in_layers2bias', 'model_ema.diffusion_modeloutput_blocks50emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks50emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks50out_layers0weight', 'model_ema.diffusion_modeloutput_blocks50out_layers0bias', 'model_ema.diffusion_modeloutput_blocks50out_layers3weight', 'model_ema.diffusion_modeloutput_blocks50out_layers3bias', 'model_ema.diffusion_modeloutput_blocks50skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks50skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks51normweight', 'model_ema.diffusion_modeloutput_blocks51normbias', 'model_ema.diffusion_modeloutput_blocks51proj_inweight', 'model_ema.diffusion_modeloutput_blocks51proj_inbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks51proj_outweight', 'model_ema.diffusion_modeloutput_blocks51proj_outbias', 'model_ema.diffusion_modeloutput_blocks52convweight', 'model_ema.diffusion_modeloutput_blocks52convbias', 'model_ema.diffusion_modeloutput_blocks60in_layers0weight', 'model_ema.diffusion_modeloutput_blocks60in_layers0bias', 'model_ema.diffusion_modeloutput_blocks60in_layers2weight', 'model_ema.diffusion_modeloutput_blocks60in_layers2bias', 'model_ema.diffusion_modeloutput_blocks60emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks60emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks60out_layers0weight', 'model_ema.diffusion_modeloutput_blocks60out_layers0bias', 'model_ema.diffusion_modeloutput_blocks60out_layers3weight', 'model_ema.diffusion_modeloutput_blocks60out_layers3bias', 'model_ema.diffusion_modeloutput_blocks60skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks60skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks61normweight', 'model_ema.diffusion_modeloutput_blocks61normbias', 'model_ema.diffusion_modeloutput_blocks61proj_inweight', 'model_ema.diffusion_modeloutput_blocks61proj_inbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks61proj_outweight', 'model_ema.diffusion_modeloutput_blocks61proj_outbias', 'model_ema.diffusion_modeloutput_blocks70in_layers0weight', 'model_ema.diffusion_modeloutput_blocks70in_layers0bias', 'model_ema.diffusion_modeloutput_blocks70in_layers2weight', 'model_ema.diffusion_modeloutput_blocks70in_layers2bias', 'model_ema.diffusion_modeloutput_blocks70emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks70emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks70out_layers0weight', 'model_ema.diffusion_modeloutput_blocks70out_layers0bias', 'model_ema.diffusion_modeloutput_blocks70out_layers3weight', 'model_ema.diffusion_modeloutput_blocks70out_layers3bias', 'model_ema.diffusion_modeloutput_blocks70skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks70skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks71normweight', 'model_ema.diffusion_modeloutput_blocks71normbias', 'model_ema.diffusion_modeloutput_blocks71proj_inweight', 'model_ema.diffusion_modeloutput_blocks71proj_inbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks71proj_outweight', 'model_ema.diffusion_modeloutput_blocks71proj_outbias', 'model_ema.diffusion_modeloutput_blocks80in_layers0weight', 'model_ema.diffusion_modeloutput_blocks80in_layers0bias', 'model_ema.diffusion_modeloutput_blocks80in_layers2weight', 'model_ema.diffusion_modeloutput_blocks80in_layers2bias', 'model_ema.diffusion_modeloutput_blocks80emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks80emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks80out_layers0weight', 'model_ema.diffusion_modeloutput_blocks80out_layers0bias', 'model_ema.diffusion_modeloutput_blocks80out_layers3weight', 'model_ema.diffusion_modeloutput_blocks80out_layers3bias', 'model_ema.diffusion_modeloutput_blocks80skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks80skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks81normweight', 'model_ema.diffusion_modeloutput_blocks81normbias', 'model_ema.diffusion_modeloutput_blocks81proj_inweight', 'model_ema.diffusion_modeloutput_blocks81proj_inbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks81proj_outweight', 'model_ema.diffusion_modeloutput_blocks81proj_outbias', 'model_ema.diffusion_modeloutput_blocks82convweight', 'model_ema.diffusion_modeloutput_blocks82convbias', 'model_ema.diffusion_modeloutput_blocks90in_layers0weight', 'model_ema.diffusion_modeloutput_blocks90in_layers0bias', 'model_ema.diffusion_modeloutput_blocks90in_layers2weight', 'model_ema.diffusion_modeloutput_blocks90in_layers2bias', 'model_ema.diffusion_modeloutput_blocks90emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks90emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks90out_layers0weight', 'model_ema.diffusion_modeloutput_blocks90out_layers0bias', 'model_ema.diffusion_modeloutput_blocks90out_layers3weight', 'model_ema.diffusion_modeloutput_blocks90out_layers3bias', 'model_ema.diffusion_modeloutput_blocks90skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks90skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks91normweight', 'model_ema.diffusion_modeloutput_blocks91normbias', 'model_ema.diffusion_modeloutput_blocks91proj_inweight', 'model_ema.diffusion_modeloutput_blocks91proj_inbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks91proj_outweight', 'model_ema.diffusion_modeloutput_blocks91proj_outbias', 'model_ema.diffusion_modeloutput_blocks100in_layers0weight', 'model_ema.diffusion_modeloutput_blocks100in_layers0bias', 'model_ema.diffusion_modeloutput_blocks100in_layers2weight', 'model_ema.diffusion_modeloutput_blocks100in_layers2bias', 'model_ema.diffusion_modeloutput_blocks100emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks100emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks100out_layers0weight', 'model_ema.diffusion_modeloutput_blocks100out_layers0bias', 'model_ema.diffusion_modeloutput_blocks100out_layers3weight', 'model_ema.diffusion_modeloutput_blocks100out_layers3bias', 'model_ema.diffusion_modeloutput_blocks100skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks100skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks101normweight', 'model_ema.diffusion_modeloutput_blocks101normbias', 'model_ema.diffusion_modeloutput_blocks101proj_inweight', 'model_ema.diffusion_modeloutput_blocks101proj_inbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks101proj_outweight', 'model_ema.diffusion_modeloutput_blocks101proj_outbias', 'model_ema.diffusion_modeloutput_blocks110in_layers0weight', 'model_ema.diffusion_modeloutput_blocks110in_layers0bias', 'model_ema.diffusion_modeloutput_blocks110in_layers2weight', 'model_ema.diffusion_modeloutput_blocks110in_layers2bias', 'model_ema.diffusion_modeloutput_blocks110emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks110emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks110out_layers0weight', 'model_ema.diffusion_modeloutput_blocks110out_layers0bias', 'model_ema.diffusion_modeloutput_blocks110out_layers3weight', 'model_ema.diffusion_modeloutput_blocks110out_layers3bias', 'model_ema.diffusion_modeloutput_blocks110skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks110skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks111normweight', 'model_ema.diffusion_modeloutput_blocks111normbias', 'model_ema.diffusion_modeloutput_blocks111proj_inweight', 'model_ema.diffusion_modeloutput_blocks111proj_inbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks111proj_outweight', 'model_ema.diffusion_modeloutput_blocks111proj_outbias', 'model_ema.diffusion_modelout0weight', 'model_ema.diffusion_modelout0bias', 'model_ema.diffusion_modelout2weight', 'model_ema.diffusion_modelout2bias']\n",
            "[Embedding Manager] weights loaded.\n",
            "reading prompts from ./infer_images/example_prompt.txt\n",
            "Sampling:   0% 0/1 [00:00<?, ?it/s]\n",
            "data:   0% 0/9 [00:00<?, ?it/s]\u001b[A[Embedding Manager] test_mode: coefficient\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.15it/s]\n",
            "\n",
            "data:  11% 1/9 [00:17<02:19, 17.42s/it]\u001b[A[Embedding Manager] test_mode: coefficient\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.19it/s]\n",
            "\n",
            "data:  22% 2/9 [00:33<01:56, 16.68s/it]\u001b[A[Embedding Manager] test_mode: coefficient\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.18it/s]\n",
            "\n",
            "data:  33% 3/9 [00:49<01:38, 16.45s/it]\u001b[A[Embedding Manager] test_mode: coefficient\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.18it/s]\n",
            "\n",
            "data:  44% 4/9 [01:05<01:21, 16.34s/it]\u001b[A[Embedding Manager] test_mode: coefficient\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.18it/s]\n",
            "\n",
            "data:  56% 5/9 [01:22<01:05, 16.28s/it]\u001b[A[Embedding Manager] test_mode: coefficient\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.18it/s]\n",
            "\n",
            "data:  67% 6/9 [01:38<00:48, 16.25s/it]\u001b[A[Embedding Manager] test_mode: coefficient\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.18it/s]\n",
            "\n",
            "data:  78% 7/9 [01:54<00:32, 16.23s/it]\u001b[A[Embedding Manager] test_mode: coefficient\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.18it/s]\n",
            "\n",
            "data:  89% 8/9 [02:10<00:16, 16.22s/it]\u001b[A[Embedding Manager] test_mode: coefficient\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.18it/s]\n",
            "\n",
            "data: 100% 9/9 [02:26<00:00, 16.32s/it]\n",
            "Sampling: 100% 1/1 [02:26<00:00, 146.86s/it]\n",
            "Your samples are ready and waiting for you here: \n",
            "outputs/training2023-07-31T13-40-17_celebbasis \n",
            " \n",
            "Enjoy.\n"
          ]
        }
      ],
      "source": [
        "# @title Choose your project folder to be tested: { display-mode: \"form\" }\n",
        "\n",
        "project_folder = \"trainingYYYY-MM-DDTHH-MM-SS_celebbasis/\" # @param\n",
        "prompt_file = \"./infer_images/example_prompt.txt\"  # @param\n",
        "batch_size = 4 # @param\n",
        "\n",
        "print('=' * 10, ' testing ', '=' * 10)\n",
        "!cd CelebBasis && bash ./02_start_test.sh \"../pretrained/sd-v1-4-full-ema.ckpt\" $prompt_file $project_folder $batch_size"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5xRY9FTME9qI",
        "outputId": "125ddbc6-9e97-44b4-a426-bf9916386649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generated images will be output under `./CelebBasis/outputs/trainingYYYY-MM-DDTHH-MM-SS_celebbasis/`. Enjoy it!"
      ],
      "metadata": {
        "id": "WveTESaiTs35"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul 31 13:25:55 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    29W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "d4nHYT2HE9qI",
        "outputId": "0d1b03c2-3ef2-4346-a4a6-5480a4c6625b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}