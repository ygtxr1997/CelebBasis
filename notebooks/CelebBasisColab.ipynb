{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6ybk9OgWB9I"
   },
   "source": [
    "---\n",
    "#1. Preparation\n",
    "##1.1 Download Stable-Diffusion Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awpo9c61ZEPR",
    "outputId": "d4460bd1-e560-4aa8-ecd3-b1c987eb5980"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-07-14 12:58:01--  https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4-full-ema.ckpt\n",
      "Resolving huggingface.co (huggingface.co)... 13.35.166.36, 13.35.166.50, 13.35.166.114, ...\n",
      "Connecting to huggingface.co (huggingface.co)|13.35.166.36|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/4c/37/4c372b4ebb57bbd02e68413d4951aa326d4b3cfb6e62db989e529c6d4b26fb21/14749efc0ae8ef0329391ad4436feb781b402f4fece4883c7ad8d10556d8a36a?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd-v1-4-full-ema.ckpt%3B+filename%3D%22sd-v1-4-full-ema.ckpt%22%3B&Expires=1689598681&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY4OTU5ODY4MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy80Yy8zNy80YzM3MmI0ZWJiNTdiYmQwMmU2ODQxM2Q0OTUxYWEzMjZkNGIzY2ZiNmU2MmRiOTg5ZTUyOWM2ZDRiMjZmYjIxLzE0NzQ5ZWZjMGFlOGVmMDMyOTM5MWFkNDQzNmZlYjc4MWI0MDJmNGZlY2U0ODgzYzdhZDhkMTA1NTZkOGEzNmE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=F7uaWUhLdvYpdUDVVega7qLTdxQJ6FKw5DE0BbYLWaNepf1TXjrCKjoa92DAEFrGrA%7EYdCXY01a1cvOz8szvyvtEnTsyI%7EAF2ZQs0wXn5IFE1PbBCKvgMT9zC8lNCtvrDuSKSWeMMYFBtWB7iJx-XViWo27GAMn6ygpuZTYipZpVkrRg6XioJMBdzvbwpvpoip8Tikr0BykLj%7EQKPQK4WEcjG0DKLvAbfgJhy-lK%7EWYv8zD-VpkxR1sdJjcC6R4UBkc-Y52QS9QOTxOzHCQAB8RotKxzmvoEfAzOx0OuELEe5kbEVmK-mhUefKM-eO2fyP8KZKSxRHDZIU9oDHW%7ENw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-07-14 12:58:01--  https://cdn-lfs.huggingface.co/repos/4c/37/4c372b4ebb57bbd02e68413d4951aa326d4b3cfb6e62db989e529c6d4b26fb21/14749efc0ae8ef0329391ad4436feb781b402f4fece4883c7ad8d10556d8a36a?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd-v1-4-full-ema.ckpt%3B+filename%3D%22sd-v1-4-full-ema.ckpt%22%3B&Expires=1689598681&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY4OTU5ODY4MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy80Yy8zNy80YzM3MmI0ZWJiNTdiYmQwMmU2ODQxM2Q0OTUxYWEzMjZkNGIzY2ZiNmU2MmRiOTg5ZTUyOWM2ZDRiMjZmYjIxLzE0NzQ5ZWZjMGFlOGVmMDMyOTM5MWFkNDQzNmZlYjc4MWI0MDJmNGZlY2U0ODgzYzdhZDhkMTA1NTZkOGEzNmE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=F7uaWUhLdvYpdUDVVega7qLTdxQJ6FKw5DE0BbYLWaNepf1TXjrCKjoa92DAEFrGrA%7EYdCXY01a1cvOz8szvyvtEnTsyI%7EAF2ZQs0wXn5IFE1PbBCKvgMT9zC8lNCtvrDuSKSWeMMYFBtWB7iJx-XViWo27GAMn6ygpuZTYipZpVkrRg6XioJMBdzvbwpvpoip8Tikr0BykLj%7EQKPQK4WEcjG0DKLvAbfgJhy-lK%7EWYv8zD-VpkxR1sdJjcC6R4UBkc-Y52QS9QOTxOzHCQAB8RotKxzmvoEfAzOx0OuELEe5kbEVmK-mhUefKM-eO2fyP8KZKSxRHDZIU9oDHW%7ENw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.35.7.113, 13.35.7.14, 13.35.7.93, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.35.7.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7703807346 (7.2G) [binary/octet-stream]\n",
      "Saving to: ‘sd-v1-4-full-ema.ckpt’\n",
      "\n",
      "sd-v1-4-full-ema.ck 100%[===================>]   7.17G   239MB/s    in 30s     \n",
      "\n",
      "2023-07-14 12:58:31 (245 MB/s) - ‘sd-v1-4-full-ema.ckpt’ saved [7703807346/7703807346]\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "%%shell\n",
    "mkdir -p pretrained/\n",
    "cd pretrained/\n",
    "wget https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4-full-ema.ckpt\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##1.2 Clone CelebBasis Code from [GitHub](https://github.com/ygtxr1997/CelebBasis/tree/main)"
   ],
   "metadata": {
    "id": "y36ZS6Ulf-MB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taP55D4-TbI0",
    "outputId": "9d73b23e-8f11-413a-fb8f-91a33968b06c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'CelebBasis'...\n",
      "remote: Enumerating objects: 764, done.\u001B[K\n",
      "remote: Counting objects: 100% (764/764), done.\u001B[K\n",
      "remote: Compressing objects: 100% (620/620), done.\u001B[K\n",
      "remote: Total 764 (delta 113), reused 723 (delta 90), pack-reused 0\u001B[K\n",
      "Receiving objects: 100% (764/764), 16.79 MiB | 11.90 MiB/s, done.\n",
      "Resolving deltas: 100% (113/113), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ygtxr1997/CelebBasis.git"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##1.3 Copy StyleGAN Datasets and Third-Party Pretrained Weights from Your Own Google Drive\n",
    "You should first copy [CelebBasis Google Drive](https://drive.google.com/drive/folders/181pJ3Y2Ffk0R8jVcErPT611aWQLCz7D9?usp=sharing) to your own [Google Drive](https://drive.google.com/drive/my-drive).\n",
    "The Google Drive directory tree will be like:\n",
    "```shell\n",
    "My Drive/\n",
    " |--CelebBasis/\n",
    "  |--datasets/\n",
    "  |--pretrained/\n",
    "```\n",
    "Then, the following cell mounts your own Google Drive to this Colab Notebook and copies the datasets and weights files from the mounted folder."
   ],
   "metadata": {
    "id": "qEGnri5fgOuN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ww0rv6vBMPmz",
    "outputId": "d8292916-82d0-4e1f-ca4f-34b5dd439394"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!cp -r /content/drive/MyDrive/CelebBasis/datasets/ ./\n",
    "!cp -r /content/drive/MyDrive/CelebBasis/pretrained/* ./pretrained/\n",
    "drive.flush_and_unmount()\n",
    "!cd ./datasets && tar -xf stylegan.tar && rm stylegan.tar\n",
    "!cp ./pretrained/PIPNet/* ./CelebBasis/evaluation/face_align/PIPNet/weights\n",
    "!mkdir -p ./CelebBasis/weights/\n",
    "!cp -r ./pretrained/glint360k_cosface_r100_fp16_0.1/ ./CelebBasis/weights/"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Use PIP to Install the Python Dependencies and Uninstall the Needless Modules (which are preinstalled by Google Colab but not used)"
   ],
   "metadata": {
    "id": "BLUapspVi1nN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKrlQ_s2VH92",
    "outputId": "22eec1d1-2fcf-4a02-f307-e6bb242ed488"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Obtaining clip from git+https://github.com/openai/CLIP.git@a1d071733d7111c9c014f024669f959182114e33#egg=clip (from -r ../CelebBasis/requirements.txt (line 18))\n",
      "  Cloning https://github.com/openai/CLIP.git (to revision a1d071733d7111c9c014f024669f959182114e33) to ./src/clip\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /content/pip_installed/src/clip\n",
      "  Running command git rev-parse -q --verify 'sha^a1d071733d7111c9c014f024669f959182114e33'\n",
      "  Running command git fetch -q https://github.com/openai/CLIP.git a1d071733d7111c9c014f024669f959182114e33\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Obtaining taming_transformers from git+https://github.com/CompVis/taming-transformers.git@3ba01b241669f5ade541ce990f7650a3b8f65318#egg=taming_transformers (from -r ../CelebBasis/requirements.txt (line 141))\n",
      "  Cloning https://github.com/CompVis/taming-transformers.git (to revision 3ba01b241669f5ade541ce990f7650a3b8f65318) to ./src/taming-transformers\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/CompVis/taming-transformers.git /content/pip_installed/src/taming-transformers\n",
      "  Running command git rev-parse -q --verify 'sha^3ba01b241669f5ade541ce990f7650a3b8f65318'\n",
      "  Running command git fetch -q https://github.com/CompVis/taming-transformers.git 3ba01b241669f5ade541ce990f7650a3b8f65318\n",
      "  Resolved https://github.com/CompVis/taming-transformers.git to commit 3ba01b241669f5ade541ce990f7650a3b8f65318\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting absl-py==1.3.0 (from -r ../CelebBasis/requirements.txt (line 1))\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.6/124.6 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting aiohttp==3.8.3 (from -r ../CelebBasis/requirements.txt (line 2))\n",
      "  Downloading aiohttp-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m19.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 3)) (1.3.1)\n",
      "Collecting albumentations==1.1.0 (from -r ../CelebBasis/requirements.txt (line 4))\n",
      "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m102.4/102.4 kB\u001B[0m \u001B[31m11.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting altair==4.2.0 (from -r ../CelebBasis/requirements.txt (line 5))\n",
      "  Downloading altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m812.8/812.8 kB\u001B[0m \u001B[31m60.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting aniso8601==9.0.1 (from -r ../CelebBasis/requirements.txt (line 6))\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.8/52.8 kB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting asttokens (from -r ../CelebBasis/requirements.txt (line 7))\n",
      "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: async-timeout==4.0.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 8)) (4.0.2)\n",
      "Collecting attrs==22.1.0 (from -r ../CelebBasis/requirements.txt (line 9))\n",
      "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.8/58.8 kB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting autofaiss==2.15.6 (from -r ../CelebBasis/requirements.txt (line 10))\n",
      "  Downloading autofaiss-2.15.6-py3-none-any.whl (70 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m70.1/70.1 kB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 11)) (0.2.0)\n",
      "Collecting blinker==1.6.2 (from -r ../CelebBasis/requirements.txt (line 12))\n",
      "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting braceexpand==0.1.7 (from -r ../CelebBasis/requirements.txt (line 13))\n",
      "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Collecting cachetools==5.2.0 (from -r ../CelebBasis/requirements.txt (line 14))\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 15)) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer==2.0.12 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 16)) (2.0.12)\n",
      "Collecting click==8.1.3 (from -r ../CelebBasis/requirements.txt (line 17))\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m96.6/96.6 kB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting clip-anytorch==2.5.2 (from -r ../CelebBasis/requirements.txt (line 19))\n",
      "  Downloading clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m81.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting clip-retrieval==2.36.1 (from -r ../CelebBasis/requirements.txt (line 20))\n",
      "  Downloading clip_retrieval-2.36.1-py3-none-any.whl (353 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m353.2/353.2 kB\u001B[0m \u001B[31m35.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting comm (from -r ../CelebBasis/requirements.txt (line 21))\n",
      "  Downloading comm-0.1.3-py3-none-any.whl (6.6 kB)\n",
      "Collecting commonmark==0.9.1 (from -r ../CelebBasis/requirements.txt (line 22))\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m51.1/51.1 kB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting contourpy==1.0.6 (from -r ../CelebBasis/requirements.txt (line 23))\n",
      "  Downloading contourpy-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (296 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m296.1/296.1 kB\u001B[0m \u001B[31m30.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 24)) (0.11.0)\n",
      "Collecting Cython==0.29.35 (from -r ../CelebBasis/requirements.txt (line 25))\n",
      "  Downloading Cython-0.29.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.9/1.9 MB\u001B[0m \u001B[31m75.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting dataclasses==0.6 (from -r ../CelebBasis/requirements.txt (line 26))\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: debugpy in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 27)) (1.6.6)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 28)) (4.4.2)\n",
      "Collecting docker-pycreds==0.4.0 (from -r ../CelebBasis/requirements.txt (line 29))\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting einops==0.4.1 (from -r ../CelebBasis/requirements.txt (line 30))\n",
      "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
      "Collecting embedding-reader==1.5.0 (from -r ../CelebBasis/requirements.txt (line 31))\n",
      "  Downloading embedding_reader-1.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: entrypoints==0.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 32)) (0.4)\n",
      "Collecting executing (from -r ../CelebBasis/requirements.txt (line 33))\n",
      "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting ExifRead-nocycle==3.0.1 (from -r ../CelebBasis/requirements.txt (line 34))\n",
      "  Downloading ExifRead_nocycle-3.0.1-py3-none-any.whl (39 kB)\n",
      "Collecting facexlib==0.2.5 (from -r ../CelebBasis/requirements.txt (line 35))\n",
      "  Downloading facexlib-0.2.5-py3-none-any.whl (59 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m59.6/59.6 kB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting faiss-cpu==1.7.4 (from -r ../CelebBasis/requirements.txt (line 36))\n",
      "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.6/17.6 MB\u001B[0m \u001B[31m80.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting filelock==3.8.0 (from -r ../CelebBasis/requirements.txt (line 37))\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting filterpy==1.4.5 (from -r ../CelebBasis/requirements.txt (line 38))\n",
      "  Downloading filterpy-1.4.5.zip (177 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m178.0/178.0 kB\u001B[0m \u001B[31m21.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting fire==0.4.0 (from -r ../CelebBasis/requirements.txt (line 39))\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m87.7/87.7 kB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting Flask==2.3.2 (from -r ../CelebBasis/requirements.txt (line 40))\n",
      "  Downloading Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m96.9/96.9 kB\u001B[0m \u001B[31m13.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting Flask-Cors==3.0.10 (from -r ../CelebBasis/requirements.txt (line 41))\n",
      "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
      "Collecting Flask-RESTful==0.3.9 (from -r ../CelebBasis/requirements.txt (line 42))\n",
      "  Downloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\n",
      "Collecting fonttools==4.38.0 (from -r ../CelebBasis/requirements.txt (line 43))\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m965.4/965.4 kB\u001B[0m \u001B[31m64.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: frozenlist==1.3.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 44)) (1.3.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 45)) (2023.6.0)\n",
      "Collecting ftfy==6.1.1 (from -r ../CelebBasis/requirements.txt (line 46))\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.1/53.1 kB\u001B[0m \u001B[31m6.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting future==0.18.2 (from -r ../CelebBasis/requirements.txt (line 47))\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m829.2/829.2 kB\u001B[0m \u001B[31m65.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting gitdb==4.0.10 (from -r ../CelebBasis/requirements.txt (line 48))\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.7/62.7 kB\u001B[0m \u001B[31m8.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting GitPython==3.1.29 (from -r ../CelebBasis/requirements.txt (line 49))\n",
      "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m182.5/182.5 kB\u001B[0m \u001B[31m21.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting grpcio==1.50.0 (from -r ../CelebBasis/requirements.txt (line 50))\n",
      "  Downloading grpcio-1.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.7/4.7 MB\u001B[0m \u001B[31m94.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: h5py==3.8.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 51)) (3.8.0)\n",
      "Collecting huggingface-hub==0.11.0 (from -r ../CelebBasis/requirements.txt (line 52))\n",
      "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m182.1/182.1 kB\u001B[0m \u001B[31m21.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 53)) (3.4)\n",
      "Collecting imageio==2.14.1 (from -r ../CelebBasis/requirements.txt (line 54))\n",
      "  Downloading imageio-2.14.1-py3-none-any.whl (3.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m92.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting imageio-ffmpeg==0.4.7 (from -r ../CelebBasis/requirements.txt (line 55))\n",
      "  Downloading imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m26.9/26.9 MB\u001B[0m \u001B[31m47.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting img2dataset==1.41.0 (from -r ../CelebBasis/requirements.txt (line 56))\n",
      "  Downloading img2dataset-1.41.0-py3-none-any.whl (40 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.6/40.6 kB\u001B[0m \u001B[31m4.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting importlib-metadata==5.0.0 (from -r ../CelebBasis/requirements.txt (line 57))\n",
      "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting importlib-resources==5.10.0 (from -r ../CelebBasis/requirements.txt (line 58))\n",
      "  Downloading importlib_resources-5.10.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 59)) (5.5.6)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 60)) (7.34.0)\n",
      "Requirement already satisfied: itsdangerous==2.1.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 61)) (2.1.2)\n",
      "Collecting jedi (from -r ../CelebBasis/requirements.txt (line 62))\n",
      "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m90.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 63)) (3.1.2)\n",
      "Collecting joblib==1.2.0 (from -r ../CelebBasis/requirements.txt (line 64))\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m298.0/298.0 kB\u001B[0m \u001B[31m32.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting jsonschema==4.17.1 (from -r ../CelebBasis/requirements.txt (line 65))\n",
      "  Downloading jsonschema-4.17.1-py3-none-any.whl (90 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m90.2/90.2 kB\u001B[0m \u001B[31m9.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: jupyter_client in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 66)) (6.1.12)\n",
      "Requirement already satisfied: jupyter_core in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 67)) (5.3.1)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 68)) (1.4.4)\n",
      "Collecting kornia==0.6.0 (from -r ../CelebBasis/requirements.txt (line 69))\n",
      "  Downloading kornia-0.6.0-py2.py3-none-any.whl (367 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m367.1/367.1 kB\u001B[0m \u001B[31m37.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: llvmlite==0.39.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 70)) (0.39.1)\n",
      "Collecting Markdown==3.4.1 (from -r ../CelebBasis/requirements.txt (line 71))\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.3/93.3 kB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting MarkupSafe==2.1.1 (from -r ../CelebBasis/requirements.txt (line 72))\n",
      "  Downloading MarkupSafe-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting matplotlib==3.6.2 (from -r ../CelebBasis/requirements.txt (line 73))\n",
      "  Downloading matplotlib-3.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.8/11.8 MB\u001B[0m \u001B[31m93.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 74)) (0.1.6)\n",
      "Collecting multidict==6.0.2 (from -r ../CelebBasis/requirements.txt (line 75))\n",
      "  Downloading multidict-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m114.5/114.5 kB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting multilingual-clip==1.0.10 (from -r ../CelebBasis/requirements.txt (line 76))\n",
      "  Downloading multilingual_clip-1.0.10-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 77)) (1.5.6)\n",
      "Collecting networkx==2.8.8 (from -r ../CelebBasis/requirements.txt (line 78))\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m66.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 79)) (3.8.1)\n",
      "Requirement already satisfied: numba==0.56.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 80)) (0.56.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 81)) (1.22.4)\n",
      "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 82)) (3.2.2)\n",
      "Collecting omegaconf==2.1.1 (from -r ../CelebBasis/requirements.txt (line 83))\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m74.7/74.7 kB\u001B[0m \u001B[31m9.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting open-clip-torch==2.19.0 (from -r ../CelebBasis/requirements.txt (line 84))\n",
      "  Downloading open_clip_torch-2.19.0-py3-none-any.whl (1.5 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m82.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting opencv-python==4.8.0.74 (from -r ../CelebBasis/requirements.txt (line 85))\n",
      "  Downloading opencv_python-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.7/61.7 MB\u001B[0m \u001B[31m11.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting opencv-python-headless==4.6.0.66 (from -r ../CelebBasis/requirements.txt (line 86))\n",
      "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m48.3/48.3 MB\u001B[0m \u001B[31m25.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting packaging==21.3 (from -r ../CelebBasis/requirements.txt (line 87))\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.8/40.8 kB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 88)) (1.5.3)\n",
      "Requirement already satisfied: parso in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 89)) (0.8.3)\n",
      "Collecting pathtools==0.1.2 (from -r ../CelebBasis/requirements.txt (line 90))\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 91)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 92)) (0.7.5)\n",
      "Collecting Pillow==9.0.1 (from -r ../CelebBasis/requirements.txt (line 93))\n",
      "  Downloading Pillow-9.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.3/4.3 MB\u001B[0m \u001B[31m76.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pkgutil_resolve_name==1.3.10 (from -r ../CelebBasis/requirements.txt (line 94))\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 95)) (3.8.1)\n",
      "Collecting prometheus-client==0.16.0 (from -r ../CelebBasis/requirements.txt (line 96))\n",
      "  Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m122.5/122.5 kB\u001B[0m \u001B[31m14.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: promise==2.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 97)) (2.3)\n",
      "Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 98)) (3.0.39)\n",
      "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 99)) (3.20.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 100)) (5.9.5)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 101)) (0.7.0)\n",
      "Collecting pudb==2019.2 (from -r ../CelebBasis/requirements.txt (line 102))\n",
      "  Downloading pudb-2019.2.tar.gz (59 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m59.5/59.5 kB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting pure-eval (from -r ../CelebBasis/requirements.txt (line 103))\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyarrow==7.0.0 (from -r ../CelebBasis/requirements.txt (line 104))\n",
      "  Downloading pyarrow-7.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m26.7/26.7 MB\u001B[0m \u001B[31m51.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pyasn1==0.4.8 (from -r ../CelebBasis/requirements.txt (line 105))\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.1/77.1 kB\u001B[0m \u001B[31m9.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pyasn1-modules==0.2.8 (from -r ../CelebBasis/requirements.txt (line 106))\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m155.3/155.3 kB\u001B[0m \u001B[31m19.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pydeck==0.8.0 (from -r ../CelebBasis/requirements.txt (line 107))\n",
      "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.7/4.7 MB\u001B[0m \u001B[31m95.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pyDeprecate==0.3.1 (from -r ../CelebBasis/requirements.txt (line 108))\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting Pygments==2.13.0 (from -r ../CelebBasis/requirements.txt (line 109))\n",
      "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m66.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting Pympler==1.0.1 (from -r ../CelebBasis/requirements.txt (line 110))\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m164.8/164.8 kB\u001B[0m \u001B[31m20.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pyparsing==3.0.9 (from -r ../CelebBasis/requirements.txt (line 111))\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m98.3/98.3 kB\u001B[0m \u001B[31m12.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pyrsistent==0.19.2 (from -r ../CelebBasis/requirements.txt (line 112))\n",
      "  Downloading pyrsistent-0.19.2-py3-none-any.whl (57 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.5/57.5 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 113)) (2.8.2)\n",
      "Collecting pytorch-lightning==1.5.9 (from -r ../CelebBasis/requirements.txt (line 114))\n",
      "  Downloading pytorch_lightning-1.5.9-py3-none-any.whl (527 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m527.2/527.2 kB\u001B[0m \u001B[31m49.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pytz==2022.6 (from -r ../CelebBasis/requirements.txt (line 115))\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m498.1/498.1 kB\u001B[0m \u001B[31m45.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pytz-deprecation-shim==0.1.0.post0 (from -r ../CelebBasis/requirements.txt (line 116))\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: PyWavelets==1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 117)) (1.4.1)\n",
      "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 118)) (6.0)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 119)) (23.2.1)\n",
      "Requirement already satisfied: qudida==0.0.4 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 120)) (0.0.4)\n",
      "Requirement already satisfied: regex==2022.10.31 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 121)) (2022.10.31)\n",
      "Requirement already satisfied: requests==2.27.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 122)) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 123)) (1.3.1)\n",
      "Collecting rich==12.6.0 (from -r ../CelebBasis/requirements.txt (line 124))\n",
      "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m237.5/237.5 kB\u001B[0m \u001B[31m27.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: rsa==4.9 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 125)) (4.9)\n",
      "Collecting sacremoses==0.0.53 (from -r ../CelebBasis/requirements.txt (line 126))\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m880.6/880.6 kB\u001B[0m \u001B[31m64.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting safetensors==0.3.1 (from -r ../CelebBasis/requirements.txt (line 127))\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m80.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: scikit-image==0.19.3 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 128)) (0.19.3)\n",
      "Collecting scikit-learn==1.1.3 (from -r ../CelebBasis/requirements.txt (line 129))\n",
      "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.5/30.5 MB\u001B[0m \u001B[31m47.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting scipy==1.9.3 (from -r ../CelebBasis/requirements.txt (line 130))\n",
      "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m33.7/33.7 MB\u001B[0m \u001B[31m39.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting semver==2.13.0 (from -r ../CelebBasis/requirements.txt (line 131))\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting sentence-transformers==2.2.2 (from -r ../CelebBasis/requirements.txt (line 132))\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.0/86.0 kB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting sentencepiece==0.1.99 (from -r ../CelebBasis/requirements.txt (line 133))\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m79.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting sentry-sdk==1.21.1 (from -r ../CelebBasis/requirements.txt (line 134))\n",
      "  Downloading sentry_sdk-1.21.1-py2.py3-none-any.whl (201 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m201.7/201.7 kB\u001B[0m \u001B[31m21.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting setproctitle==1.3.2 (from -r ../CelebBasis/requirements.txt (line 135))\n",
      "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting shortuuid==1.0.11 (from -r ../CelebBasis/requirements.txt (line 136))\n",
      "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 137)) (1.16.0)\n",
      "Collecting smmap==5.0.0 (from -r ../CelebBasis/requirements.txt (line 138))\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting stack-data (from -r ../CelebBasis/requirements.txt (line 139))\n",
      "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
      "Collecting streamlit==1.15.1 (from -r ../CelebBasis/requirements.txt (line 140))\n",
      "  Downloading streamlit-1.15.1-py2.py3-none-any.whl (10.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.3/10.3 MB\u001B[0m \u001B[31m84.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 142)) (2.12.3)\n",
      "Requirement already satisfied: tensorboard-data-server in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 143)) (0.7.1)\n",
      "Collecting tensorboard-plugin-wit (from -r ../CelebBasis/requirements.txt (line 144))\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m781.3/781.3 kB\u001B[0m \u001B[31m59.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: termcolor==2.3.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 145)) (2.3.0)\n",
      "Collecting test-tube==0.7.5 (from -r ../CelebBasis/requirements.txt (line 146))\n",
      "  Downloading test_tube-0.7.5.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 147)) (3.1.0)\n",
      "Collecting tifffile==2022.10.10 (from -r ../CelebBasis/requirements.txt (line 148))\n",
      "  Downloading tifffile-2022.10.10-py3-none-any.whl (210 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m210.3/210.3 kB\u001B[0m \u001B[31m22.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting timm==0.6.13 (from -r ../CelebBasis/requirements.txt (line 149))\n",
      "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m549.1/549.1 kB\u001B[0m \u001B[31m42.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting tokenizers==0.12.1 (from -r ../CelebBasis/requirements.txt (line 150))\n",
      "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.6/6.6 MB\u001B[0m \u001B[31m87.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 151)) (0.10.2)\n",
      "Requirement already satisfied: toolz==0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 152)) (0.12.0)\n",
      "Collecting torch==1.12.0 (from -r ../CelebBasis/requirements.txt (line 153))\n",
      "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m776.3/776.3 MB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torch-fidelity==0.3.0 (from -r ../CelebBasis/requirements.txt (line 154))\n",
      "  Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
      "Collecting torchmetrics==0.6.0 (from -r ../CelebBasis/requirements.txt (line 155))\n",
      "  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m329.4/329.4 kB\u001B[0m \u001B[31m31.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 156)) (0.15.2+cu118)\n",
      "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 157)) (6.3.1)\n",
      "Collecting tqdm==4.64.1 (from -r ../CelebBasis/requirements.txt (line 158))\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 159)) (5.7.1)\n",
      "Collecting transformers==4.18.0 (from -r ../CelebBasis/requirements.txt (line 160))\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.0/4.0 MB\u001B[0m \u001B[31m107.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 161)) (4.7.1)\n",
      "Collecting tzdata==2022.6 (from -r ../CelebBasis/requirements.txt (line 162))\n",
      "  Downloading tzdata-2022.6-py2.py3-none-any.whl (338 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m338.8/338.8 kB\u001B[0m \u001B[31m34.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting tzlocal==4.2 (from -r ../CelebBasis/requirements.txt (line 163))\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Collecting urllib3==1.26.13 (from -r ../CelebBasis/requirements.txt (line 164))\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m140.6/140.6 kB\u001B[0m \u001B[31m17.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting urwid==2.1.2 (from -r ../CelebBasis/requirements.txt (line 165))\n",
      "  Downloading urwid-2.1.2.tar.gz (634 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m634.6/634.6 kB\u001B[0m \u001B[31m48.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting validators==0.20.0 (from -r ../CelebBasis/requirements.txt (line 166))\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting wandb==0.12.21 (from -r ../CelebBasis/requirements.txt (line 167))\n",
      "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m83.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting watchdog==2.1.9 (from -r ../CelebBasis/requirements.txt (line 168))\n",
      "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.4/78.4 kB\u001B[0m \u001B[31m10.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from -r ../CelebBasis/requirements.txt (line 169)) (0.2.6)\n",
      "Collecting webdataset==0.2.48 (from -r ../CelebBasis/requirements.txt (line 170))\n",
      "  Downloading webdataset-0.2.48-py3-none-any.whl (51 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m51.9/51.9 kB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting Werkzeug==2.3.3 (from -r ../CelebBasis/requirements.txt (line 171))\n",
      "  Downloading Werkzeug-2.3.3-py3-none-any.whl (242 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m242.3/242.3 kB\u001B[0m \u001B[31m19.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting yarl==1.8.1 (from -r ../CelebBasis/requirements.txt (line 172))\n",
      "  Downloading yarl-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (263 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m264.0/264.0 kB\u001B[0m \u001B[31m29.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting zipp==3.10.0 (from -r ../CelebBasis/requirements.txt (line 173))\n",
      "  Downloading zipp-3.10.0-py3-none-any.whl (6.2 kB)\n",
      "Collecting fsspec (from -r ../CelebBasis/requirements.txt (line 45))\n",
      "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.5/139.5 kB\u001B[0m \u001B[31m16.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba==0.56.4->-r ../CelebBasis/requirements.txt (line 80)) (67.7.2)\n",
      "Collecting antlr4-python3-runtime==4.8 (from omegaconf==2.1.1->-r ../CelebBasis/requirements.txt (line 83))\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m112.4/112.4 kB\u001B[0m \u001B[31m14.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting setuptools (from numba==0.56.4->-r ../CelebBasis/requirements.txt (line 80))\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m952.4/952.4 kB\u001B[0m \u001B[31m69.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r ../CelebBasis/requirements.txt (line 59)) (0.2.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r ../CelebBasis/requirements.txt (line 142)) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r ../CelebBasis/requirements.txt (line 142)) (1.0.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r ../CelebBasis/requirements.txt (line 142)) (0.40.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from -r ../CelebBasis/requirements.txt (line 156))\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.0/6.0 MB\u001B[0m \u001B[31m102.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.0/6.0 MB\u001B[0m \u001B[31m97.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.2/24.2 MB\u001B[0m \u001B[31m68.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Downloading torchvision-0.14.0-cp310-cp310-manylinux1_x86_64.whl (24.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.3/24.3 MB\u001B[0m \u001B[31m67.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m19.1/19.1 MB\u001B[0m \u001B[31m71.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Downloading torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m19.1/19.1 MB\u001B[0m \u001B[31m79.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hINFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0 (from pytorch-lightning==1.5.9->-r ../CelebBasis/requirements.txt (line 114))\n",
      "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m160.1/160.1 kB\u001B[0m \u001B[31m15.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m154.0/154.0 kB\u001B[0m \u001B[31m17.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m145.4/145.4 kB\u001B[0m \u001B[31m17.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.0/143.0 kB\u001B[0m \u001B[31m18.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hBuilding wheels for collected packages: filterpy, fire, future, pathtools, pudb, sacremoses, sentence-transformers, test-tube, urwid, validators, antlr4-python3-runtime\n",
      "  Building wheel for filterpy (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110459 sha256=280aa60a0ed28b5c45c30ba5517f452b015fcb89cc9d479732f53364861ad92b\n",
      "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
      "  Building wheel for fire (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115927 sha256=d92f2006e2c53b0cf40357b3d8e4c8889b1da7c8aea9166aeb107bc5d2497b36\n",
      "  Stored in directory: /root/.cache/pip/wheels/26/9a/dd/2818b1b023daf077ec3e625c47ae446aca587a5abe48e05212\n",
      "  Building wheel for future (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491056 sha256=5779d9bae505bf3a97fb17268a64c8f5f0750582847a147205e0435820fdb03e\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/73/06/557dc4f4ef68179b9d763930d6eec26b88ed7c389b19588a1c\n",
      "  Building wheel for pathtools (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=db6c16a41c925be2e52a004e4dab4f4b47c82ff148aa3560ae4d5e69674027a5\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
      "  Building wheel for pudb (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pudb: filename=pudb-2019.2-py3-none-any.whl size=63218 sha256=65eecda14ff2c3d550db87b00cbabf1e90791961da0172dd6b607beb109f11b7\n",
      "  Stored in directory: /root/.cache/pip/wheels/02/0f/24/1ca86e678056ad3c72b3fe94f829b9bdf92bb4d661c32bbed1\n",
      "  Building wheel for sacremoses (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=061a574531ac55f8f640218bcbf2b6abe6d62e1e8cf12fe4473358493037c24c\n",
      "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=9bf30ff50eef8ebb2fc34901e7a690bbfe3579895a7d90710133465ff7a65182\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "  Building wheel for test-tube (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for test-tube: filename=test_tube-0.7.5-py3-none-any.whl size=25329 sha256=d9a7e690a7e1b5ce96a31d8335d0d2124ef6cd22c558a4915c887f772a9aa4aa\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/d4/8b/1aeb47c0dedd931b8e6aec55a8091864a69ac6f0adc5b12ea9\n",
      "  Building wheel for urwid (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for urwid: filename=urwid-2.1.2-cp310-cp310-linux_x86_64.whl size=259901 sha256=c02eae3170cd8d6240c26eceafe928e0bd707c99cd7f37bedeb5a0f51ce5d021\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/3d/85/cde786c07f333509d868e5024d5ed8c70519fa1b8e8c66ec6c\n",
      "  Building wheel for validators (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=57797498a48b82c92c5aeef097399231ea5a76bc78992c8b5b07e8fc2e716128\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=2670923737d45c69e0ba734c26c6aaf51038464e4c28df6700adfc62c976c794\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
      "Successfully built filterpy fire future pathtools pudb sacremoses sentence-transformers test-tube urwid validators antlr4-python3-runtime\n",
      "Installing collected packages: urwid, tokenizers, tensorboard-plugin-wit, sentencepiece, safetensors, pytz, pyasn1, pure-eval, pathtools, faiss-cpu, ExifRead-nocycle, executing, einops, dataclasses, commonmark, braceexpand, antlr4-python3-runtime, aniso8601, zipp, webdataset, watchdog, validators, urllib3, tzdata, tqdm, torch, tifffile, smmap, shortuuid, setuptools, setproctitle, semver, scipy, pyrsistent, pyparsing, Pympler, Pygments, pyDeprecate, pyasn1-modules, pyarrow, prometheus-client, pkgutil_resolve_name, Pillow, opencv-python-headless, opencv-python, omegaconf, networkx, multidict, MarkupSafe, Markdown, joblib, jedi, importlib-resources, imageio-ffmpeg, grpcio, future, ftfy, fsspec, fonttools, fire, filelock, docker-pycreds, Cython, contourpy, comm, click, cachetools, blinker, attrs, asttokens, absl-py, yarl, Werkzeug, taming_transformers, stack-data, sentry-sdk, scikit-learn, sacremoses, rich, pytz-deprecation-shim, pudb, packaging, jsonschema, importlib-metadata, imageio, gitdb, tzlocal, torchvision, torchmetrics, pydeck, matplotlib, kornia, huggingface-hub, GitPython, Flask, embedding-reader, altair, aiohttp, wandb, transformers, torch-fidelity, timm, streamlit, Flask-RESTful, Flask-Cors, filterpy, clip-anytorch, clip, autofaiss, albumentations, sentence-transformers, open-clip-torch, multilingual-clip, img2dataset, facexlib, test-tube, pytorch-lightning, clip-retrieval\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2022.7.1\n",
      "    Uninstalling pytz-2022.7.1:\n",
      "      Successfully uninstalled pytz-2022.7.1\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.5.0\n",
      "    Uninstalling pyasn1-0.5.0:\n",
      "      Successfully uninstalled pyasn1-0.5.0\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.16.0\n",
      "    Uninstalling zipp-3.16.0:\n",
      "      Successfully uninstalled zipp-3.16.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1+cu118\n",
      "    Uninstalling torch-2.0.1+cu118:\n",
      "      Successfully uninstalled torch-2.0.1+cu118\n",
      "  Attempting uninstall: tifffile\n",
      "    Found existing installation: tifffile 2023.7.10\n",
      "    Uninstalling tifffile-2023.7.10:\n",
      "      Successfully uninstalled tifffile-2023.7.10\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 67.7.2\n",
      "    Uninstalling setuptools-67.7.2:\n",
      "      Successfully uninstalled setuptools-67.7.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n",
      "  Attempting uninstall: pyrsistent\n",
      "    Found existing installation: pyrsistent 0.19.3\n",
      "    Uninstalling pyrsistent-0.19.3:\n",
      "      Successfully uninstalled pyrsistent-0.19.3\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.1.0\n",
      "    Uninstalling pyparsing-3.1.0:\n",
      "      Successfully uninstalled pyparsing-3.1.0\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.14.0\n",
      "    Uninstalling Pygments-2.14.0:\n",
      "      Successfully uninstalled Pygments-2.14.0\n",
      "  Attempting uninstall: pyasn1-modules\n",
      "    Found existing installation: pyasn1-modules 0.3.0\n",
      "    Uninstalling pyasn1-modules-0.3.0:\n",
      "      Successfully uninstalled pyasn1-modules-0.3.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 9.0.0\n",
      "    Uninstalling pyarrow-9.0.0:\n",
      "      Successfully uninstalled pyarrow-9.0.0\n",
      "  Attempting uninstall: prometheus-client\n",
      "    Found existing installation: prometheus-client 0.17.1\n",
      "    Uninstalling prometheus-client-0.17.1:\n",
      "      Successfully uninstalled prometheus-client-0.17.1\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.4.0\n",
      "    Uninstalling Pillow-8.4.0:\n",
      "      Successfully uninstalled Pillow-8.4.0\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.8.0.74\n",
      "    Uninstalling opencv-python-headless-4.8.0.74:\n",
      "      Successfully uninstalled opencv-python-headless-4.8.0.74\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.7.0.72\n",
      "    Uninstalling opencv-python-4.7.0.72:\n",
      "      Successfully uninstalled opencv-python-4.7.0.72\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.1\n",
      "    Uninstalling networkx-3.1:\n",
      "      Successfully uninstalled networkx-3.1\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.0.4\n",
      "    Uninstalling multidict-6.0.4:\n",
      "      Successfully uninstalled multidict-6.0.4\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.3\n",
      "    Uninstalling MarkupSafe-2.1.3:\n",
      "      Successfully uninstalled MarkupSafe-2.1.3\n",
      "  Attempting uninstall: Markdown\n",
      "    Found existing installation: Markdown 3.4.3\n",
      "    Uninstalling Markdown-3.4.3:\n",
      "      Successfully uninstalled Markdown-3.4.3\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.3.1\n",
      "    Uninstalling joblib-1.3.1:\n",
      "      Successfully uninstalled joblib-1.3.1\n",
      "  Attempting uninstall: importlib-resources\n",
      "    Found existing installation: importlib-resources 6.0.0\n",
      "    Uninstalling importlib-resources-6.0.0:\n",
      "      Successfully uninstalled importlib-resources-6.0.0\n",
      "  Attempting uninstall: imageio-ffmpeg\n",
      "    Found existing installation: imageio-ffmpeg 0.4.8\n",
      "    Uninstalling imageio-ffmpeg-0.4.8:\n",
      "      Successfully uninstalled imageio-ffmpeg-0.4.8\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.56.0\n",
      "    Uninstalling grpcio-1.56.0:\n",
      "      Successfully uninstalled grpcio-1.56.0\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 0.18.3\n",
      "    Uninstalling future-0.18.3:\n",
      "      Successfully uninstalled future-0.18.3\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.6.0\n",
      "    Uninstalling fsspec-2023.6.0:\n",
      "      Successfully uninstalled fsspec-2023.6.0\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.40.0\n",
      "    Uninstalling fonttools-4.40.0:\n",
      "      Successfully uninstalled fonttools-4.40.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.12.2\n",
      "    Uninstalling filelock-3.12.2:\n",
      "      Successfully uninstalled filelock-3.12.2\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.36\n",
      "    Uninstalling Cython-0.29.36:\n",
      "      Successfully uninstalled Cython-0.29.36\n",
      "  Attempting uninstall: contourpy\n",
      "    Found existing installation: contourpy 1.1.0\n",
      "    Uninstalling contourpy-1.1.0:\n",
      "      Successfully uninstalled contourpy-1.1.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.4\n",
      "    Uninstalling click-8.1.4:\n",
      "      Successfully uninstalled click-8.1.4\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 5.3.1\n",
      "    Uninstalling cachetools-5.3.1:\n",
      "      Successfully uninstalled cachetools-5.3.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.4.0\n",
      "    Uninstalling absl-py-1.4.0:\n",
      "      Successfully uninstalled absl-py-1.4.0\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.9.2\n",
      "    Uninstalling yarl-1.9.2:\n",
      "      Successfully uninstalled yarl-1.9.2\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 2.3.6\n",
      "    Uninstalling Werkzeug-2.3.6:\n",
      "      Successfully uninstalled Werkzeug-2.3.6\n",
      "  Running setup.py develop for taming_transformers\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.4.2\n",
      "    Uninstalling rich-13.4.2:\n",
      "      Successfully uninstalled rich-13.4.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.3.3\n",
      "    Uninstalling jsonschema-4.3.3:\n",
      "      Successfully uninstalled jsonschema-4.3.3\n",
      "  Attempting uninstall: imageio\n",
      "    Found existing installation: imageio 2.25.1\n",
      "    Uninstalling imageio-2.25.1:\n",
      "      Successfully uninstalled imageio-2.25.1\n",
      "  Attempting uninstall: tzlocal\n",
      "    Found existing installation: tzlocal 5.0.1\n",
      "    Uninstalling tzlocal-5.0.1:\n",
      "      Successfully uninstalled tzlocal-5.0.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.2+cu118\n",
      "    Uninstalling torchvision-0.15.2+cu118:\n",
      "      Successfully uninstalled torchvision-0.15.2+cu118\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.1\n",
      "    Uninstalling matplotlib-3.7.1:\n",
      "      Successfully uninstalled matplotlib-3.7.1\n",
      "  Attempting uninstall: Flask\n",
      "    Found existing installation: Flask 2.2.5\n",
      "    Uninstalling Flask-2.2.5:\n",
      "      Successfully uninstalled Flask-2.2.5\n",
      "  Attempting uninstall: altair\n",
      "    Found existing installation: altair 4.2.2\n",
      "    Uninstalling altair-4.2.2:\n",
      "      Successfully uninstalled altair-4.2.2\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.4\n",
      "    Uninstalling aiohttp-3.8.4:\n",
      "      Successfully uninstalled aiohttp-3.8.4\n",
      "  Running setup.py develop for clip\n",
      "  Attempting uninstall: albumentations\n",
      "    Found existing installation: albumentations 1.2.1\n",
      "    Uninstalling albumentations-1.2.1:\n",
      "      Successfully uninstalled albumentations-1.2.1\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n",
      "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\n",
      "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2022.11.0 which is incompatible.\n",
      "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n",
      "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n",
      "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed Cython-0.29.35 ExifRead-nocycle-3.0.1 Flask-2.3.2 Flask-Cors-3.0.10 Flask-RESTful-0.3.9 GitPython-3.1.29 Markdown-3.4.1 MarkupSafe-2.1.1 Pillow-9.0.1 Pygments-2.13.0 Pympler-1.0.1 Werkzeug-2.3.3 absl-py-1.3.0 aiohttp-3.8.3 albumentations-1.1.0 altair-4.2.0 aniso8601-9.0.1 antlr4-python3-runtime-4.8 asttokens-2.2.1 attrs-22.1.0 autofaiss-2.15.6 blinker-1.6.2 braceexpand-0.1.7 cachetools-5.2.0 click-8.1.3 clip-1.0 clip-anytorch-2.5.2 clip-retrieval-2.36.1 comm-0.1.3 commonmark-0.9.1 contourpy-1.0.6 dataclasses-0.6 docker-pycreds-0.4.0 einops-0.4.1 embedding-reader-1.5.0 executing-1.2.0 facexlib-0.2.5 faiss-cpu-1.7.4 filelock-3.8.0 filterpy-1.4.5 fire-0.4.0 fonttools-4.38.0 fsspec-2022.11.0 ftfy-6.1.1 future-0.18.2 gitdb-4.0.10 grpcio-1.50.0 huggingface-hub-0.11.0 imageio-2.14.1 imageio-ffmpeg-0.4.7 img2dataset-1.41.0 importlib-metadata-5.0.0 importlib-resources-5.10.0 jedi-0.18.2 joblib-1.2.0 jsonschema-4.17.1 kornia-0.6.0 matplotlib-3.6.2 multidict-6.0.2 multilingual-clip-1.0.10 networkx-2.8.8 omegaconf-2.1.1 open-clip-torch-2.19.0 opencv-python-4.8.0.74 opencv-python-headless-4.6.0.66 packaging-21.3 pathtools-0.1.2 pkgutil_resolve_name-1.3.10 prometheus-client-0.16.0 pudb-2019.2 pure-eval-0.2.2 pyDeprecate-0.3.1 pyarrow-7.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pydeck-0.8.0 pyparsing-3.0.9 pyrsistent-0.19.2 pytorch-lightning-1.5.9 pytz-2022.6 pytz-deprecation-shim-0.1.0.post0 rich-12.6.0 sacremoses-0.0.53 safetensors-0.3.1 scikit-learn-1.1.3 scipy-1.9.3 semver-2.13.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 sentry-sdk-1.21.1 setproctitle-1.3.2 setuptools-59.5.0 shortuuid-1.0.11 smmap-5.0.0 stack-data-0.6.2 streamlit-1.15.1 taming_transformers-0.0.1 tensorboard-plugin-wit-1.8.1 test-tube-0.7.5 tifffile-2022.10.10 timm-0.6.13 tokenizers-0.12.1 torch-1.12.0 torch-fidelity-0.3.0 torchmetrics-0.6.0 torchvision-0.13.0 tqdm-4.64.1 transformers-4.18.0 tzdata-2022.6 tzlocal-4.2 urllib3-1.26.13 urwid-2.1.2 validators-0.20.0 wandb-0.12.21 watchdog-2.1.9 webdataset-0.2.48 yarl-1.8.1 zipp-3.10.0\n",
      "Found existing installation: torchtext 0.15.2\n",
      "Uninstalling torchtext-0.15.2:\n",
      "  Successfully uninstalled torchtext-0.15.2\n",
      "Found existing installation: torchdata 0.6.1\n",
      "Uninstalling torchdata-0.6.1:\n",
      "  Successfully uninstalled torchdata-0.6.1\n",
      "Found existing installation: torchaudio 2.0.2+cu118\n",
      "Uninstalling torchaudio-2.0.2+cu118:\n",
      "  Successfully uninstalled torchaudio-2.0.2+cu118\n",
      "clip-anytorch                    2.5.2\n",
      "open-clip-torch                  2.19.0\n",
      "pytorch-lightning                1.5.9\n",
      "torch                            1.12.0\n",
      "torch-fidelity                   0.3.0\n",
      "torchmetrics                     0.6.0\n",
      "torchsummary                     1.5.1\n",
      "torchvision                      0.13.0\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p pip_installed/ && cd pip_installed/ && pip install -r ../CelebBasis/requirements.txt\n",
    "!pip uninstall -r ./CelebBasis/requirements_uninstall.txt -y\n",
    "!pip list |grep torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#2. Crop and Align Faces"
   ],
   "metadata": {
    "id": "_KfHoRNloykq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9ONycB8TcqB",
    "outputId": "4f2d348f-30ba-4e78-976c-bd8b24d794fa"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/CelebBasis/evaluation/face_align/PIPNet/FaceBoxesV2/utils/build.py:13: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils.core import setup\n",
      "running build_ext\n",
      "cythoning nms/cpu_nms.pyx to nms/cpu_nms.c\n",
      "/usr/local/lib/python3.10/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/CelebBasis/evaluation/face_align/PIPNet/FaceBoxesV2/utils/nms/cpu_nms.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "building 'nms.cpu_nms' extension\n",
      "creating build\n",
      "creating build/temp.linux-x86_64-3.10\n",
      "creating build/temp.linux-x86_64-3.10/nms\n",
      "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c nms/cpu_nms.c -o build/temp.linux-x86_64-3.10/nms/cpu_nms.o -Wno-cpp -Wno-unused-function\n",
      "\u001B[01m\u001B[Knms/cpu_nms.c:\u001B[m\u001B[K In function ‘\u001B[01m\u001B[K__pyx_pf_3nms_7cpu_nms_2cpu_soft_nms\u001B[m\u001B[K’:\n",
      "\u001B[01m\u001B[Knms/cpu_nms.c:3554:33:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[Kcomparison of integer expressions of different signedness: ‘\u001B[01m\u001B[Kint\u001B[m\u001B[K’ and ‘\u001B[01m\u001B[Kunsigned int\u001B[m\u001B[K’ [\u001B[01;35m\u001B[K-Wsign-compare\u001B[m\u001B[K]\n",
      " 3554 |       __pyx_t_8 = ((__pyx_v_pos \u001B[01;35m\u001B[K<\u001B[m\u001B[K __pyx_v_N) != 0);\n",
      "      |                                 \u001B[01;35m\u001B[K^\u001B[m\u001B[K\n",
      "\u001B[01m\u001B[Knms/cpu_nms.c:4065:33:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[Kcomparison of integer expressions of different signedness: ‘\u001B[01m\u001B[Kint\u001B[m\u001B[K’ and ‘\u001B[01m\u001B[Kunsigned int\u001B[m\u001B[K’ [\u001B[01;35m\u001B[K-Wsign-compare\u001B[m\u001B[K]\n",
      " 4065 |       __pyx_t_8 = ((__pyx_v_pos \u001B[01;35m\u001B[K<\u001B[m\u001B[K __pyx_v_N) != 0);\n",
      "      |                                 \u001B[01;35m\u001B[K^\u001B[m\u001B[K\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC build/temp.linux-x86_64-3.10/nms/cpu_nms.o -o /content/CelebBasis/evaluation/face_align/PIPNet/FaceBoxesV2/utils/nms/cpu_nms.cpython-310-x86_64-linux-gnu.so\n",
      "/content/CelebBasis\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100% 171M/171M [00:02<00:00, 79.4MB/s]\n",
      "alignment model loaded\n",
      "Detect and Align: 100% 224/224 [00:46<00:00,  4.80it/s]\n",
      "Generating pickle list...(saved to ../datasets/stylegan/ffhq.pickle)\n",
      "100% 224/224 [00:00<00:00, 724382.49it/s]\n",
      "Checking pickle list...\n",
      "pickle type: <class 'list'> , total len: 224\n",
      "pickle[0]: ../datasets/stylegan/ffhq/0002.png\n",
      "pickle[1]: ../datasets/stylegan/ffhq/0011.png\n",
      "pickle[-2]: ../datasets/stylegan/ffhq/1996.png\n",
      "pickle[-1]: ../datasets/stylegan/ffhq/1997.png\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!cd CelebBasis && chmod +x *.sh && bash ./00_align_face.sh ../datasets/stylegan/stylegan3-r-ffhq-1024x1024 ../datasets/stylegan/ffhq"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#3. Train\n",
    "* Limited by Google Colab GPU Memory ($<$16GB), we have to modify the `configs/stable-diffusion/aigc_id_colab.yaml` as follows:\n",
    "```yaml\n",
    "model:\n",
    "  params:\n",
    "    personalization_config:\n",
    "      params:\n",
    "        momentum: 0.9  # default: 0.99\n",
    "data:\n",
    "  params:\n",
    "    batch_size: 1  # default: 2\n",
    "    num_workers: 2  # default: 8\n",
    "lightning:\n",
    "  modelcheckpoint:\n",
    "    params:\n",
    "      every_n_train_steps: 400  # default: 200\n",
    "  callbacks:\n",
    "    image_logger:\n",
    "      params:\n",
    "        batch_frequency: 1200  # default: 600\n",
    "  trainer:\n",
    "    max_steps: 800  # default: 1600\n",
    "```\n",
    "* These modifications may increase the training time and downgrade the performance slightly."
   ],
   "metadata": {
    "id": "eLtyJPj6o2xw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xh6m84j_Ifwy",
    "outputId": "3e593176-6c67-4061-c835-dc4c97f83738"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Global seed set to 23\n",
      "Running on GPUs 0,\n",
      "Loading model from ../pretrained/sd-v1-4-full-ema.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Downloading: \"https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth\" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth\n",
      "100% 5.10M/5.10M [00:00<00:00, 60.8MB/s]\n",
      "Downloading: 100% 939k/939k [00:00<00:00, 1.41MB/s]\n",
      "Downloading: 100% 512k/512k [00:00<00:00, 1.01MB/s]\n",
      "Downloading: 100% 389/389 [00:00<00:00, 229kB/s]\n",
      "Downloading: 100% 905/905 [00:00<00:00, 784kB/s]\n",
      "Downloading: 100% 4.41k/4.41k [00:00<00:00, 3.39MB/s]\n",
      "Downloading: 100% 1.59G/1.59G [00:23<00:00, 74.0MB/s]\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'logit_scale', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'text_projection.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'visual_projection.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.weight']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[celebs cols_embeddings len]: [646, 638, 311, 118, 25, 2]\n",
      "[(col_0) celebs ori]: torch.Size([646, 768]) tensor(5.3118e-05) tensor(-0.0405) tensor(0.0509)\n",
      "[(col_0) celebs c_mean]: tensor(-1.2509e-05) tensor(-0.0091) tensor(0.0112)\n",
      "[(col_0) celebs pca_base]: torch.Size([512, 768]) tensor(-0.0003) tensor(-0.1054) tensor(0.0999) tensor(1.0000)\n",
      "[(col_0) celebs embeddings loaded]: torch.Size([513, 768]) (device:cuda)\n",
      "[(col_1) celebs ori]: torch.Size([638, 768]) tensor(-9.8908e-06) tensor(-0.0414) tensor(0.0464)\n",
      "[(col_1) celebs c_mean]: tensor(-3.7355e-06) tensor(-0.0087) tensor(0.0065)\n",
      "[(col_1) celebs pca_base]: torch.Size([512, 768]) tensor(1.3023e-05) tensor(-0.1589) tensor(0.2419) tensor(1.)\n",
      "[(col_1) celebs embeddings loaded]: torch.Size([513, 768]) (device:cuda)\n",
      "[all celebs embeddings loaded] shape = torch.Size([2, 513, 768]) (device:cuda) flatten=False\n",
      "Restored from ../pretrained/sd-v1-4-full-ema.ckpt with 0 missing and 688 unexpected keys\n",
      "Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'model_ema.diffusion_modeltime_embed0weight', 'model_ema.diffusion_modeltime_embed0bias', 'model_ema.diffusion_modeltime_embed2weight', 'model_ema.diffusion_modeltime_embed2bias', 'model_ema.diffusion_modelinput_blocks00weight', 'model_ema.diffusion_modelinput_blocks00bias', 'model_ema.diffusion_modelinput_blocks10in_layers0weight', 'model_ema.diffusion_modelinput_blocks10in_layers0bias', 'model_ema.diffusion_modelinput_blocks10in_layers2weight', 'model_ema.diffusion_modelinput_blocks10in_layers2bias', 'model_ema.diffusion_modelinput_blocks10emb_layers1weight', 'model_ema.diffusion_modelinput_blocks10emb_layers1bias', 'model_ema.diffusion_modelinput_blocks10out_layers0weight', 'model_ema.diffusion_modelinput_blocks10out_layers0bias', 'model_ema.diffusion_modelinput_blocks10out_layers3weight', 'model_ema.diffusion_modelinput_blocks10out_layers3bias', 'model_ema.diffusion_modelinput_blocks11normweight', 'model_ema.diffusion_modelinput_blocks11normbias', 'model_ema.diffusion_modelinput_blocks11proj_inweight', 'model_ema.diffusion_modelinput_blocks11proj_inbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks11proj_outweight', 'model_ema.diffusion_modelinput_blocks11proj_outbias', 'model_ema.diffusion_modelinput_blocks20in_layers0weight', 'model_ema.diffusion_modelinput_blocks20in_layers0bias', 'model_ema.diffusion_modelinput_blocks20in_layers2weight', 'model_ema.diffusion_modelinput_blocks20in_layers2bias', 'model_ema.diffusion_modelinput_blocks20emb_layers1weight', 'model_ema.diffusion_modelinput_blocks20emb_layers1bias', 'model_ema.diffusion_modelinput_blocks20out_layers0weight', 'model_ema.diffusion_modelinput_blocks20out_layers0bias', 'model_ema.diffusion_modelinput_blocks20out_layers3weight', 'model_ema.diffusion_modelinput_blocks20out_layers3bias', 'model_ema.diffusion_modelinput_blocks21normweight', 'model_ema.diffusion_modelinput_blocks21normbias', 'model_ema.diffusion_modelinput_blocks21proj_inweight', 'model_ema.diffusion_modelinput_blocks21proj_inbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks21proj_outweight', 'model_ema.diffusion_modelinput_blocks21proj_outbias', 'model_ema.diffusion_modelinput_blocks30opweight', 'model_ema.diffusion_modelinput_blocks30opbias', 'model_ema.diffusion_modelinput_blocks40in_layers0weight', 'model_ema.diffusion_modelinput_blocks40in_layers0bias', 'model_ema.diffusion_modelinput_blocks40in_layers2weight', 'model_ema.diffusion_modelinput_blocks40in_layers2bias', 'model_ema.diffusion_modelinput_blocks40emb_layers1weight', 'model_ema.diffusion_modelinput_blocks40emb_layers1bias', 'model_ema.diffusion_modelinput_blocks40out_layers0weight', 'model_ema.diffusion_modelinput_blocks40out_layers0bias', 'model_ema.diffusion_modelinput_blocks40out_layers3weight', 'model_ema.diffusion_modelinput_blocks40out_layers3bias', 'model_ema.diffusion_modelinput_blocks40skip_connectionweight', 'model_ema.diffusion_modelinput_blocks40skip_connectionbias', 'model_ema.diffusion_modelinput_blocks41normweight', 'model_ema.diffusion_modelinput_blocks41normbias', 'model_ema.diffusion_modelinput_blocks41proj_inweight', 'model_ema.diffusion_modelinput_blocks41proj_inbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks41proj_outweight', 'model_ema.diffusion_modelinput_blocks41proj_outbias', 'model_ema.diffusion_modelinput_blocks50in_layers0weight', 'model_ema.diffusion_modelinput_blocks50in_layers0bias', 'model_ema.diffusion_modelinput_blocks50in_layers2weight', 'model_ema.diffusion_modelinput_blocks50in_layers2bias', 'model_ema.diffusion_modelinput_blocks50emb_layers1weight', 'model_ema.diffusion_modelinput_blocks50emb_layers1bias', 'model_ema.diffusion_modelinput_blocks50out_layers0weight', 'model_ema.diffusion_modelinput_blocks50out_layers0bias', 'model_ema.diffusion_modelinput_blocks50out_layers3weight', 'model_ema.diffusion_modelinput_blocks50out_layers3bias', 'model_ema.diffusion_modelinput_blocks51normweight', 'model_ema.diffusion_modelinput_blocks51normbias', 'model_ema.diffusion_modelinput_blocks51proj_inweight', 'model_ema.diffusion_modelinput_blocks51proj_inbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks51proj_outweight', 'model_ema.diffusion_modelinput_blocks51proj_outbias', 'model_ema.diffusion_modelinput_blocks60opweight', 'model_ema.diffusion_modelinput_blocks60opbias', 'model_ema.diffusion_modelinput_blocks70in_layers0weight', 'model_ema.diffusion_modelinput_blocks70in_layers0bias', 'model_ema.diffusion_modelinput_blocks70in_layers2weight', 'model_ema.diffusion_modelinput_blocks70in_layers2bias', 'model_ema.diffusion_modelinput_blocks70emb_layers1weight', 'model_ema.diffusion_modelinput_blocks70emb_layers1bias', 'model_ema.diffusion_modelinput_blocks70out_layers0weight', 'model_ema.diffusion_modelinput_blocks70out_layers0bias', 'model_ema.diffusion_modelinput_blocks70out_layers3weight', 'model_ema.diffusion_modelinput_blocks70out_layers3bias', 'model_ema.diffusion_modelinput_blocks70skip_connectionweight', 'model_ema.diffusion_modelinput_blocks70skip_connectionbias', 'model_ema.diffusion_modelinput_blocks71normweight', 'model_ema.diffusion_modelinput_blocks71normbias', 'model_ema.diffusion_modelinput_blocks71proj_inweight', 'model_ema.diffusion_modelinput_blocks71proj_inbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks71proj_outweight', 'model_ema.diffusion_modelinput_blocks71proj_outbias', 'model_ema.diffusion_modelinput_blocks80in_layers0weight', 'model_ema.diffusion_modelinput_blocks80in_layers0bias', 'model_ema.diffusion_modelinput_blocks80in_layers2weight', 'model_ema.diffusion_modelinput_blocks80in_layers2bias', 'model_ema.diffusion_modelinput_blocks80emb_layers1weight', 'model_ema.diffusion_modelinput_blocks80emb_layers1bias', 'model_ema.diffusion_modelinput_blocks80out_layers0weight', 'model_ema.diffusion_modelinput_blocks80out_layers0bias', 'model_ema.diffusion_modelinput_blocks80out_layers3weight', 'model_ema.diffusion_modelinput_blocks80out_layers3bias', 'model_ema.diffusion_modelinput_blocks81normweight', 'model_ema.diffusion_modelinput_blocks81normbias', 'model_ema.diffusion_modelinput_blocks81proj_inweight', 'model_ema.diffusion_modelinput_blocks81proj_inbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks81proj_outweight', 'model_ema.diffusion_modelinput_blocks81proj_outbias', 'model_ema.diffusion_modelinput_blocks90opweight', 'model_ema.diffusion_modelinput_blocks90opbias', 'model_ema.diffusion_modelinput_blocks100in_layers0weight', 'model_ema.diffusion_modelinput_blocks100in_layers0bias', 'model_ema.diffusion_modelinput_blocks100in_layers2weight', 'model_ema.diffusion_modelinput_blocks100in_layers2bias', 'model_ema.diffusion_modelinput_blocks100emb_layers1weight', 'model_ema.diffusion_modelinput_blocks100emb_layers1bias', 'model_ema.diffusion_modelinput_blocks100out_layers0weight', 'model_ema.diffusion_modelinput_blocks100out_layers0bias', 'model_ema.diffusion_modelinput_blocks100out_layers3weight', 'model_ema.diffusion_modelinput_blocks100out_layers3bias', 'model_ema.diffusion_modelinput_blocks110in_layers0weight', 'model_ema.diffusion_modelinput_blocks110in_layers0bias', 'model_ema.diffusion_modelinput_blocks110in_layers2weight', 'model_ema.diffusion_modelinput_blocks110in_layers2bias', 'model_ema.diffusion_modelinput_blocks110emb_layers1weight', 'model_ema.diffusion_modelinput_blocks110emb_layers1bias', 'model_ema.diffusion_modelinput_blocks110out_layers0weight', 'model_ema.diffusion_modelinput_blocks110out_layers0bias', 'model_ema.diffusion_modelinput_blocks110out_layers3weight', 'model_ema.diffusion_modelinput_blocks110out_layers3bias', 'model_ema.diffusion_modelmiddle_block0in_layers0weight', 'model_ema.diffusion_modelmiddle_block0in_layers0bias', 'model_ema.diffusion_modelmiddle_block0in_layers2weight', 'model_ema.diffusion_modelmiddle_block0in_layers2bias', 'model_ema.diffusion_modelmiddle_block0emb_layers1weight', 'model_ema.diffusion_modelmiddle_block0emb_layers1bias', 'model_ema.diffusion_modelmiddle_block0out_layers0weight', 'model_ema.diffusion_modelmiddle_block0out_layers0bias', 'model_ema.diffusion_modelmiddle_block0out_layers3weight', 'model_ema.diffusion_modelmiddle_block0out_layers3bias', 'model_ema.diffusion_modelmiddle_block1normweight', 'model_ema.diffusion_modelmiddle_block1normbias', 'model_ema.diffusion_modelmiddle_block1proj_inweight', 'model_ema.diffusion_modelmiddle_block1proj_inbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3bias', 'model_ema.diffusion_modelmiddle_block1proj_outweight', 'model_ema.diffusion_modelmiddle_block1proj_outbias', 'model_ema.diffusion_modelmiddle_block2in_layers0weight', 'model_ema.diffusion_modelmiddle_block2in_layers0bias', 'model_ema.diffusion_modelmiddle_block2in_layers2weight', 'model_ema.diffusion_modelmiddle_block2in_layers2bias', 'model_ema.diffusion_modelmiddle_block2emb_layers1weight', 'model_ema.diffusion_modelmiddle_block2emb_layers1bias', 'model_ema.diffusion_modelmiddle_block2out_layers0weight', 'model_ema.diffusion_modelmiddle_block2out_layers0bias', 'model_ema.diffusion_modelmiddle_block2out_layers3weight', 'model_ema.diffusion_modelmiddle_block2out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00in_layers0weight', 'model_ema.diffusion_modeloutput_blocks00in_layers0bias', 'model_ema.diffusion_modeloutput_blocks00in_layers2weight', 'model_ema.diffusion_modeloutput_blocks00in_layers2bias', 'model_ema.diffusion_modeloutput_blocks00emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks00emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks00out_layers0weight', 'model_ema.diffusion_modeloutput_blocks00out_layers0bias', 'model_ema.diffusion_modeloutput_blocks00out_layers3weight', 'model_ema.diffusion_modeloutput_blocks00out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks00skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks10in_layers0weight', 'model_ema.diffusion_modeloutput_blocks10in_layers0bias', 'model_ema.diffusion_modeloutput_blocks10in_layers2weight', 'model_ema.diffusion_modeloutput_blocks10in_layers2bias', 'model_ema.diffusion_modeloutput_blocks10emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks10emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks10out_layers0weight', 'model_ema.diffusion_modeloutput_blocks10out_layers0bias', 'model_ema.diffusion_modeloutput_blocks10out_layers3weight', 'model_ema.diffusion_modeloutput_blocks10out_layers3bias', 'model_ema.diffusion_modeloutput_blocks10skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks10skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks20in_layers0weight', 'model_ema.diffusion_modeloutput_blocks20in_layers0bias', 'model_ema.diffusion_modeloutput_blocks20in_layers2weight', 'model_ema.diffusion_modeloutput_blocks20in_layers2bias', 'model_ema.diffusion_modeloutput_blocks20emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks20emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks20out_layers0weight', 'model_ema.diffusion_modeloutput_blocks20out_layers0bias', 'model_ema.diffusion_modeloutput_blocks20out_layers3weight', 'model_ema.diffusion_modeloutput_blocks20out_layers3bias', 'model_ema.diffusion_modeloutput_blocks20skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks20skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks21convweight', 'model_ema.diffusion_modeloutput_blocks21convbias', 'model_ema.diffusion_modeloutput_blocks30in_layers0weight', 'model_ema.diffusion_modeloutput_blocks30in_layers0bias', 'model_ema.diffusion_modeloutput_blocks30in_layers2weight', 'model_ema.diffusion_modeloutput_blocks30in_layers2bias', 'model_ema.diffusion_modeloutput_blocks30emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks30emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks30out_layers0weight', 'model_ema.diffusion_modeloutput_blocks30out_layers0bias', 'model_ema.diffusion_modeloutput_blocks30out_layers3weight', 'model_ema.diffusion_modeloutput_blocks30out_layers3bias', 'model_ema.diffusion_modeloutput_blocks30skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks30skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks31normweight', 'model_ema.diffusion_modeloutput_blocks31normbias', 'model_ema.diffusion_modeloutput_blocks31proj_inweight', 'model_ema.diffusion_modeloutput_blocks31proj_inbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks31proj_outweight', 'model_ema.diffusion_modeloutput_blocks31proj_outbias', 'model_ema.diffusion_modeloutput_blocks40in_layers0weight', 'model_ema.diffusion_modeloutput_blocks40in_layers0bias', 'model_ema.diffusion_modeloutput_blocks40in_layers2weight', 'model_ema.diffusion_modeloutput_blocks40in_layers2bias', 'model_ema.diffusion_modeloutput_blocks40emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks40emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks40out_layers0weight', 'model_ema.diffusion_modeloutput_blocks40out_layers0bias', 'model_ema.diffusion_modeloutput_blocks40out_layers3weight', 'model_ema.diffusion_modeloutput_blocks40out_layers3bias', 'model_ema.diffusion_modeloutput_blocks40skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks40skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks41normweight', 'model_ema.diffusion_modeloutput_blocks41normbias', 'model_ema.diffusion_modeloutput_blocks41proj_inweight', 'model_ema.diffusion_modeloutput_blocks41proj_inbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks41proj_outweight', 'model_ema.diffusion_modeloutput_blocks41proj_outbias', 'model_ema.diffusion_modeloutput_blocks50in_layers0weight', 'model_ema.diffusion_modeloutput_blocks50in_layers0bias', 'model_ema.diffusion_modeloutput_blocks50in_layers2weight', 'model_ema.diffusion_modeloutput_blocks50in_layers2bias', 'model_ema.diffusion_modeloutput_blocks50emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks50emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks50out_layers0weight', 'model_ema.diffusion_modeloutput_blocks50out_layers0bias', 'model_ema.diffusion_modeloutput_blocks50out_layers3weight', 'model_ema.diffusion_modeloutput_blocks50out_layers3bias', 'model_ema.diffusion_modeloutput_blocks50skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks50skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks51normweight', 'model_ema.diffusion_modeloutput_blocks51normbias', 'model_ema.diffusion_modeloutput_blocks51proj_inweight', 'model_ema.diffusion_modeloutput_blocks51proj_inbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks51proj_outweight', 'model_ema.diffusion_modeloutput_blocks51proj_outbias', 'model_ema.diffusion_modeloutput_blocks52convweight', 'model_ema.diffusion_modeloutput_blocks52convbias', 'model_ema.diffusion_modeloutput_blocks60in_layers0weight', 'model_ema.diffusion_modeloutput_blocks60in_layers0bias', 'model_ema.diffusion_modeloutput_blocks60in_layers2weight', 'model_ema.diffusion_modeloutput_blocks60in_layers2bias', 'model_ema.diffusion_modeloutput_blocks60emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks60emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks60out_layers0weight', 'model_ema.diffusion_modeloutput_blocks60out_layers0bias', 'model_ema.diffusion_modeloutput_blocks60out_layers3weight', 'model_ema.diffusion_modeloutput_blocks60out_layers3bias', 'model_ema.diffusion_modeloutput_blocks60skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks60skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks61normweight', 'model_ema.diffusion_modeloutput_blocks61normbias', 'model_ema.diffusion_modeloutput_blocks61proj_inweight', 'model_ema.diffusion_modeloutput_blocks61proj_inbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks61proj_outweight', 'model_ema.diffusion_modeloutput_blocks61proj_outbias', 'model_ema.diffusion_modeloutput_blocks70in_layers0weight', 'model_ema.diffusion_modeloutput_blocks70in_layers0bias', 'model_ema.diffusion_modeloutput_blocks70in_layers2weight', 'model_ema.diffusion_modeloutput_blocks70in_layers2bias', 'model_ema.diffusion_modeloutput_blocks70emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks70emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks70out_layers0weight', 'model_ema.diffusion_modeloutput_blocks70out_layers0bias', 'model_ema.diffusion_modeloutput_blocks70out_layers3weight', 'model_ema.diffusion_modeloutput_blocks70out_layers3bias', 'model_ema.diffusion_modeloutput_blocks70skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks70skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks71normweight', 'model_ema.diffusion_modeloutput_blocks71normbias', 'model_ema.diffusion_modeloutput_blocks71proj_inweight', 'model_ema.diffusion_modeloutput_blocks71proj_inbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks71proj_outweight', 'model_ema.diffusion_modeloutput_blocks71proj_outbias', 'model_ema.diffusion_modeloutput_blocks80in_layers0weight', 'model_ema.diffusion_modeloutput_blocks80in_layers0bias', 'model_ema.diffusion_modeloutput_blocks80in_layers2weight', 'model_ema.diffusion_modeloutput_blocks80in_layers2bias', 'model_ema.diffusion_modeloutput_blocks80emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks80emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks80out_layers0weight', 'model_ema.diffusion_modeloutput_blocks80out_layers0bias', 'model_ema.diffusion_modeloutput_blocks80out_layers3weight', 'model_ema.diffusion_modeloutput_blocks80out_layers3bias', 'model_ema.diffusion_modeloutput_blocks80skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks80skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks81normweight', 'model_ema.diffusion_modeloutput_blocks81normbias', 'model_ema.diffusion_modeloutput_blocks81proj_inweight', 'model_ema.diffusion_modeloutput_blocks81proj_inbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks81proj_outweight', 'model_ema.diffusion_modeloutput_blocks81proj_outbias', 'model_ema.diffusion_modeloutput_blocks82convweight', 'model_ema.diffusion_modeloutput_blocks82convbias', 'model_ema.diffusion_modeloutput_blocks90in_layers0weight', 'model_ema.diffusion_modeloutput_blocks90in_layers0bias', 'model_ema.diffusion_modeloutput_blocks90in_layers2weight', 'model_ema.diffusion_modeloutput_blocks90in_layers2bias', 'model_ema.diffusion_modeloutput_blocks90emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks90emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks90out_layers0weight', 'model_ema.diffusion_modeloutput_blocks90out_layers0bias', 'model_ema.diffusion_modeloutput_blocks90out_layers3weight', 'model_ema.diffusion_modeloutput_blocks90out_layers3bias', 'model_ema.diffusion_modeloutput_blocks90skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks90skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks91normweight', 'model_ema.diffusion_modeloutput_blocks91normbias', 'model_ema.diffusion_modeloutput_blocks91proj_inweight', 'model_ema.diffusion_modeloutput_blocks91proj_inbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks91proj_outweight', 'model_ema.diffusion_modeloutput_blocks91proj_outbias', 'model_ema.diffusion_modeloutput_blocks100in_layers0weight', 'model_ema.diffusion_modeloutput_blocks100in_layers0bias', 'model_ema.diffusion_modeloutput_blocks100in_layers2weight', 'model_ema.diffusion_modeloutput_blocks100in_layers2bias', 'model_ema.diffusion_modeloutput_blocks100emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks100emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks100out_layers0weight', 'model_ema.diffusion_modeloutput_blocks100out_layers0bias', 'model_ema.diffusion_modeloutput_blocks100out_layers3weight', 'model_ema.diffusion_modeloutput_blocks100out_layers3bias', 'model_ema.diffusion_modeloutput_blocks100skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks100skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks101normweight', 'model_ema.diffusion_modeloutput_blocks101normbias', 'model_ema.diffusion_modeloutput_blocks101proj_inweight', 'model_ema.diffusion_modeloutput_blocks101proj_inbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks101proj_outweight', 'model_ema.diffusion_modeloutput_blocks101proj_outbias', 'model_ema.diffusion_modeloutput_blocks110in_layers0weight', 'model_ema.diffusion_modeloutput_blocks110in_layers0bias', 'model_ema.diffusion_modeloutput_blocks110in_layers2weight', 'model_ema.diffusion_modeloutput_blocks110in_layers2bias', 'model_ema.diffusion_modeloutput_blocks110emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks110emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks110out_layers0weight', 'model_ema.diffusion_modeloutput_blocks110out_layers0bias', 'model_ema.diffusion_modeloutput_blocks110out_layers3weight', 'model_ema.diffusion_modeloutput_blocks110out_layers3bias', 'model_ema.diffusion_modeloutput_blocks110skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks110skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks111normweight', 'model_ema.diffusion_modeloutput_blocks111normbias', 'model_ema.diffusion_modeloutput_blocks111proj_inweight', 'model_ema.diffusion_modeloutput_blocks111proj_inbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks111proj_outweight', 'model_ema.diffusion_modeloutput_blocks111proj_outbias', 'model_ema.diffusion_modelout0weight', 'model_ema.diffusion_modelout0bias', 'model_ema.diffusion_modelout2weight', 'model_ema.diffusion_modelout2bias']\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/test_tube.py:104: LightningDeprecationWarning: The TestTubeLogger is deprecated since v1.5 and will be removed in v1.7. We recommend switching to the `pytorch_lightning.loggers.TensorBoardLogger` as an alternative.\n",
      "  rank_zero_deprecation(\n",
      "Monitoring val/loss_simple_ema as checkpoint metric.\n",
      "Merged modelckpt-cfg: \n",
      "{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/training2023-07-14T13-08-03_celebbasis/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/loss_simple_ema', 'save_top_k': 1, 'every_n_train_steps': 400}}\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='ddp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='ddp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "[FaceIdDataset] loaded from /content/datasets/stylegan/ffhq.pickle. (id*max_img=2*1, train2000+reg0=total2000)\n",
      "[FaceIdDataset] loaded from /content/datasets/stylegan/ffhq.pickle. (id*max_img=1*1, train1+reg0=total1)\n",
      "[FaceIdDataset] loaded from /content/datasets/stylegan/ffhq.pickle. (id*max_img=2*1, train2000+reg0=total2000)\n",
      "[FaceIdDataset] loaded from /content/datasets/stylegan/ffhq.pickle. (id*max_img=1*1, train1+reg0=total1)\n",
      "#### Data #####\n",
      "train, FaceIdDatasetOneShot, 2000\n",
      "validation, FaceIdDatasetOneShot, 1\n",
      "accumulate_grad_batches = 1\n",
      "Setting learning rate to 5.00e-03 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 1 (batchsize) * 5.00e-03 (base_lr)\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:275: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "  rank_zero_deprecation(\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:284: LightningDeprecationWarning: Base `LightningModule.on_train_batch_start` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:291: LightningDeprecationWarning: Base `Callback.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 23\n",
      "initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2023-07-14 13:10:28.144018: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 13:10:30.215528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Project config\n",
      "model:\n",
      "  base_learning_rate: 0.005\n",
      "  target: ldm.models.diffusion.ddpm.LatentDiffusion\n",
      "  params:\n",
      "    linear_start: 0.00085\n",
      "    linear_end: 0.012\n",
      "    num_timesteps_cond: 1\n",
      "    log_every_t: 200\n",
      "    timesteps: 1000\n",
      "    first_stage_key: image\n",
      "    cond_stage_key: caption\n",
      "    image_size: 64\n",
      "    channels: 4\n",
      "    cond_stage_trainable: true\n",
      "    conditioning_key: crossattn\n",
      "    monitor: val/loss_simple_ema\n",
      "    scale_factor: 0.18215\n",
      "    use_ema: false\n",
      "    embedding_reg_weight: 0.0\n",
      "    unfreeze_model: false\n",
      "    model_lr: 0.0\n",
      "    personalization_config:\n",
      "      target: ldm.modules.embedding_manager.EmbeddingManagerId\n",
      "      params:\n",
      "        placeholder_strings:\n",
      "        - sks\n",
      "        - ks\n",
      "        - ata\n",
      "        - tre\n",
      "        - ry\n",
      "        - bop\n",
      "        - rn\n",
      "        - '&'\n",
      "        - '*'\n",
      "        - '`'\n",
      "        initializer_words:\n",
      "        - face\n",
      "        - face\n",
      "        - face\n",
      "        - face\n",
      "        - face\n",
      "        - face\n",
      "        - face\n",
      "        - face\n",
      "        - face\n",
      "        - face\n",
      "        max_ids: 10\n",
      "        num_embeds_per_token: 2\n",
      "        meta_mlp_depth: 1\n",
      "        loss_type: none\n",
      "        meta_inner_dim: 512\n",
      "        meta_heads: 1\n",
      "        use_rm_mlp: false\n",
      "        test_mode: coefficient\n",
      "        momentum: 0.9\n",
      "        save_fp16: false\n",
      "        embedding_manager_ckpt: ''\n",
      "    unet_config:\n",
      "      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n",
      "      params:\n",
      "        image_size: 32\n",
      "        in_channels: 4\n",
      "        out_channels: 4\n",
      "        model_channels: 320\n",
      "        attention_resolutions:\n",
      "        - 4\n",
      "        - 2\n",
      "        - 1\n",
      "        num_res_blocks: 2\n",
      "        channel_mult:\n",
      "        - 1\n",
      "        - 2\n",
      "        - 4\n",
      "        - 4\n",
      "        num_heads: 8\n",
      "        use_spatial_transformer: true\n",
      "        transformer_depth: 1\n",
      "        context_dim: 768\n",
      "        use_checkpoint: true\n",
      "        legacy: false\n",
      "    first_stage_config:\n",
      "      target: ldm.models.autoencoder.AutoencoderKL\n",
      "      params:\n",
      "        embed_dim: 4\n",
      "        monitor: val/rec_loss\n",
      "        ddconfig:\n",
      "          double_z: true\n",
      "          z_channels: 4\n",
      "          resolution: 512\n",
      "          in_channels: 3\n",
      "          out_ch: 3\n",
      "          ch: 128\n",
      "          ch_mult:\n",
      "          - 1\n",
      "          - 2\n",
      "          - 4\n",
      "          - 4\n",
      "          num_res_blocks: 2\n",
      "          attn_resolutions: []\n",
      "          dropout: 0.0\n",
      "        lossconfig:\n",
      "          target: torch.nn.Identity\n",
      "    cond_stage_config:\n",
      "      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder\n",
      "      params:\n",
      "        use_celeb: true\n",
      "        use_svd: true\n",
      "        rm_repeats: true\n",
      "        celeb_txt: ./infer_images/wiki_names_v2.txt\n",
      "        n_components: 512\n",
      "        use_sample_reduce: false\n",
      "        n_samples: 513\n",
      "        use_flatten: false\n",
      "        num_embeds_per_token: 2\n",
      "    ckpt_path: ../pretrained/sd-v1-4-full-ema.ckpt\n",
      "data:\n",
      "  target: main.DataModuleFromConfig\n",
      "  params:\n",
      "    batch_size: 1\n",
      "    num_workers: 4\n",
      "    wrap: false\n",
      "    train:\n",
      "      target: ldm.data.face_id.FaceIdDatasetOneShot\n",
      "      params:\n",
      "        pickle_path: /content/datasets/stylegan/ffhq.pickle\n",
      "        split: train\n",
      "        num_ids: 2\n",
      "        specific_ids:\n",
      "        - 1\n",
      "        - 2\n",
      "        images_per_id: 1\n",
      "        repeats: 1000\n",
      "        reg_ids: 1000\n",
      "        reg_repeats: 0\n",
      "        diff_cnt: 0\n",
      "    validation:\n",
      "      target: ldm.data.face_id.FaceIdDatasetOneShot\n",
      "      params:\n",
      "        pickle_path: /content/datasets/stylegan/ffhq.pickle\n",
      "        split: val\n",
      "        num_ids: 1\n",
      "        images_per_id: 1\n",
      "        repeats: 1\n",
      "        reg_repeats: 0\n",
      "        diff_cnt: 0\n",
      "\n",
      "Lightning config\n",
      "modelcheckpoint:\n",
      "  params:\n",
      "    every_n_train_steps: 400\n",
      "callbacks:\n",
      "  image_logger:\n",
      "    target: main.ImageLogger\n",
      "    params:\n",
      "      batch_frequency: 1200\n",
      "      max_images: 8\n",
      "      increase_log_steps: false\n",
      "trainer:\n",
      "  benchmark: true\n",
      "  max_steps: 1600\n",
      "  accelerator: ddp\n",
      "  gpus: 0,\n",
      "\n",
      "\n",
      "  | Name              | Type               | Params\n",
      "---------------------------------------------------------\n",
      "0 | model             | DiffusionWrapper   | 859 M \n",
      "1 | first_stage_model | AutoencoderKL      | 83.7 M\n",
      "2 | cond_stage_model  | FrozenCLIPEmbedder | 123 M \n",
      "3 | embedding_manager | EmbeddingManagerId | 65.7 M\n",
      "---------------------------------------------------------\n",
      "65.7 M    Trainable params\n",
      "1.1 B     Non-trainable params\n",
      "1.1 B     Total params\n",
      "4,527.667 Total estimated model params size (MB)\n",
      "Validation sanity check:   0% 0/1 [00:00<?, ?it/s][Embedding Manager] test_mode: coefficient\n",
      "[Embedding Manager] test_mode: coefficient\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "Global seed set to 23\n",
      "Epoch 0:   0% 0/2001 [00:00<?, ?it/s] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:227: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "Epoch 0:  20% 400/2001 [02:21<09:25,  2.83it/s, loss=0.0589, v_num=0, train/loss_simple_step=0.189, train/loss_vlb_step=0.00209, train/loss_step=0.189, train/loss_emb_reg_step=0.000, global_step=399.0]    /usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:644: UserWarning: ModelCheckpoint(monitor='val/loss_simple_ema') not found in the returned metrics: ['train/loss_simple', 'train/loss_simple_step', 'train/loss_vlb', 'train/loss_vlb_step', 'train/loss', 'train/loss_step', 'train/loss_emb_reg', 'train/loss_emb_reg_step', 'global_step']. HINT: Did you call self.log('val/loss_simple_ema', value) in the LightningModule?\n",
      "  warning_cache.warn(m)\n",
      "Epoch 0, global step 399: val/loss_simple_ema was not in top 1\n",
      "Epoch 0:  33% 660/2001 [03:52<07:52,  2.84it/s, loss=0.0469, v_num=0, train/loss_simple_step=0.0325, train/loss_vlb_step=0.000378, train/loss_step=0.0325, train/loss_emb_reg_step=0.000, global_step=659.0]"
     ]
    }
   ],
   "source": [
    "!cd CelebBasis && bash ./01_start_train.sh ../pretrained/sd-v1-4-full-ema.ckpt ./configs/stable-diffusion/aigc_id_colab.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#4. Test\n",
    "Modify the following `\"traininYYYY-MM-DDTHH-MM-SS_celebbasis/\"` to the project folder under `./CelebBasis/logs/` and run the test.\n",
    "\n",
    "The generated images will be output under `./CelebBasis/outputs/traininYYYY-MM-DDTHH-MM-SS_celebbasis/`. Enjoy it!"
   ],
   "metadata": {
    "id": "KwCsuFfNusa4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!cd CelebBasis && bash ./02_start_test.sh \"../pretrained/sd-v1-4-full-ema.ckpt\" \"./infer_images/example_prompt.txt\" \"training2023-07-13T14-55-56_celebbasis\" 4"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6-U6WMzqBYd",
    "outputId": "515f1050-4099-409c-cb9f-ffbcfe4500f3"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "logs/training2023-07-13T14-55-56_celebbasis/configs/training2023-07-13T14-55-56-project.yaml\n",
      "embeddings_gs-1599.pt\n",
      "Global seed set to 42\n",
      "Loading model from ../pretrained/sd-v1-4-full-ema.ckpt\n",
      "Global Step: 470000\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.post_layernorm.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'logit_scale', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'visual_projection.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'text_projection.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[celebs cols_embeddings len]: [646, 638, 311, 118, 25, 2]\n",
      "[(col_0) celebs ori]: torch.Size([646, 768]) tensor(5.3118e-05) tensor(-0.0405) tensor(0.0509)\n",
      "[(col_0) celebs c_mean]: tensor(-1.2509e-05) tensor(-0.0091) tensor(0.0112)\n",
      "[(col_0) celebs pca_base]: torch.Size([512, 768]) tensor(-0.0003) tensor(-0.1054) tensor(0.0999) tensor(1.0000)\n",
      "[(col_0) celebs embeddings loaded]: torch.Size([513, 768]) (device:cuda)\n",
      "[(col_1) celebs ori]: torch.Size([638, 768]) tensor(-9.8908e-06) tensor(-0.0414) tensor(0.0464)\n",
      "[(col_1) celebs c_mean]: tensor(-3.7355e-06) tensor(-0.0087) tensor(0.0065)\n",
      "[(col_1) celebs pca_base]: torch.Size([512, 768]) tensor(1.3023e-05) tensor(-0.1589) tensor(0.2419) tensor(1.)\n",
      "[(col_1) celebs embeddings loaded]: torch.Size([513, 768]) (device:cuda)\n",
      "[all celebs embeddings loaded] shape = torch.Size([2, 513, 768]) (device:cuda) flatten=False\n",
      "Restored from ../pretrained/sd-v1-4-full-ema.ckpt with 0 missing and 688 unexpected keys\n",
      "Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'model_ema.diffusion_modeltime_embed0weight', 'model_ema.diffusion_modeltime_embed0bias', 'model_ema.diffusion_modeltime_embed2weight', 'model_ema.diffusion_modeltime_embed2bias', 'model_ema.diffusion_modelinput_blocks00weight', 'model_ema.diffusion_modelinput_blocks00bias', 'model_ema.diffusion_modelinput_blocks10in_layers0weight', 'model_ema.diffusion_modelinput_blocks10in_layers0bias', 'model_ema.diffusion_modelinput_blocks10in_layers2weight', 'model_ema.diffusion_modelinput_blocks10in_layers2bias', 'model_ema.diffusion_modelinput_blocks10emb_layers1weight', 'model_ema.diffusion_modelinput_blocks10emb_layers1bias', 'model_ema.diffusion_modelinput_blocks10out_layers0weight', 'model_ema.diffusion_modelinput_blocks10out_layers0bias', 'model_ema.diffusion_modelinput_blocks10out_layers3weight', 'model_ema.diffusion_modelinput_blocks10out_layers3bias', 'model_ema.diffusion_modelinput_blocks11normweight', 'model_ema.diffusion_modelinput_blocks11normbias', 'model_ema.diffusion_modelinput_blocks11proj_inweight', 'model_ema.diffusion_modelinput_blocks11proj_inbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks11proj_outweight', 'model_ema.diffusion_modelinput_blocks11proj_outbias', 'model_ema.diffusion_modelinput_blocks20in_layers0weight', 'model_ema.diffusion_modelinput_blocks20in_layers0bias', 'model_ema.diffusion_modelinput_blocks20in_layers2weight', 'model_ema.diffusion_modelinput_blocks20in_layers2bias', 'model_ema.diffusion_modelinput_blocks20emb_layers1weight', 'model_ema.diffusion_modelinput_blocks20emb_layers1bias', 'model_ema.diffusion_modelinput_blocks20out_layers0weight', 'model_ema.diffusion_modelinput_blocks20out_layers0bias', 'model_ema.diffusion_modelinput_blocks20out_layers3weight', 'model_ema.diffusion_modelinput_blocks20out_layers3bias', 'model_ema.diffusion_modelinput_blocks21normweight', 'model_ema.diffusion_modelinput_blocks21normbias', 'model_ema.diffusion_modelinput_blocks21proj_inweight', 'model_ema.diffusion_modelinput_blocks21proj_inbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks21proj_outweight', 'model_ema.diffusion_modelinput_blocks21proj_outbias', 'model_ema.diffusion_modelinput_blocks30opweight', 'model_ema.diffusion_modelinput_blocks30opbias', 'model_ema.diffusion_modelinput_blocks40in_layers0weight', 'model_ema.diffusion_modelinput_blocks40in_layers0bias', 'model_ema.diffusion_modelinput_blocks40in_layers2weight', 'model_ema.diffusion_modelinput_blocks40in_layers2bias', 'model_ema.diffusion_modelinput_blocks40emb_layers1weight', 'model_ema.diffusion_modelinput_blocks40emb_layers1bias', 'model_ema.diffusion_modelinput_blocks40out_layers0weight', 'model_ema.diffusion_modelinput_blocks40out_layers0bias', 'model_ema.diffusion_modelinput_blocks40out_layers3weight', 'model_ema.diffusion_modelinput_blocks40out_layers3bias', 'model_ema.diffusion_modelinput_blocks40skip_connectionweight', 'model_ema.diffusion_modelinput_blocks40skip_connectionbias', 'model_ema.diffusion_modelinput_blocks41normweight', 'model_ema.diffusion_modelinput_blocks41normbias', 'model_ema.diffusion_modelinput_blocks41proj_inweight', 'model_ema.diffusion_modelinput_blocks41proj_inbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks41proj_outweight', 'model_ema.diffusion_modelinput_blocks41proj_outbias', 'model_ema.diffusion_modelinput_blocks50in_layers0weight', 'model_ema.diffusion_modelinput_blocks50in_layers0bias', 'model_ema.diffusion_modelinput_blocks50in_layers2weight', 'model_ema.diffusion_modelinput_blocks50in_layers2bias', 'model_ema.diffusion_modelinput_blocks50emb_layers1weight', 'model_ema.diffusion_modelinput_blocks50emb_layers1bias', 'model_ema.diffusion_modelinput_blocks50out_layers0weight', 'model_ema.diffusion_modelinput_blocks50out_layers0bias', 'model_ema.diffusion_modelinput_blocks50out_layers3weight', 'model_ema.diffusion_modelinput_blocks50out_layers3bias', 'model_ema.diffusion_modelinput_blocks51normweight', 'model_ema.diffusion_modelinput_blocks51normbias', 'model_ema.diffusion_modelinput_blocks51proj_inweight', 'model_ema.diffusion_modelinput_blocks51proj_inbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks51proj_outweight', 'model_ema.diffusion_modelinput_blocks51proj_outbias', 'model_ema.diffusion_modelinput_blocks60opweight', 'model_ema.diffusion_modelinput_blocks60opbias', 'model_ema.diffusion_modelinput_blocks70in_layers0weight', 'model_ema.diffusion_modelinput_blocks70in_layers0bias', 'model_ema.diffusion_modelinput_blocks70in_layers2weight', 'model_ema.diffusion_modelinput_blocks70in_layers2bias', 'model_ema.diffusion_modelinput_blocks70emb_layers1weight', 'model_ema.diffusion_modelinput_blocks70emb_layers1bias', 'model_ema.diffusion_modelinput_blocks70out_layers0weight', 'model_ema.diffusion_modelinput_blocks70out_layers0bias', 'model_ema.diffusion_modelinput_blocks70out_layers3weight', 'model_ema.diffusion_modelinput_blocks70out_layers3bias', 'model_ema.diffusion_modelinput_blocks70skip_connectionweight', 'model_ema.diffusion_modelinput_blocks70skip_connectionbias', 'model_ema.diffusion_modelinput_blocks71normweight', 'model_ema.diffusion_modelinput_blocks71normbias', 'model_ema.diffusion_modelinput_blocks71proj_inweight', 'model_ema.diffusion_modelinput_blocks71proj_inbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks71proj_outweight', 'model_ema.diffusion_modelinput_blocks71proj_outbias', 'model_ema.diffusion_modelinput_blocks80in_layers0weight', 'model_ema.diffusion_modelinput_blocks80in_layers0bias', 'model_ema.diffusion_modelinput_blocks80in_layers2weight', 'model_ema.diffusion_modelinput_blocks80in_layers2bias', 'model_ema.diffusion_modelinput_blocks80emb_layers1weight', 'model_ema.diffusion_modelinput_blocks80emb_layers1bias', 'model_ema.diffusion_modelinput_blocks80out_layers0weight', 'model_ema.diffusion_modelinput_blocks80out_layers0bias', 'model_ema.diffusion_modelinput_blocks80out_layers3weight', 'model_ema.diffusion_modelinput_blocks80out_layers3bias', 'model_ema.diffusion_modelinput_blocks81normweight', 'model_ema.diffusion_modelinput_blocks81normbias', 'model_ema.diffusion_modelinput_blocks81proj_inweight', 'model_ema.diffusion_modelinput_blocks81proj_inbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks81proj_outweight', 'model_ema.diffusion_modelinput_blocks81proj_outbias', 'model_ema.diffusion_modelinput_blocks90opweight', 'model_ema.diffusion_modelinput_blocks90opbias', 'model_ema.diffusion_modelinput_blocks100in_layers0weight', 'model_ema.diffusion_modelinput_blocks100in_layers0bias', 'model_ema.diffusion_modelinput_blocks100in_layers2weight', 'model_ema.diffusion_modelinput_blocks100in_layers2bias', 'model_ema.diffusion_modelinput_blocks100emb_layers1weight', 'model_ema.diffusion_modelinput_blocks100emb_layers1bias', 'model_ema.diffusion_modelinput_blocks100out_layers0weight', 'model_ema.diffusion_modelinput_blocks100out_layers0bias', 'model_ema.diffusion_modelinput_blocks100out_layers3weight', 'model_ema.diffusion_modelinput_blocks100out_layers3bias', 'model_ema.diffusion_modelinput_blocks110in_layers0weight', 'model_ema.diffusion_modelinput_blocks110in_layers0bias', 'model_ema.diffusion_modelinput_blocks110in_layers2weight', 'model_ema.diffusion_modelinput_blocks110in_layers2bias', 'model_ema.diffusion_modelinput_blocks110emb_layers1weight', 'model_ema.diffusion_modelinput_blocks110emb_layers1bias', 'model_ema.diffusion_modelinput_blocks110out_layers0weight', 'model_ema.diffusion_modelinput_blocks110out_layers0bias', 'model_ema.diffusion_modelinput_blocks110out_layers3weight', 'model_ema.diffusion_modelinput_blocks110out_layers3bias', 'model_ema.diffusion_modelmiddle_block0in_layers0weight', 'model_ema.diffusion_modelmiddle_block0in_layers0bias', 'model_ema.diffusion_modelmiddle_block0in_layers2weight', 'model_ema.diffusion_modelmiddle_block0in_layers2bias', 'model_ema.diffusion_modelmiddle_block0emb_layers1weight', 'model_ema.diffusion_modelmiddle_block0emb_layers1bias', 'model_ema.diffusion_modelmiddle_block0out_layers0weight', 'model_ema.diffusion_modelmiddle_block0out_layers0bias', 'model_ema.diffusion_modelmiddle_block0out_layers3weight', 'model_ema.diffusion_modelmiddle_block0out_layers3bias', 'model_ema.diffusion_modelmiddle_block1normweight', 'model_ema.diffusion_modelmiddle_block1normbias', 'model_ema.diffusion_modelmiddle_block1proj_inweight', 'model_ema.diffusion_modelmiddle_block1proj_inbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3bias', 'model_ema.diffusion_modelmiddle_block1proj_outweight', 'model_ema.diffusion_modelmiddle_block1proj_outbias', 'model_ema.diffusion_modelmiddle_block2in_layers0weight', 'model_ema.diffusion_modelmiddle_block2in_layers0bias', 'model_ema.diffusion_modelmiddle_block2in_layers2weight', 'model_ema.diffusion_modelmiddle_block2in_layers2bias', 'model_ema.diffusion_modelmiddle_block2emb_layers1weight', 'model_ema.diffusion_modelmiddle_block2emb_layers1bias', 'model_ema.diffusion_modelmiddle_block2out_layers0weight', 'model_ema.diffusion_modelmiddle_block2out_layers0bias', 'model_ema.diffusion_modelmiddle_block2out_layers3weight', 'model_ema.diffusion_modelmiddle_block2out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00in_layers0weight', 'model_ema.diffusion_modeloutput_blocks00in_layers0bias', 'model_ema.diffusion_modeloutput_blocks00in_layers2weight', 'model_ema.diffusion_modeloutput_blocks00in_layers2bias', 'model_ema.diffusion_modeloutput_blocks00emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks00emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks00out_layers0weight', 'model_ema.diffusion_modeloutput_blocks00out_layers0bias', 'model_ema.diffusion_modeloutput_blocks00out_layers3weight', 'model_ema.diffusion_modeloutput_blocks00out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks00skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks10in_layers0weight', 'model_ema.diffusion_modeloutput_blocks10in_layers0bias', 'model_ema.diffusion_modeloutput_blocks10in_layers2weight', 'model_ema.diffusion_modeloutput_blocks10in_layers2bias', 'model_ema.diffusion_modeloutput_blocks10emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks10emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks10out_layers0weight', 'model_ema.diffusion_modeloutput_blocks10out_layers0bias', 'model_ema.diffusion_modeloutput_blocks10out_layers3weight', 'model_ema.diffusion_modeloutput_blocks10out_layers3bias', 'model_ema.diffusion_modeloutput_blocks10skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks10skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks20in_layers0weight', 'model_ema.diffusion_modeloutput_blocks20in_layers0bias', 'model_ema.diffusion_modeloutput_blocks20in_layers2weight', 'model_ema.diffusion_modeloutput_blocks20in_layers2bias', 'model_ema.diffusion_modeloutput_blocks20emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks20emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks20out_layers0weight', 'model_ema.diffusion_modeloutput_blocks20out_layers0bias', 'model_ema.diffusion_modeloutput_blocks20out_layers3weight', 'model_ema.diffusion_modeloutput_blocks20out_layers3bias', 'model_ema.diffusion_modeloutput_blocks20skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks20skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks21convweight', 'model_ema.diffusion_modeloutput_blocks21convbias', 'model_ema.diffusion_modeloutput_blocks30in_layers0weight', 'model_ema.diffusion_modeloutput_blocks30in_layers0bias', 'model_ema.diffusion_modeloutput_blocks30in_layers2weight', 'model_ema.diffusion_modeloutput_blocks30in_layers2bias', 'model_ema.diffusion_modeloutput_blocks30emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks30emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks30out_layers0weight', 'model_ema.diffusion_modeloutput_blocks30out_layers0bias', 'model_ema.diffusion_modeloutput_blocks30out_layers3weight', 'model_ema.diffusion_modeloutput_blocks30out_layers3bias', 'model_ema.diffusion_modeloutput_blocks30skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks30skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks31normweight', 'model_ema.diffusion_modeloutput_blocks31normbias', 'model_ema.diffusion_modeloutput_blocks31proj_inweight', 'model_ema.diffusion_modeloutput_blocks31proj_inbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks31proj_outweight', 'model_ema.diffusion_modeloutput_blocks31proj_outbias', 'model_ema.diffusion_modeloutput_blocks40in_layers0weight', 'model_ema.diffusion_modeloutput_blocks40in_layers0bias', 'model_ema.diffusion_modeloutput_blocks40in_layers2weight', 'model_ema.diffusion_modeloutput_blocks40in_layers2bias', 'model_ema.diffusion_modeloutput_blocks40emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks40emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks40out_layers0weight', 'model_ema.diffusion_modeloutput_blocks40out_layers0bias', 'model_ema.diffusion_modeloutput_blocks40out_layers3weight', 'model_ema.diffusion_modeloutput_blocks40out_layers3bias', 'model_ema.diffusion_modeloutput_blocks40skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks40skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks41normweight', 'model_ema.diffusion_modeloutput_blocks41normbias', 'model_ema.diffusion_modeloutput_blocks41proj_inweight', 'model_ema.diffusion_modeloutput_blocks41proj_inbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks41proj_outweight', 'model_ema.diffusion_modeloutput_blocks41proj_outbias', 'model_ema.diffusion_modeloutput_blocks50in_layers0weight', 'model_ema.diffusion_modeloutput_blocks50in_layers0bias', 'model_ema.diffusion_modeloutput_blocks50in_layers2weight', 'model_ema.diffusion_modeloutput_blocks50in_layers2bias', 'model_ema.diffusion_modeloutput_blocks50emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks50emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks50out_layers0weight', 'model_ema.diffusion_modeloutput_blocks50out_layers0bias', 'model_ema.diffusion_modeloutput_blocks50out_layers3weight', 'model_ema.diffusion_modeloutput_blocks50out_layers3bias', 'model_ema.diffusion_modeloutput_blocks50skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks50skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks51normweight', 'model_ema.diffusion_modeloutput_blocks51normbias', 'model_ema.diffusion_modeloutput_blocks51proj_inweight', 'model_ema.diffusion_modeloutput_blocks51proj_inbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks51proj_outweight', 'model_ema.diffusion_modeloutput_blocks51proj_outbias', 'model_ema.diffusion_modeloutput_blocks52convweight', 'model_ema.diffusion_modeloutput_blocks52convbias', 'model_ema.diffusion_modeloutput_blocks60in_layers0weight', 'model_ema.diffusion_modeloutput_blocks60in_layers0bias', 'model_ema.diffusion_modeloutput_blocks60in_layers2weight', 'model_ema.diffusion_modeloutput_blocks60in_layers2bias', 'model_ema.diffusion_modeloutput_blocks60emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks60emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks60out_layers0weight', 'model_ema.diffusion_modeloutput_blocks60out_layers0bias', 'model_ema.diffusion_modeloutput_blocks60out_layers3weight', 'model_ema.diffusion_modeloutput_blocks60out_layers3bias', 'model_ema.diffusion_modeloutput_blocks60skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks60skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks61normweight', 'model_ema.diffusion_modeloutput_blocks61normbias', 'model_ema.diffusion_modeloutput_blocks61proj_inweight', 'model_ema.diffusion_modeloutput_blocks61proj_inbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks61proj_outweight', 'model_ema.diffusion_modeloutput_blocks61proj_outbias', 'model_ema.diffusion_modeloutput_blocks70in_layers0weight', 'model_ema.diffusion_modeloutput_blocks70in_layers0bias', 'model_ema.diffusion_modeloutput_blocks70in_layers2weight', 'model_ema.diffusion_modeloutput_blocks70in_layers2bias', 'model_ema.diffusion_modeloutput_blocks70emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks70emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks70out_layers0weight', 'model_ema.diffusion_modeloutput_blocks70out_layers0bias', 'model_ema.diffusion_modeloutput_blocks70out_layers3weight', 'model_ema.diffusion_modeloutput_blocks70out_layers3bias', 'model_ema.diffusion_modeloutput_blocks70skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks70skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks71normweight', 'model_ema.diffusion_modeloutput_blocks71normbias', 'model_ema.diffusion_modeloutput_blocks71proj_inweight', 'model_ema.diffusion_modeloutput_blocks71proj_inbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks71proj_outweight', 'model_ema.diffusion_modeloutput_blocks71proj_outbias', 'model_ema.diffusion_modeloutput_blocks80in_layers0weight', 'model_ema.diffusion_modeloutput_blocks80in_layers0bias', 'model_ema.diffusion_modeloutput_blocks80in_layers2weight', 'model_ema.diffusion_modeloutput_blocks80in_layers2bias', 'model_ema.diffusion_modeloutput_blocks80emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks80emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks80out_layers0weight', 'model_ema.diffusion_modeloutput_blocks80out_layers0bias', 'model_ema.diffusion_modeloutput_blocks80out_layers3weight', 'model_ema.diffusion_modeloutput_blocks80out_layers3bias', 'model_ema.diffusion_modeloutput_blocks80skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks80skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks81normweight', 'model_ema.diffusion_modeloutput_blocks81normbias', 'model_ema.diffusion_modeloutput_blocks81proj_inweight', 'model_ema.diffusion_modeloutput_blocks81proj_inbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks81proj_outweight', 'model_ema.diffusion_modeloutput_blocks81proj_outbias', 'model_ema.diffusion_modeloutput_blocks82convweight', 'model_ema.diffusion_modeloutput_blocks82convbias', 'model_ema.diffusion_modeloutput_blocks90in_layers0weight', 'model_ema.diffusion_modeloutput_blocks90in_layers0bias', 'model_ema.diffusion_modeloutput_blocks90in_layers2weight', 'model_ema.diffusion_modeloutput_blocks90in_layers2bias', 'model_ema.diffusion_modeloutput_blocks90emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks90emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks90out_layers0weight', 'model_ema.diffusion_modeloutput_blocks90out_layers0bias', 'model_ema.diffusion_modeloutput_blocks90out_layers3weight', 'model_ema.diffusion_modeloutput_blocks90out_layers3bias', 'model_ema.diffusion_modeloutput_blocks90skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks90skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks91normweight', 'model_ema.diffusion_modeloutput_blocks91normbias', 'model_ema.diffusion_modeloutput_blocks91proj_inweight', 'model_ema.diffusion_modeloutput_blocks91proj_inbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks91proj_outweight', 'model_ema.diffusion_modeloutput_blocks91proj_outbias', 'model_ema.diffusion_modeloutput_blocks100in_layers0weight', 'model_ema.diffusion_modeloutput_blocks100in_layers0bias', 'model_ema.diffusion_modeloutput_blocks100in_layers2weight', 'model_ema.diffusion_modeloutput_blocks100in_layers2bias', 'model_ema.diffusion_modeloutput_blocks100emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks100emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks100out_layers0weight', 'model_ema.diffusion_modeloutput_blocks100out_layers0bias', 'model_ema.diffusion_modeloutput_blocks100out_layers3weight', 'model_ema.diffusion_modeloutput_blocks100out_layers3bias', 'model_ema.diffusion_modeloutput_blocks100skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks100skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks101normweight', 'model_ema.diffusion_modeloutput_blocks101normbias', 'model_ema.diffusion_modeloutput_blocks101proj_inweight', 'model_ema.diffusion_modeloutput_blocks101proj_inbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks101proj_outweight', 'model_ema.diffusion_modeloutput_blocks101proj_outbias', 'model_ema.diffusion_modeloutput_blocks110in_layers0weight', 'model_ema.diffusion_modeloutput_blocks110in_layers0bias', 'model_ema.diffusion_modeloutput_blocks110in_layers2weight', 'model_ema.diffusion_modeloutput_blocks110in_layers2bias', 'model_ema.diffusion_modeloutput_blocks110emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks110emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks110out_layers0weight', 'model_ema.diffusion_modeloutput_blocks110out_layers0bias', 'model_ema.diffusion_modeloutput_blocks110out_layers3weight', 'model_ema.diffusion_modeloutput_blocks110out_layers3bias', 'model_ema.diffusion_modeloutput_blocks110skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks110skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks111normweight', 'model_ema.diffusion_modeloutput_blocks111normbias', 'model_ema.diffusion_modeloutput_blocks111proj_inweight', 'model_ema.diffusion_modeloutput_blocks111proj_inbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks111proj_outweight', 'model_ema.diffusion_modeloutput_blocks111proj_outbias', 'model_ema.diffusion_modelout0weight', 'model_ema.diffusion_modelout0bias', 'model_ema.diffusion_modelout2weight', 'model_ema.diffusion_modelout2bias']\n",
      "[Embedding Manager] weights loaded.\n",
      "reading prompts from ./infer_images/example_prompt.txt\n",
      "Sampling:   0% 0/1 [00:00<?, ?it/s]\n",
      "data:   0% 0/9 [00:00<?, ?it/s]\u001B[A[Embedding Manager] test_mode: coefficient\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.14it/s]\n",
      "\n",
      "data:  11% 1/9 [00:17<02:20, 17.53s/it]\u001B[A[Embedding Manager] test_mode: coefficient\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.17it/s]\n",
      "\n",
      "data:  22% 2/9 [00:33<01:57, 16.77s/it]\u001B[A[Embedding Manager] test_mode: coefficient\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.17it/s]\n",
      "\n",
      "data:  33% 3/9 [00:50<01:39, 16.53s/it]\u001B[A[Embedding Manager] test_mode: coefficient\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.17it/s]\n",
      "\n",
      "data:  44% 4/9 [01:06<01:22, 16.43s/it]\u001B[A[Embedding Manager] test_mode: coefficient\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.17it/s]\n",
      "\n",
      "data:  56% 5/9 [01:22<01:05, 16.36s/it]\u001B[A[Embedding Manager] test_mode: coefficient\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.17it/s]\n",
      "\n",
      "data:  67% 6/9 [01:38<00:48, 16.33s/it]\u001B[A[Embedding Manager] test_mode: coefficient\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.17it/s]\n",
      "\n",
      "data:  78% 7/9 [01:55<00:32, 16.30s/it]\u001B[A[Embedding Manager] test_mode: coefficient\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.17it/s]\n",
      "\n",
      "data:  89% 8/9 [02:11<00:16, 16.28s/it]\u001B[A[Embedding Manager] test_mode: coefficient\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.17it/s]\n",
      "\n",
      "data: 100% 9/9 [02:27<00:00, 16.39s/it]\n",
      "Sampling: 100% 1/1 [02:27<00:00, 147.55s/it]\n",
      "Your samples are ready and waiting for you here: \n",
      "outputs/training2023-07-13T14-55-56_celebbasis \n",
      " \n",
      "Enjoy.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhrEJlo12pFd",
    "outputId": "6e14c13d-20db-422e-ea2f-3f38cea2fc94"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Jul 13 15:24:52 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    44W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "gpuType": "V100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}